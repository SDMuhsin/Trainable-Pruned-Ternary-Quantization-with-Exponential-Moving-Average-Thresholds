

==================== Beginning of the experiment ====================


Original number of training samples (KMNIST): 60000
New number of training samples (KMNIST): 6000
Number of samples in the training dataset:  6000
Number of samples in the testing dataset:  10000
Shape of the used representation: torch.Size([1, 20, 20])
Pre-trained models files to use:  ['./results/KMNIST_RESNET18_FP_29.10.2024_17:00:57_0/model//final_model-KMNIST_RESNET18_FP_rep-0.pth'] 1
===> Saving the results of the experiment in ./results/KMNIST_RESNET18_30.10.2024_07:01:36_0
Number of samples in the training dataset:  6000
Number of samples in the testing dataset:  10000


Class weights: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]




=======> Repetitions 0 <=======
===> Model loaded successfully !
Adjusting learning rate of group 0 to 5.0000e-06.
================================================================================
METRICS


=======>Train loss at epoch 0 is 0.1288807988166809
		Test loss at epoch 0 is 0.8982678651809692

=======>Train F1 Score at epoch 0 is 0.96418664967534

		Test F1 Score at epoch 0 is 0.834

=======>Train accuracy at epoch 0 is 0.9643333333333334

		Test accuracy at epoch 0 is 0.834

=======>Train MCC at epoch 0 is 0.960459920841119

		Test MCC at epoch 0 is 0.8165392977523165
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 0: 89.02445983886719



================================================================================
METRICS


=======>Train loss at epoch 1 is 0.1254296451807022
		Test loss at epoch 1 is 0.8531299233436584

=======>Train F1 Score at epoch 1 is 0.9681523369279823

		Test F1 Score at epoch 1 is 0.8364

=======>Train accuracy at epoch 1 is 0.9681666666666666

		Test accuracy at epoch 1 is 0.8364

=======>Train MCC at epoch 1 is 0.9646924951229352

		Test MCC at epoch 1 is 0.8190749499926524
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 1: 89.02376556396484



================================================================================
METRICS


=======>Train loss at epoch 2 is 0.14312370121479034
		Test loss at epoch 2 is 0.8242920637130737

=======>Train F1 Score at epoch 2 is 0.964318588515156

		Test F1 Score at epoch 2 is 0.8387

=======>Train accuracy at epoch 2 is 0.9643333333333334

		Test accuracy at epoch 2 is 0.8387

=======>Train MCC at epoch 2 is 0.9604653588592402

		Test MCC at epoch 2 is 0.8215700986379961
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 2: 89.02281951904297



================================================================================
METRICS


=======>Train loss at epoch 3 is 0.11619196832180023
		Test loss at epoch 3 is 0.833297610282898

=======>Train F1 Score at epoch 3 is 0.9683037142255518

		Test F1 Score at epoch 3 is 0.8421

=======>Train accuracy at epoch 3 is 0.9683333333333334

		Test accuracy at epoch 3 is 0.8421

=======>Train MCC at epoch 3 is 0.9649023968756275

		Test MCC at epoch 3 is 0.8251574064771756
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 3: 89.02095031738281



================================================================================
METRICS


=======>Train loss at epoch 4 is 0.124983049929142
		Test loss at epoch 4 is 0.8239473104476929

=======>Train F1 Score at epoch 4 is 0.9658306163550003

		Test F1 Score at epoch 4 is 0.842

=======>Train accuracy at epoch 4 is 0.9658333333333333

		Test accuracy at epoch 4 is 0.842

=======>Train MCC at epoch 4 is 0.9621136037873835

		Test MCC at epoch 4 is 0.8251010828091356
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 4: 89.01924133300781



================================================================================
METRICS


=======>Train loss at epoch 5 is 0.10957780480384827
		Test loss at epoch 5 is 0.8206627368927002

=======>Train F1 Score at epoch 5 is 0.9675928719443758

		Test F1 Score at epoch 5 is 0.8408

=======>Train accuracy at epoch 5 is 0.9676666666666667

		Test accuracy at epoch 5 is 0.8408

=======>Train MCC at epoch 5 is 0.964129969269983

		Test MCC at epoch 5 is 0.8239453203009738
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 5: 89.01818084716797



================================================================================
METRICS


=======>Train loss at epoch 6 is 0.11518984287977219
		Test loss at epoch 6 is 0.8501523733139038

=======>Train F1 Score at epoch 6 is 0.9680907023653011

		Test F1 Score at epoch 6 is 0.8396999999999999

=======>Train accuracy at epoch 6 is 0.9681666666666666

		Test accuracy at epoch 6 is 0.8397

=======>Train MCC at epoch 6 is 0.9646782131002489

		Test MCC at epoch 6 is 0.8225646199505269
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 6: 89.0169448852539



================================================================================
METRICS


=======>Train loss at epoch 7 is 0.11006402224302292
		Test loss at epoch 7 is 0.8214811086654663

=======>Train F1 Score at epoch 7 is 0.9696140195447116

		Test F1 Score at epoch 7 is 0.8401

=======>Train accuracy at epoch 7 is 0.9696666666666667

		Test accuracy at epoch 7 is 0.8401

=======>Train MCC at epoch 7 is 0.9663541833397222

		Test MCC at epoch 7 is 0.8229626832280419
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 7: 89.01538848876953



================================================================================
METRICS


=======>Train loss at epoch 8 is 0.11027802526950836
		Test loss at epoch 8 is 0.8502574563026428

=======>Train F1 Score at epoch 8 is 0.9694648112528859

		Test F1 Score at epoch 8 is 0.8394

=======>Train accuracy at epoch 8 is 0.9695

		Test accuracy at epoch 8 is 0.8394

=======>Train MCC at epoch 8 is 0.9661659222695534

		Test MCC at epoch 8 is 0.8223928762191997
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 8: 89.01403045654297



================================================================================
METRICS


=======>Train loss at epoch 9 is 0.09868115931749344
		Test loss at epoch 9 is 0.7853515148162842

=======>Train F1 Score at epoch 9 is 0.9713082122395698

		Test F1 Score at epoch 9 is 0.8472999999999999

=======>Train accuracy at epoch 9 is 0.9713333333333334

		Test accuracy at epoch 9 is 0.8473

=======>Train MCC at epoch 9 is 0.968192238273526

		Test MCC at epoch 9 is 0.8308279154667264
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 9: 89.0125732421875



================================================================================
METRICS


=======>Train loss at epoch 10 is 0.10231062024831772
		Test loss at epoch 10 is 0.8207653760910034

=======>Train F1 Score at epoch 10 is 0.9713230398436176

		Test F1 Score at epoch 10 is 0.843

=======>Train accuracy at epoch 10 is 0.9713333333333334

		Test accuracy at epoch 10 is 0.843

=======>Train MCC at epoch 10 is 0.9682103706505817

		Test MCC at epoch 10 is 0.8262043991473458
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 10: 89.01164245605469



================================================================================
METRICS


=======>Train loss at epoch 11 is 0.10364137589931488
		Test loss at epoch 11 is 0.86622154712677

=======>Train F1 Score at epoch 11 is 0.9721316892034567

		Test F1 Score at epoch 11 is 0.8426

=======>Train accuracy at epoch 11 is 0.9721666666666666

		Test accuracy at epoch 11 is 0.8426

=======>Train MCC at epoch 11 is 0.969109010948521

		Test MCC at epoch 11 is 0.8258801709192002
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 11: 89.01046752929688



================================================================================
METRICS


=======>Train loss at epoch 12 is 0.08887938410043716
		Test loss at epoch 12 is 0.820966362953186

=======>Train F1 Score at epoch 12 is 0.9741983211021841

		Test F1 Score at epoch 12 is 0.8466

=======>Train accuracy at epoch 12 is 0.9741666666666666

		Test accuracy at epoch 12 is 0.8466

=======>Train MCC at epoch 12 is 0.971340487291003

		Test MCC at epoch 12 is 0.8301376584718143
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 12: 89.00946044921875



================================================================================
METRICS


=======>Train loss at epoch 13 is 0.10160783678293228
		Test loss at epoch 13 is 0.8003506660461426

=======>Train F1 Score at epoch 13 is 0.9707110861063224

		Test F1 Score at epoch 13 is 0.8457

=======>Train accuracy at epoch 13 is 0.9706666666666667

		Test accuracy at epoch 13 is 0.8457

=======>Train MCC at epoch 13 is 0.9674720460798247

		Test MCC at epoch 13 is 0.8290311874386335
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 13: 89.0078353881836



================================================================================
METRICS


=======>Train loss at epoch 14 is 0.10016264766454697
		Test loss at epoch 14 is 0.8212181925773621

=======>Train F1 Score at epoch 14 is 0.9721466405953831

		Test F1 Score at epoch 14 is 0.8441000000000001

=======>Train accuracy at epoch 14 is 0.9721666666666666

		Test accuracy at epoch 14 is 0.8441

=======>Train MCC at epoch 14 is 0.969127036409786

		Test MCC at epoch 14 is 0.8274485680237232
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 14: 89.0062484741211



================================================================================
METRICS


=======>Train loss at epoch 15 is 0.09252382069826126
		Test loss at epoch 15 is 0.8205738067626953

=======>Train F1 Score at epoch 15 is 0.9738167711126069

		Test F1 Score at epoch 15 is 0.845

=======>Train accuracy at epoch 15 is 0.9738333333333333

		Test accuracy at epoch 15 is 0.845

=======>Train MCC at epoch 15 is 0.9709710969838723

		Test MCC at epoch 15 is 0.8283032635982687
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 15: 89.00507354736328



================================================================================
METRICS


=======>Train loss at epoch 16 is 0.09343253076076508
		Test loss at epoch 16 is 0.8208346962928772

=======>Train F1 Score at epoch 16 is 0.974174139512194

		Test F1 Score at epoch 16 is 0.8447

=======>Train accuracy at epoch 16 is 0.9741666666666666

		Test accuracy at epoch 16 is 0.8447

=======>Train MCC at epoch 16 is 0.9713391434946442

		Test MCC at epoch 16 is 0.8279617970148148
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 16: 89.00402069091797



================================================================================
METRICS


=======>Train loss at epoch 17 is 0.08531647175550461
		Test loss at epoch 17 is 0.8110213875770569

=======>Train F1 Score at epoch 17 is 0.9753164558089263

		Test F1 Score at epoch 17 is 0.8467

=======>Train accuracy at epoch 17 is 0.9753333333333334

		Test accuracy at epoch 17 is 0.8467

=======>Train MCC at epoch 17 is 0.9726316516320808

		Test MCC at epoch 17 is 0.8302192138310855
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 17: 89.00245666503906



================================================================================
METRICS


=======>Train loss at epoch 18 is 0.08267217874526978
		Test loss at epoch 18 is 0.8015378713607788

=======>Train F1 Score at epoch 18 is 0.976561075481819

		Test F1 Score at epoch 18 is 0.8486

=======>Train accuracy at epoch 18 is 0.9766666666666667

		Test accuracy at epoch 18 is 0.8486

=======>Train MCC at epoch 18 is 0.9741016269746271

		Test MCC at epoch 18 is 0.8323898648662621
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 18: 89.00191497802734



================================================================================
METRICS


=======>Train loss at epoch 19 is 0.08440574258565903
		Test loss at epoch 19 is 0.7745047211647034

=======>Train F1 Score at epoch 19 is 0.9738483356582803

		Test F1 Score at epoch 19 is 0.8474

=======>Train accuracy at epoch 19 is 0.9738333333333333

		Test accuracy at epoch 19 is 0.8474

=======>Train MCC at epoch 19 is 0.970962421448623

		Test MCC at epoch 19 is 0.8309453692756784
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 19: 89.00016784667969



================================================================================
METRICS


=======>Train loss at epoch 20 is 0.09143571555614471
		Test loss at epoch 20 is 0.7705725431442261

=======>Train F1 Score at epoch 20 is 0.9778460630469977

		Test F1 Score at epoch 20 is 0.8505

=======>Train accuracy at epoch 20 is 0.9778333333333333

		Test accuracy at epoch 20 is 0.8505

=======>Train MCC at epoch 20 is 0.9754070802641144

		Test MCC at epoch 20 is 0.8342875882264248
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 20: 88.99826049804688



================================================================================
METRICS


=======>Train loss at epoch 21 is 0.06963702291250229
		Test loss at epoch 21 is 0.7943941950798035

=======>Train F1 Score at epoch 21 is 0.9798102482938426

		Test F1 Score at epoch 21 is 0.8491

=======>Train accuracy at epoch 21 is 0.9798333333333333

		Test accuracy at epoch 21 is 0.8491

=======>Train MCC at epoch 21 is 0.9776187489544022

		Test MCC at epoch 21 is 0.8327974418693159
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 21: 88.99725341796875



================================================================================
METRICS


=======>Train loss at epoch 22 is 0.0773683488368988
		Test loss at epoch 22 is 0.7837958931922913

=======>Train F1 Score at epoch 22 is 0.9791414792201554

		Test F1 Score at epoch 22 is 0.8454

=======>Train accuracy at epoch 22 is 0.9791666666666666

		Test accuracy at epoch 22 is 0.8454

=======>Train MCC at epoch 22 is 0.9768671841050965

		Test MCC at epoch 22 is 0.8287592019373936
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 22: 88.99560546875



================================================================================
METRICS


=======>Train loss at epoch 23 is 0.08875968307256699
		Test loss at epoch 23 is 0.8040261268615723

=======>Train F1 Score at epoch 23 is 0.9770349313971701

		Test F1 Score at epoch 23 is 0.8489

=======>Train accuracy at epoch 23 is 0.977

		Test accuracy at epoch 23 is 0.8489

=======>Train MCC at epoch 23 is 0.9744753026655273

		Test MCC at epoch 23 is 0.8326516219383285
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 23: 88.99398803710938



================================================================================
METRICS


=======>Train loss at epoch 24 is 0.0808749571442604
		Test loss at epoch 24 is 0.7639565467834473

=======>Train F1 Score at epoch 24 is 0.9750208373828562

		Test F1 Score at epoch 24 is 0.8512000000000001

=======>Train accuracy at epoch 24 is 0.975

		Test accuracy at epoch 24 is 0.8512

=======>Train MCC at epoch 24 is 0.9722606969150238

		Test MCC at epoch 24 is 0.8351447847257522
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 24: 88.99295043945312



================================================================================
METRICS


=======>Train loss at epoch 25 is 0.07126753032207489
		Test loss at epoch 25 is 0.8063517808914185

=======>Train F1 Score at epoch 25 is 0.9786631090030642

		Test F1 Score at epoch 25 is 0.8466

=======>Train accuracy at epoch 25 is 0.9786666666666667

		Test accuracy at epoch 25 is 0.8466

=======>Train MCC at epoch 25 is 0.9763289008041656

		Test MCC at epoch 25 is 0.8300333403641028
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 25: 88.99226379394531



================================================================================
METRICS


=======>Train loss at epoch 26 is 0.07474929094314575
		Test loss at epoch 26 is 0.7938880920410156

=======>Train F1 Score at epoch 26 is 0.9770002281352971

		Test F1 Score at epoch 26 is 0.8485

=======>Train accuracy at epoch 26 is 0.977

		Test accuracy at epoch 26 is 0.8485

=======>Train MCC at epoch 26 is 0.9744639988191833

		Test MCC at epoch 26 is 0.8322026760942809
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 26: 88.99089050292969



================================================================================
METRICS


=======>Train loss at epoch 27 is 0.07459460943937302
		Test loss at epoch 27 is 0.7540009617805481

=======>Train F1 Score at epoch 27 is 0.9789614197381387

		Test F1 Score at epoch 27 is 0.8529

=======>Train accuracy at epoch 27 is 0.979

		Test accuracy at epoch 27 is 0.8529

=======>Train MCC at epoch 27 is 0.9766826518550964

		Test MCC at epoch 27 is 0.8369512387413135
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 27: 88.98958587646484



================================================================================
METRICS


=======>Train loss at epoch 28 is 0.0706166923046112
		Test loss at epoch 28 is 0.7851089835166931

=======>Train F1 Score at epoch 28 is 0.9812864309415857

		Test F1 Score at epoch 28 is 0.8507000000000001

=======>Train accuracy at epoch 28 is 0.9813333333333333

		Test accuracy at epoch 28 is 0.8507

=======>Train MCC at epoch 28 is 0.9792797118284621

		Test MCC at epoch 28 is 0.8347126548618355
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 28: 88.98785400390625



================================================================================
METRICS


=======>Train loss at epoch 29 is 0.06225934252142906
		Test loss at epoch 29 is 0.7525357604026794

=======>Train F1 Score at epoch 29 is 0.9813957248520968

		Test F1 Score at epoch 29 is 0.8526

=======>Train accuracy at epoch 29 is 0.9813333333333333

		Test accuracy at epoch 29 is 0.8526

=======>Train MCC at epoch 29 is 0.9792728039117868

		Test MCC at epoch 29 is 0.8365320288107607
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 29: 88.98643493652344



================================================================================
METRICS


=======>Train loss at epoch 30 is 0.06607312709093094
		Test loss at epoch 30 is 0.7577328681945801

=======>Train F1 Score at epoch 30 is 0.9799989080113193

		Test F1 Score at epoch 30 is 0.8515

=======>Train accuracy at epoch 30 is 0.98

		Test accuracy at epoch 30 is 0.8515

=======>Train MCC at epoch 30 is 0.9777933455251313

		Test MCC at epoch 30 is 0.835339959725051
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 30: 88.98529052734375



================================================================================
METRICS


=======>Train loss at epoch 31 is 0.0695316344499588
		Test loss at epoch 31 is 0.7763981819152832

=======>Train F1 Score at epoch 31 is 0.9814947139469672

		Test F1 Score at epoch 31 is 0.8499

=======>Train accuracy at epoch 31 is 0.9815

		Test accuracy at epoch 31 is 0.8499

=======>Train MCC at epoch 31 is 0.9794627287154332

		Test MCC at epoch 31 is 0.8337368800976452
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 31: 88.9837646484375



================================================================================
METRICS


=======>Train loss at epoch 32 is 0.06722334772348404
		Test loss at epoch 32 is 0.7844156622886658

=======>Train F1 Score at epoch 32 is 0.9813343680810089

		Test F1 Score at epoch 32 is 0.8511

=======>Train accuracy at epoch 32 is 0.9813333333333333

		Test accuracy at epoch 32 is 0.8511

=======>Train MCC at epoch 32 is 0.9792776814623702

		Test MCC at epoch 32 is 0.834947321254163
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 32: 88.98204803466797



================================================================================
METRICS


=======>Train loss at epoch 33 is 0.07662300020456314
		Test loss at epoch 33 is 0.7935807108879089

=======>Train F1 Score at epoch 33 is 0.9781047182412372

		Test F1 Score at epoch 33 is 0.8513

=======>Train accuracy at epoch 33 is 0.9781666666666666

		Test accuracy at epoch 33 is 0.8513

=======>Train MCC at epoch 33 is 0.975759212115071

		Test MCC at epoch 33 is 0.8351677158185039
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 33: 88.98004150390625



================================================================================
METRICS


=======>Train loss at epoch 34 is 0.06878452748060226
		Test loss at epoch 34 is 0.7760592103004456

=======>Train F1 Score at epoch 34 is 0.9789729523310202

		Test F1 Score at epoch 34 is 0.8539

=======>Train accuracy at epoch 34 is 0.979

		Test accuracy at epoch 34 is 0.8539

=======>Train MCC at epoch 34 is 0.9766841738963723

		Test MCC at epoch 34 is 0.8379902212885849
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 34: 88.97809600830078



================================================================================
METRICS


=======>Train loss at epoch 35 is 0.06802091002464294
		Test loss at epoch 35 is 0.7747657299041748

=======>Train F1 Score at epoch 35 is 0.9798635037255078

		Test F1 Score at epoch 35 is 0.8506

=======>Train accuracy at epoch 35 is 0.9798333333333333

		Test accuracy at epoch 35 is 0.8506

=======>Train MCC at epoch 35 is 0.9776102152200796

		Test MCC at epoch 35 is 0.8344472352233082
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 35: 88.97630310058594



================================================================================
METRICS


=======>Train loss at epoch 36 is 0.06272076815366745
		Test loss at epoch 36 is 0.7702749967575073

=======>Train F1 Score at epoch 36 is 0.9803416817891927

		Test F1 Score at epoch 36 is 0.8519

=======>Train accuracy at epoch 36 is 0.9803333333333333

		Test accuracy at epoch 36 is 0.8519

=======>Train MCC at epoch 36 is 0.9781696108714432

		Test MCC at epoch 36 is 0.8358579620807032
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 36: 88.97413635253906



================================================================================
METRICS


=======>Train loss at epoch 37 is 0.057362597435712814
		Test loss at epoch 37 is 0.7616811990737915

=======>Train F1 Score at epoch 37 is 0.9827209160390113

		Test F1 Score at epoch 37 is 0.8547

=======>Train accuracy at epoch 37 is 0.9826666666666667

		Test accuracy at epoch 37 is 0.8547

=======>Train MCC at epoch 37 is 0.9807525392328985

		Test MCC at epoch 37 is 0.8388815523439768
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 37: 88.97139739990234



================================================================================
METRICS


=======>Train loss at epoch 38 is 0.05787905305624008
		Test loss at epoch 38 is 0.76255863904953

=======>Train F1 Score at epoch 38 is 0.9818450479113314

		Test F1 Score at epoch 38 is 0.8571000000000001

=======>Train accuracy at epoch 38 is 0.9818333333333333

		Test accuracy at epoch 38 is 0.8571

=======>Train MCC at epoch 38 is 0.979826199511265

		Test MCC at epoch 38 is 0.8415607473407871
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 38: 88.96937561035156



================================================================================
METRICS


=======>Train loss at epoch 39 is 0.059375256299972534
		Test loss at epoch 39 is 0.7680193781852722

=======>Train F1 Score at epoch 39 is 0.9826552474984552

		Test F1 Score at epoch 39 is 0.8524

=======>Train accuracy at epoch 39 is 0.9826666666666667

		Test accuracy at epoch 39 is 0.8524

=======>Train MCC at epoch 39 is 0.9807530242128295

		Test MCC at epoch 39 is 0.8364005645083983
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 39: 88.96709442138672



================================================================================
METRICS


=======>Train loss at epoch 40 is 0.05802496522665024
		Test loss at epoch 40 is 0.7651919722557068

=======>Train F1 Score at epoch 40 is 0.9846590521410399

		Test F1 Score at epoch 40 is 0.8507000000000001

=======>Train accuracy at epoch 40 is 0.9846666666666667

		Test accuracy at epoch 40 is 0.8507

=======>Train MCC at epoch 40 is 0.982971455551154

		Test MCC at epoch 40 is 0.8346051395544504
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 40: 88.9651870727539



================================================================================
METRICS


=======>Train loss at epoch 41 is 0.05599778890609741
		Test loss at epoch 41 is 0.7735026478767395

=======>Train F1 Score at epoch 41 is 0.9834843671182879

		Test F1 Score at epoch 41 is 0.8533

=======>Train accuracy at epoch 41 is 0.9835

		Test accuracy at epoch 41 is 0.8533

=======>Train MCC at epoch 41 is 0.9816751619664645

		Test MCC at epoch 41 is 0.8373107930188187
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 41: 88.96434020996094



================================================================================
METRICS


=======>Train loss at epoch 42 is 0.05440434068441391
		Test loss at epoch 42 is 0.776669979095459

=======>Train F1 Score at epoch 42 is 0.9825301580438366

		Test F1 Score at epoch 42 is 0.8536

=======>Train accuracy at epoch 42 is 0.9825

		Test accuracy at epoch 42 is 0.8536

=======>Train MCC at epoch 42 is 0.9805674436682048

		Test MCC at epoch 42 is 0.8377659184012792
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 42: 88.96228790283203



================================================================================
METRICS


=======>Train loss at epoch 43 is 0.06747022271156311
		Test loss at epoch 43 is 0.7585813999176025

=======>Train F1 Score at epoch 43 is 0.9816667326696065

		Test F1 Score at epoch 43 is 0.8554999999999999

=======>Train accuracy at epoch 43 is 0.9816666666666667

		Test accuracy at epoch 43 is 0.8555

=======>Train MCC at epoch 43 is 0.979638787602177

		Test MCC at epoch 43 is 0.8396992011775083
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 43: 88.96055603027344



================================================================================
METRICS


=======>Train loss at epoch 44 is 0.054147861897945404
		Test loss at epoch 44 is 0.7470093965530396

=======>Train F1 Score at epoch 44 is 0.984008453063946

		Test F1 Score at epoch 44 is 0.8547

=======>Train accuracy at epoch 44 is 0.984

		Test accuracy at epoch 44 is 0.8547

=======>Train MCC at epoch 44 is 0.9822298434330439

		Test MCC at epoch 44 is 0.8389914222751851
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 44: 88.95890045166016



================================================================================
METRICS


=======>Train loss at epoch 45 is 0.059444598853588104
		Test loss at epoch 45 is 0.7317588925361633

=======>Train F1 Score at epoch 45 is 0.9841505711044342

		Test F1 Score at epoch 45 is 0.8584

=======>Train accuracy at epoch 45 is 0.9841666666666666

		Test accuracy at epoch 45 is 0.8584

=======>Train MCC at epoch 45 is 0.9824146834025975

		Test MCC at epoch 45 is 0.8429044179740495
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 45: 88.95660400390625



================================================================================
METRICS


=======>Train loss at epoch 46 is 0.0609455406665802
		Test loss at epoch 46 is 0.7422780990600586

=======>Train F1 Score at epoch 46 is 0.9831689755066938

		Test F1 Score at epoch 46 is 0.8552

=======>Train accuracy at epoch 46 is 0.9831666666666666

		Test accuracy at epoch 46 is 0.8552

=======>Train MCC at epoch 46 is 0.9813056651153237

		Test MCC at epoch 46 is 0.839438107962484
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 46: 88.95542907714844



================================================================================
METRICS


=======>Train loss at epoch 47 is 0.048436250537633896
		Test loss at epoch 47 is 0.7544754147529602

=======>Train F1 Score at epoch 47 is 0.9841423807045345

		Test F1 Score at epoch 47 is 0.8584

=======>Train accuracy at epoch 47 is 0.9841666666666666

		Test accuracy at epoch 47 is 0.8584

=======>Train MCC at epoch 47 is 0.9824159391917544

		Test MCC at epoch 47 is 0.8429650073117326
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 47: 88.95393371582031



================================================================================
METRICS


=======>Train loss at epoch 48 is 0.052475690841674805
		Test loss at epoch 48 is 0.754936933517456

=======>Train F1 Score at epoch 48 is 0.9841448434011285

		Test F1 Score at epoch 48 is 0.8557

=======>Train accuracy at epoch 48 is 0.9841666666666666

		Test accuracy at epoch 48 is 0.8557

=======>Train MCC at epoch 48 is 0.9824178297247655

		Test MCC at epoch 48 is 0.8400190912700096
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 48: 88.95213317871094



================================================================================
METRICS


=======>Train loss at epoch 49 is 0.04534001648426056
		Test loss at epoch 49 is 0.740348219871521

=======>Train F1 Score at epoch 49 is 0.9846485980951147

		Test F1 Score at epoch 49 is 0.859

=======>Train accuracy at epoch 49 is 0.9846666666666667

		Test accuracy at epoch 49 is 0.859

=======>Train MCC at epoch 49 is 0.9829728524016644

		Test MCC at epoch 49 is 0.8435224347697674
================================================================================


!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)
=======> SPARSITY RATE AT EPOCH 49: 88.94983673095703



!!!!Counting the non zero parameters of ONLY THE LAYERS TO QUANTIZE (10988608 params to quantize)


=======> For repetition 0 we have an sparsity rate of 0.8894983530044556







Param: encoder.conv1.weight
	Parameter containing:
tensor([[[[ 0.0000,  1.0022, -1.0022,  ..., -1.0022,  1.0022,  1.0022],
          [ 0.0000,  0.0000, -1.0022,  ...,  1.0022,  1.0022, -1.0022],
          [-1.0022, -1.0022, -1.0022,  ...,  1.0022,  0.0000, -1.0022],
          ...,
          [-1.0022,  0.0000, -1.0022,  ...,  1.0022,  0.0000, -1.0022],
          [ 0.0000, -1.0022,  0.0000,  ..., -1.0022, -1.0022,  1.0022],
          [-1.0022, -1.0022, -1.0022,  ...,  0.0000,  1.0022,  1.0022]]],


        [[[ 1.0022,  1.0022,  0.0000,  ...,  0.0000,  1.0022,  1.0022],
          [ 0.0000,  1.0022,  0.0000,  ...,  1.0022, -1.0022, -1.0022],
          [-1.0022,  1.0022,  0.0000,  ..., -1.0022,  1.0022,  1.0022],
          ...,
          [ 1.0022,  0.0000,  1.0022,  ..., -1.0022, -1.0022, -1.0022],
          [ 0.0000, -1.0022, -1.0022,  ...,  1.0022, -1.0022, -1.0022],
          [-1.0022, -1.0022,  1.0022,  ...,  1.0022,  1.0022, -1.0022]]],


        [[[-1.0022,  0.0000,  0.0000,  ...,  0.0000,  1.0022,  1.0022],
          [ 0.0000,  1.0022, -1.0022,  ...,  1.0022,  1.0022,  1.0022],
          [-1.0022, -1.0022, -1.0022,  ...,  1.0022,  1.0022,  0.0000],
          ...,
          [ 0.0000, -1.0022, -1.0022,  ..., -1.0022, -1.0022, -1.0022],
          [ 0.0000, -1.0022, -1.0022,  ..., -1.0022, -1.0022,  1.0022],
          [ 0.0000, -1.0022,  0.0000,  ...,  1.0022,  1.0022,  1.0022]]],


        ...,


        [[[-1.0022,  0.0000,  1.0022,  ...,  0.0000, -1.0022,  1.0022],
          [ 1.0022,  0.0000, -1.0022,  ...,  0.0000, -1.0022,  1.0022],
          [ 1.0022,  1.0022,  0.0000,  ..., -1.0022,  0.0000,  1.0022],
          ...,
          [-1.0022,  1.0022,  0.0000,  ...,  1.0022, -1.0022, -1.0022],
          [ 1.0022, -1.0022,  1.0022,  ..., -1.0022, -1.0022, -1.0022],
          [-1.0022,  1.0022, -1.0022,  ..., -1.0022,  0.0000,  1.0022]]],


        [[[ 0.0000,  0.0000, -1.0022,  ..., -1.0022, -1.0022,  1.0022],
          [ 1.0022,  0.0000, -1.0022,  ...,  1.0022,  1.0022,  1.0022],
          [ 1.0022,  1.0022, -1.0022,  ...,  0.0000, -1.0022, -1.0022],
          ...,
          [-1.0022, -1.0022, -1.0022,  ...,  1.0022, -1.0022,  0.0000],
          [ 0.0000,  1.0022,  1.0022,  ..., -1.0022, -1.0022,  1.0022],
          [ 1.0022,  1.0022, -1.0022,  ..., -1.0022,  0.0000,  1.0022]]],


        [[[ 1.0022,  0.0000,  0.0000,  ...,  1.0022, -1.0022, -1.0022],
          [-1.0022, -1.0022, -1.0022,  ..., -1.0022,  0.0000, -1.0022],
          [ 0.0000, -1.0022,  0.0000,  ...,  1.0022,  1.0022, -1.0022],
          ...,
          [-1.0022,  0.0000, -1.0022,  ..., -1.0022, -1.0022,  0.0000],
          [-1.0022, -1.0022,  0.0000,  ...,  0.0000, -1.0022, -1.0022],
          [ 1.0022, -1.0022,  1.0022,  ...,  1.0022, -1.0022, -1.0022]]]],
       device='cuda:0', requires_grad=True)
Param: encoder.bn1.weight
	Parameter containing:
tensor([1.1482, 0.9943, 1.1804, 1.1311, 1.1834, 1.1112, 1.2100, 1.1458, 1.0561,
        1.0767, 1.0039, 0.9898, 1.0082, 1.1485, 1.0649, 0.8295, 1.1458, 1.0881,
        1.1692, 0.9398, 1.0268, 0.9711, 1.1233, 1.0621, 1.0259, 1.0860, 1.2127,
        1.1551, 0.9532, 1.0401, 1.0654, 1.2527, 1.2714, 0.9844, 1.0950, 1.0122,
        1.2359, 1.0309, 0.9854, 0.9341, 1.0542, 1.0497, 1.0828, 1.1062, 1.1218,
        0.9466, 1.0750, 1.1487, 0.9429, 1.1777, 0.9391, 1.2263, 1.0803, 1.0386,
        1.2551, 1.0967, 1.1640, 1.1876, 1.1404, 1.0781, 1.0606, 1.2290, 0.9248,
        1.0715], device='cuda:0', requires_grad=True)
Param: encoder.bn1.bias
	Parameter containing:
tensor([-0.3025, -0.3065, -0.2988, -0.2768, -0.3349, -0.2510, -0.3643, -0.3230,
        -0.2567, -0.3841, -0.2280, -0.2832, -0.2801, -0.4462, -0.2456, -0.4007,
        -0.3788, -0.5053, -0.3002, -0.2720, -0.2681, -0.2406, -0.3395, -0.4192,
        -0.3657, -0.2072, -0.3223, -0.2032, -0.3488, -0.3441, -0.3747, -0.3852,
        -0.3589, -0.3292, -0.3295, -0.3442, -0.2972, -0.3385, -0.2097, -0.3351,
        -0.2510, -0.3657, -0.2662, -0.3167, -0.4043, -0.3181, -0.4306, -0.1783,
        -0.2440, -0.3785, -0.3978, -0.2668, -0.2150, -0.4296, -0.3561, -0.2743,
        -0.4040, -0.2535, -0.3711, -0.1713, -0.3929, -0.2633, -0.3343, -0.4571],
       device='cuda:0', requires_grad=True)
Param: encoder.layer1.0.conv1.weight
	Parameter containing:
tensor([[[[ 0.0000,  1.0028,  1.0028],
          [ 0.0000,  1.0028,  0.0000],
          [ 0.0000,  0.0000, -1.0028]],

         [[-1.0028, -1.0028,  0.0000],
          [-1.0028, -1.0028,  1.0028],
          [-1.0028,  0.0000,  1.0028]],

         [[ 1.0028,  0.0000,  0.0000],
          [ 0.0000,  1.0028, -1.0028],
          [ 0.0000,  1.0028,  1.0028]],

         ...,

         [[-1.0028,  0.0000,  0.0000],
          [ 0.0000,  1.0028,  0.0000],
          [ 1.0028,  0.0000, -1.0028]],

         [[ 0.0000, -1.0028, -1.0028],
          [ 0.0000,  0.0000,  0.0000],
          [-1.0028,  1.0028,  0.0000]],

         [[-1.0028, -1.0028,  1.0028],
          [ 0.0000,  1.0028,  1.0028],
          [ 0.0000, -1.0028, -1.0028]]],


        [[[ 0.0000, -1.0028,  0.0000],
          [ 0.0000, -1.0028, -1.0028],
          [ 0.0000, -1.0028,  0.0000]],

         [[ 1.0028,  1.0028,  1.0028],
          [-1.0028,  1.0028,  0.0000],
          [ 1.0028,  1.0028,  1.0028]],

         [[-1.0028, -1.0028,  0.0000],
          [-1.0028, -1.0028,  1.0028],
          [ 0.0000, -1.0028, -1.0028]],

         ...,

         [[ 1.0028,  1.0028,  1.0028],
          [ 1.0028,  1.0028,  0.0000],
          [ 1.0028,  0.0000,  0.0000]],

         [[-1.0028,  0.0000,  0.0000],
          [ 0.0000,  1.0028,  0.0000],
          [ 1.0028,  0.0000, -1.0028]],

         [[ 1.0028,  1.0028,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-1.0028, -1.0028, -1.0028],
          [-1.0028, -1.0028, -1.0028],
          [ 0.0000,  1.0028,  1.0028]],

         [[ 1.0028,  1.0028,  0.0000],
          [ 0.0000, -1.0028,  1.0028],
          [-1.0028, -1.0028,  0.0000]],

         [[ 1.0028, -1.0028, -1.0028],
          [ 0.0000,  1.0028,  0.0000],
          [-1.0028,  0.0000,  0.0000]],

         ...,

         [[ 0.0000, -1.0028, -1.0028],
          [-1.0028,  0.0000,  0.0000],
          [-1.0028,  0.0000, -1.0028]],

         [[ 0.0000,  1.0028,  1.0028],
          [ 1.0028,  0.0000, -1.0028],
          [ 0.0000,  1.0028, -1.0028]],

         [[ 1.0028,  0.0000, -1.0028],
          [ 1.0028,  1.0028, -1.0028],
          [ 1.0028,  0.0000, -1.0028]]],


        ...,


        [[[ 0.0000,  0.0000,  1.0028],
          [ 0.0000,  0.0000,  1.0028],
          [ 1.0028, -1.0028, -1.0028]],

         [[-1.0028,  1.0028,  0.0000],
          [-1.0028,  0.0000,  0.0000],
          [ 0.0000, -1.0028,  0.0000]],

         [[-1.0028,  0.0000, -1.0028],
          [ 1.0028,  0.0000,  0.0000],
          [-1.0028, -1.0028, -1.0028]],

         ...,

         [[ 1.0028,  0.0000, -1.0028],
          [ 0.0000, -1.0028, -1.0028],
          [ 0.0000, -1.0028, -1.0028]],

         [[-1.0028, -1.0028, -1.0028],
          [ 0.0000,  0.0000, -1.0028],
          [ 0.0000,  1.0028,  1.0028]],

         [[ 0.0000,  1.0028, -1.0028],
          [ 1.0028,  1.0028,  1.0028],
          [ 0.0000, -1.0028,  0.0000]]],


        [[[ 0.0000,  0.0000,  1.0028],
          [-1.0028,  0.0000,  1.0028],
          [ 0.0000,  0.0000,  1.0028]],

         [[ 1.0028,  1.0028, -1.0028],
          [ 0.0000,  0.0000, -1.0028],
          [ 0.0000,  0.0000,  1.0028]],

         [[-1.0028,  0.0000, -1.0028],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0028,  0.0000]],

         ...,

         [[ 1.0028,  0.0000, -1.0028],
          [ 0.0000, -1.0028, -1.0028],
          [-1.0028, -1.0028,  0.0000]],

         [[ 0.0000,  1.0028, -1.0028],
          [ 1.0028,  1.0028, -1.0028],
          [ 1.0028,  0.0000,  0.0000]],

         [[ 0.0000,  1.0028, -1.0028],
          [ 1.0028,  0.0000,  0.0000],
          [ 0.0000, -1.0028,  1.0028]]],


        [[[ 1.0028,  1.0028, -1.0028],
          [ 0.0000,  1.0028, -1.0028],
          [ 0.0000,  1.0028, -1.0028]],

         [[ 0.0000, -1.0028,  0.0000],
          [ 0.0000, -1.0028,  0.0000],
          [ 0.0000, -1.0028, -1.0028]],

         [[ 0.0000, -1.0028,  1.0028],
          [ 1.0028,  0.0000,  1.0028],
          [-1.0028,  0.0000, -1.0028]],

         ...,

         [[ 0.0000, -1.0028, -1.0028],
          [-1.0028,  0.0000, -1.0028],
          [-1.0028,  1.0028, -1.0028]],

         [[ 1.0028,  0.0000,  1.0028],
          [ 1.0028,  1.0028,  0.0000],
          [ 1.0028,  0.0000,  0.0000]],

         [[ 1.0028,  1.0028,  1.0028],
          [ 1.0028,  1.0028,  0.0000],
          [ 0.0000,  0.0000, -1.0028]]]], device='cuda:0', requires_grad=True)
Param: encoder.layer1.0.bn1.weight
	Parameter containing:
tensor([0.8672, 0.9967, 0.9290, 1.0264, 0.9591, 0.8856, 0.9342, 0.9981, 0.8323,
        1.0168, 1.1130, 0.9785, 0.9536, 1.0717, 1.0087, 1.0067, 0.8848, 1.0216,
        1.0514, 0.9792, 1.0682, 0.9678, 0.8190, 0.9901, 0.9641, 1.0486, 1.0325,
        0.9303, 1.0385, 1.0150, 1.0212, 1.0038, 1.1549, 0.8856, 0.8966, 0.8434,
        0.9304, 1.0735, 0.8228, 0.8606, 1.1123, 1.0401, 1.1567, 1.0818, 1.0650,
        0.7977, 0.9821, 0.9313, 0.9198, 0.9065, 0.8354, 1.0533, 1.1438, 1.0038,
        0.9891, 1.0835, 0.8518, 0.9074, 0.9425, 0.8703, 0.8168, 0.9503, 1.1159,
        1.0136], device='cuda:0', requires_grad=True)
Param: encoder.layer1.0.bn1.bias
	Parameter containing:
tensor([-0.2014, -0.2521, -0.0911, -0.1519, -0.3049, -0.1625, -0.1940, -0.1759,
        -0.2663, -0.1649, -0.1201, -0.2307, -0.0907, -0.2302, -0.3104, -0.1942,
        -0.2486, -0.1876, -0.2278, -0.2297, -0.1333, -0.1739, -0.2380, -0.1609,
        -0.1883, -0.0857, -0.2201, -0.0859, -0.1489, -0.1083, -0.1746, -0.1292,
        -0.1561, -0.2054, -0.1981, -0.1992, -0.1636, -0.1316, -0.3573, -0.2055,
        -0.0642, -0.2408, -0.1476, -0.1216, -0.1919, -0.2973, -0.1766, -0.2195,
        -0.3351, -0.1501, -0.1759, -0.1313, -0.1931, -0.2640, -0.1804, -0.1918,
        -0.2590, -0.1885, -0.2831, -0.2971, -0.2231, -0.1522, -0.1304, -0.1971],
       device='cuda:0', requires_grad=True)
Param: encoder.layer1.0.conv2.weight
	Parameter containing:
tensor([[[[-1.0014, -1.0014,  1.0014],
          [ 0.0000, -1.0014,  0.0000],
          [ 0.0000, -1.0014,  1.0014]],

         [[-1.0014,  0.0000,  1.0014],
          [-1.0014, -1.0014, -1.0014],
          [ 0.0000, -1.0014, -1.0014]],

         [[ 0.0000,  0.0000, -1.0014],
          [ 1.0014,  0.0000,  0.0000],
          [ 1.0014,  0.0000, -1.0014]],

         ...,

         [[ 1.0014,  0.0000, -1.0014],
          [ 0.0000,  0.0000, -1.0014],
          [ 0.0000,  1.0014,  0.0000]],

         [[-1.0014,  1.0014,  1.0014],
          [ 0.0000,  0.0000, -1.0014],
          [ 1.0014,  0.0000, -1.0014]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  1.0014],
          [ 1.0014,  0.0000, -1.0014]]],


        [[[ 1.0014, -1.0014,  1.0014],
          [ 1.0014, -1.0014, -1.0014],
          [ 0.0000,  0.0000,  0.0000]],

         [[-1.0014, -1.0014,  1.0014],
          [ 0.0000, -1.0014, -1.0014],
          [ 1.0014,  0.0000, -1.0014]],

         [[ 1.0014,  0.0000,  1.0014],
          [ 0.0000,  0.0000,  1.0014],
          [ 0.0000,  1.0014,  1.0014]],

         ...,

         [[ 0.0000, -1.0014, -1.0014],
          [ 1.0014,  1.0014,  0.0000],
          [ 0.0000,  0.0000,  1.0014]],

         [[ 0.0000, -1.0014, -1.0014],
          [ 1.0014,  0.0000, -1.0014],
          [-1.0014,  0.0000, -1.0014]],

         [[ 1.0014, -1.0014, -1.0014],
          [ 1.0014, -1.0014,  0.0000],
          [ 0.0000,  0.0000,  1.0014]]],


        [[[ 0.0000,  1.0014,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 1.0014,  1.0014,  0.0000]],

         [[-1.0014, -1.0014,  0.0000],
          [-1.0014,  0.0000, -1.0014],
          [-1.0014,  1.0014, -1.0014]],

         [[-1.0014,  0.0000,  0.0000],
          [-1.0014,  0.0000,  1.0014],
          [-1.0014, -1.0014, -1.0014]],

         ...,

         [[ 0.0000, -1.0014,  0.0000],
          [-1.0014,  0.0000,  1.0014],
          [ 0.0000,  1.0014, -1.0014]],

         [[ 1.0014, -1.0014, -1.0014],
          [ 1.0014, -1.0014, -1.0014],
          [-1.0014,  0.0000, -1.0014]],

         [[-1.0014, -1.0014, -1.0014],
          [-1.0014,  0.0000, -1.0014],
          [ 1.0014, -1.0014, -1.0014]]],


        ...,


        [[[ 0.0000, -1.0014,  0.0000],
          [ 0.0000,  1.0014, -1.0014],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 1.0014,  1.0014,  1.0014],
          [ 1.0014,  1.0014, -1.0014],
          [ 1.0014,  0.0000,  0.0000]],

         [[ 0.0000,  1.0014, -1.0014],
          [ 1.0014,  1.0014,  0.0000],
          [-1.0014,  0.0000,  1.0014]],

         ...,

         [[ 1.0014,  1.0014,  0.0000],
          [ 1.0014,  0.0000, -1.0014],
          [-1.0014, -1.0014,  1.0014]],

         [[-1.0014,  0.0000,  0.0000],
          [-1.0014,  0.0000,  0.0000],
          [-1.0014, -1.0014, -1.0014]],

         [[-1.0014,  0.0000, -1.0014],
          [ 0.0000, -1.0014, -1.0014],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000, -1.0014,  1.0014],
          [-1.0014,  0.0000,  1.0014],
          [-1.0014,  0.0000,  0.0000]],

         [[-1.0014, -1.0014,  0.0000],
          [-1.0014,  1.0014,  1.0014],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 1.0014, -1.0014, -1.0014],
          [-1.0014,  1.0014,  1.0014],
          [ 0.0000,  1.0014,  1.0014]],

         ...,

         [[ 0.0000,  1.0014,  0.0000],
          [ 1.0014,  1.0014,  0.0000],
          [ 0.0000, -1.0014, -1.0014]],

         [[-1.0014, -1.0014, -1.0014],
          [-1.0014, -1.0014,  1.0014],
          [ 1.0014, -1.0014,  0.0000]],

         [[ 0.0000,  0.0000,  1.0014],
          [ 0.0000,  1.0014,  1.0014],
          [-1.0014,  1.0014,  0.0000]]],


        [[[ 0.0000, -1.0014, -1.0014],
          [-1.0014,  1.0014,  1.0014],
          [-1.0014, -1.0014,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0014,  0.0000],
          [ 1.0014,  1.0014,  0.0000]],

         [[-1.0014,  0.0000,  0.0000],
          [ 0.0000,  1.0014,  1.0014],
          [-1.0014,  1.0014,  1.0014]],

         ...,

         [[ 0.0000, -1.0014,  0.0000],
          [-1.0014,  0.0000,  1.0014],
          [ 0.0000, -1.0014,  1.0014]],

         [[-1.0014, -1.0014,  0.0000],
          [ 0.0000,  0.0000,  1.0014],
          [ 1.0014,  1.0014,  0.0000]],

         [[ 1.0014,  0.0000,  1.0014],
          [ 0.0000,  1.0014,  0.0000],
          [-1.0014,  1.0014,  0.0000]]]], device='cuda:0', requires_grad=True)
Param: encoder.layer1.0.bn2.weight
	Parameter containing:
tensor([0.9121, 0.8667, 0.9038, 0.9253, 0.8181, 0.8490, 0.8087, 0.9160, 0.5644,
        0.8088, 0.7122, 0.8074, 0.8085, 0.8474, 0.9090, 0.8481, 0.7504, 0.9131,
        1.0431, 0.8432, 0.8599, 0.9803, 0.7640, 0.8667, 0.8035, 0.8347, 0.8804,
        1.0278, 0.8310, 0.7721, 0.7675, 0.8404, 0.8519, 0.8612, 0.8118, 0.8930,
        0.8149, 0.7263, 0.9381, 0.8274, 0.7546, 0.8033, 0.9656, 0.8641, 0.9020,
        0.8845, 1.0532, 0.8548, 1.0504, 0.7733, 0.9193, 0.8252, 0.7514, 0.8518,
        0.8764, 0.8210, 0.9107, 0.9563, 0.8025, 0.8250, 0.8467, 0.8720, 0.9056,
        0.9329], device='cuda:0', requires_grad=True)
Param: encoder.layer1.0.bn2.bias
	Parameter containing:
tensor([-0.2036, -0.2696, -0.2577, -0.2900, -0.2687, -0.1788, -0.3394, -0.3225,
        -0.3455, -0.2058, -0.1796, -0.2350, -0.2780, -0.3014, -0.1322, -0.3272,
        -0.3073, -0.2885, -0.3315, -0.1755, -0.2173, -0.1794, -0.3406, -0.2174,
        -0.2633, -0.2911, -0.3452, -0.1701, -0.2943, -0.2357, -0.1768, -0.2818,
        -0.3901, -0.1925, -0.1862, -0.2939, -0.3046, -0.2570, -0.2349, -0.2987,
        -0.2941, -0.3012, -0.2007, -0.1815, -0.2294, -0.2254, -0.2556, -0.2119,
        -0.2708, -0.3300, -0.3092, -0.1272, -0.2944, -0.2137, -0.3059, -0.3665,
        -0.2281, -0.2348, -0.2570, -0.3216, -0.2444, -0.1766, -0.1754, -0.2706],
       device='cuda:0', requires_grad=True)
Param: encoder.layer1.1.conv1.weight
	Parameter containing:
tensor([[[[ 0.0000, -0.9995, -0.9995],
          [ 0.9995, -0.9995, -0.9995],
          [ 0.9995,  0.9995, -0.9995]],

         [[-0.9995, -0.9995,  0.9995],
          [ 0.0000,  0.0000,  0.9995],
          [ 0.0000,  0.9995,  0.9995]],

         [[-0.9995, -0.9995,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.9995,  0.9995,  0.0000]],

         ...,

         [[ 0.9995,  0.0000, -0.9995],
          [-0.9995,  0.0000,  0.0000],
          [ 0.0000,  0.9995,  0.9995]],

         [[-0.9995,  0.0000,  0.9995],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.9995,  0.9995,  0.0000]],

         [[ 0.0000,  0.9995,  0.9995],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.9995,  0.9995,  0.0000]]],


        [[[-0.9995,  0.0000,  0.9995],
          [-0.9995,  0.0000,  0.0000],
          [-0.9995, -0.9995, -0.9995]],

         [[ 0.0000,  0.9995,  0.0000],
          [-0.9995,  0.9995,  0.0000],
          [ 0.0000,  0.9995,  0.0000]],

         [[-0.9995, -0.9995, -0.9995],
          [ 0.0000, -0.9995,  0.0000],
          [ 0.0000, -0.9995,  0.0000]],

         ...,

         [[-0.9995,  0.0000,  0.0000],
          [ 0.0000, -0.9995,  0.9995],
          [ 0.0000, -0.9995,  0.9995]],

         [[ 0.9995,  0.0000,  0.9995],
          [ 0.0000,  0.0000,  0.0000],
          [-0.9995,  0.0000,  0.9995]],

         [[ 0.9995,  0.9995,  0.0000],
          [ 0.0000, -0.9995,  0.0000],
          [-0.9995,  0.0000,  0.9995]]],


        [[[ 0.0000,  0.9995,  0.9995],
          [-0.9995,  0.9995,  0.9995],
          [-0.9995,  0.0000,  0.9995]],

         [[ 0.0000,  0.9995,  0.0000],
          [ 0.0000, -0.9995, -0.9995],
          [-0.9995, -0.9995, -0.9995]],

         [[ 0.0000,  0.9995,  0.0000],
          [ 0.0000,  0.0000, -0.9995],
          [-0.9995, -0.9995,  0.0000]],

         ...,

         [[ 0.0000,  0.9995,  0.9995],
          [ 0.0000, -0.9995, -0.9995],
          [ 0.0000, -0.9995, -0.9995]],

         [[ 0.9995, -0.9995, -0.9995],
          [ 0.0000,  0.9995,  0.0000],
          [-0.9995,  0.0000, -0.9995]],

         [[ 0.9995,  0.0000, -0.9995],
          [ 0.0000,  0.0000,  0.0000],
          [-0.9995, -0.9995,  0.0000]]],


        ...,


        [[[ 0.0000,  0.9995, -0.9995],
          [ 0.0000,  0.0000, -0.9995],
          [ 0.9995,  0.9995, -0.9995]],

         [[ 0.9995,  0.9995,  0.0000],
          [-0.9995,  0.0000,  0.9995],
          [-0.9995,  0.0000,  0.9995]],

         [[ 0.0000,  0.0000, -0.9995],
          [ 0.0000,  0.9995,  0.9995],
          [-0.9995,  0.9995,  0.0000]],

         ...,

         [[-0.9995, -0.9995, -0.9995],
          [ 0.9995, -0.9995, -0.9995],
          [-0.9995,  0.0000, -0.9995]],

         [[ 0.9995,  0.0000, -0.9995],
          [ 0.0000,  0.0000,  0.9995],
          [-0.9995, -0.9995,  0.0000]],

         [[ 0.0000,  0.9995,  0.9995],
          [-0.9995,  0.9995,  0.9995],
          [-0.9995, -0.9995,  0.0000]]],


        [[[ 0.0000, -0.9995,  0.0000],
          [-0.9995,  0.9995,  0.0000],
          [ 0.0000,  0.9995, -0.9995]],

         [[ 0.0000,  0.9995,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.9995,  0.0000, -0.9995]],

         [[ 0.9995,  0.0000,  0.9995],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.9995,  0.9995, -0.9995]],

         ...,

         [[-0.9995, -0.9995,  0.9995],
          [-0.9995,  0.0000, -0.9995],
          [ 0.9995, -0.9995, -0.9995]],

         [[ 0.9995,  0.0000,  0.9995],
          [-0.9995,  0.9995,  0.9995],
          [-0.9995,  0.0000,  0.9995]],

         [[-0.9995,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -0.9995,  0.0000]]],


        [[[-0.9995,  0.9995,  0.0000],
          [-0.9995,  0.0000,  0.0000],
          [-0.9995,  0.0000,  0.9995]],

         [[ 0.9995,  0.9995,  0.9995],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -0.9995]],

         [[-0.9995, -0.9995, -0.9995],
          [ 0.0000,  0.0000,  0.0000],
          [-0.9995, -0.9995,  0.9995]],

         ...,

         [[-0.9995, -0.9995,  0.0000],
          [ 0.9995,  0.0000,  0.0000],
          [ 0.9995,  0.9995,  0.9995]],

         [[ 0.0000,  0.9995,  0.9995],
          [ 0.9995,  0.9995,  0.9995],
          [-0.9995, -0.9995,  0.9995]],

         [[ 0.9995,  0.9995,  0.9995],
          [ 0.9995,  0.0000,  0.0000],
          [-0.9995, -0.9995, -0.9995]]]], device='cuda:0', requires_grad=True)
Param: encoder.layer1.1.bn1.weight
	Parameter containing:
tensor([0.8605, 0.9410, 0.8968, 1.0439, 0.9174, 0.8962, 1.0973, 1.0191, 1.0253,
        1.0369, 1.0875, 1.0208, 0.9334, 0.8253, 1.0075, 0.9373, 0.8978, 1.0114,
        1.1366, 0.9293, 1.0476, 0.8754, 1.1095, 0.8903, 1.0265, 0.9095, 0.8863,
        1.0009, 0.8851, 1.2229, 1.1650, 0.9516, 0.9695, 0.9192, 0.9848, 1.0569,
        0.9088, 0.8768, 0.9826, 0.9277, 1.0402, 0.8460, 1.0084, 0.9315, 1.0114,
        1.1594, 0.7575, 1.0208, 1.0303, 0.8468, 0.9711, 0.9992, 0.8571, 0.9122,
        0.8896, 0.9994, 0.9034, 1.0304, 1.1650, 1.1536, 0.9110, 0.9838, 1.0005,
        1.0617], device='cuda:0', requires_grad=True)
Param: encoder.layer1.1.bn1.bias
	Parameter containing:
tensor([-0.0955, -0.2036, -0.2804, -0.1576, -0.1589, -0.2707, -0.2234, -0.2287,
        -0.0991, -0.2472, -0.1807, -0.1218, -0.2159, -0.1682, -0.0723, -0.1284,
        -0.1818, -0.1578,  0.0702, -0.2274, -0.1673, -0.1377, -0.1670, -0.1679,
        -0.1987, -0.0985, -0.2253, -0.1225, -0.2058, -0.1956, -0.2167, -0.1612,
        -0.1370, -0.1332, -0.1449, -0.1063, -0.2884, -0.1287, -0.2294, -0.2942,
        -0.1164, -0.2779, -0.1979, -0.0686, -0.2326, -0.1562, -0.2876, -0.1112,
        -0.1150, -0.2893, -0.1499, -0.1775, -0.2561, -0.1062, -0.1619, -0.1303,
        -0.1380, -0.0597, -0.1427, -0.1909, -0.1998, -0.1211, -0.2408, -0.2009],
       device='cuda:0', requires_grad=True)
Param: encoder.layer1.1.conv2.weight
	Parameter containing:
tensor([[[[ 0.0000,  1.0020,  1.0020],
          [-1.0020,  0.0000,  0.0000],
          [ 1.0020,  0.0000,  0.0000]],

         [[-1.0020,  1.0020,  0.0000],
          [-1.0020,  1.0020,  1.0020],
          [-1.0020,  1.0020,  0.0000]],

         [[ 1.0020,  0.0000,  0.0000],
          [ 0.0000,  1.0020,  0.0000],
          [ 0.0000,  1.0020,  0.0000]],

         ...,

         [[ 0.0000, -1.0020, -1.0020],
          [ 0.0000,  0.0000,  0.0000],
          [-1.0020,  1.0020, -1.0020]],

         [[ 0.0000,  1.0020,  1.0020],
          [ 1.0020,  1.0020,  0.0000],
          [ 1.0020, -1.0020,  0.0000]],

         [[ 0.0000, -1.0020,  1.0020],
          [-1.0020, -1.0020,  0.0000],
          [-1.0020,  1.0020,  0.0000]]],


        [[[ 0.0000,  1.0020,  0.0000],
          [ 0.0000,  0.0000, -1.0020],
          [ 0.0000,  0.0000, -1.0020]],

         [[ 0.0000,  0.0000, -1.0020],
          [-1.0020, -1.0020, -1.0020],
          [ 0.0000,  0.0000, -1.0020]],

         [[ 0.0000, -1.0020, -1.0020],
          [ 0.0000,  0.0000,  1.0020],
          [-1.0020,  0.0000,  1.0020]],

         ...,

         [[ 1.0020, -1.0020,  0.0000],
          [ 1.0020,  0.0000,  0.0000],
          [ 1.0020,  0.0000,  1.0020]],

         [[-1.0020,  0.0000,  1.0020],
          [-1.0020,  0.0000,  0.0000],
          [ 0.0000, -1.0020, -1.0020]],

         [[-1.0020,  0.0000,  1.0020],
          [ 1.0020,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  1.0020,  0.0000],
          [ 1.0020,  0.0000, -1.0020],
          [ 1.0020,  0.0000, -1.0020]],

         [[ 1.0020, -1.0020,  1.0020],
          [ 1.0020, -1.0020,  0.0000],
          [ 1.0020,  1.0020,  1.0020]],

         [[ 0.0000, -1.0020, -1.0020],
          [-1.0020, -1.0020, -1.0020],
          [-1.0020,  0.0000,  0.0000]],

         ...,

         [[-1.0020, -1.0020, -1.0020],
          [-1.0020, -1.0020, -1.0020],
          [-1.0020, -1.0020, -1.0020]],

         [[ 0.0000,  0.0000,  0.0000],
          [-1.0020,  1.0020, -1.0020],
          [ 1.0020,  1.0020, -1.0020]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0020,  0.0000],
          [ 0.0000, -1.0020, -1.0020]]],


        ...,


        [[[ 0.0000,  0.0000,  1.0020],
          [-1.0020, -1.0020,  1.0020],
          [ 1.0020,  0.0000,  0.0000]],

         [[ 0.0000, -1.0020, -1.0020],
          [ 0.0000,  1.0020, -1.0020],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 1.0020,  0.0000, -1.0020],
          [ 0.0000,  0.0000,  0.0000]],

         ...,

         [[ 1.0020,  1.0020, -1.0020],
          [ 1.0020,  1.0020,  1.0020],
          [ 0.0000,  1.0020,  1.0020]],

         [[-1.0020, -1.0020, -1.0020],
          [-1.0020,  0.0000, -1.0020],
          [ 0.0000, -1.0020,  0.0000]],

         [[ 0.0000,  0.0000, -1.0020],
          [ 0.0000,  0.0000, -1.0020],
          [-1.0020,  1.0020,  0.0000]]],


        [[[-1.0020, -1.0020, -1.0020],
          [ 0.0000,  0.0000, -1.0020],
          [ 1.0020,  0.0000,  0.0000]],

         [[ 0.0000, -1.0020, -1.0020],
          [ 1.0020,  0.0000, -1.0020],
          [ 0.0000, -1.0020,  0.0000]],

         [[ 1.0020,  1.0020, -1.0020],
          [ 0.0000,  1.0020,  0.0000],
          [-1.0020, -1.0020,  0.0000]],

         ...,

         [[ 0.0000, -1.0020,  0.0000],
          [ 0.0000,  1.0020, -1.0020],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 1.0020,  0.0000,  1.0020],
          [-1.0020, -1.0020, -1.0020],
          [-1.0020,  0.0000, -1.0020]],

         [[ 0.0000, -1.0020, -1.0020],
          [ 0.0000, -1.0020, -1.0020],
          [-1.0020,  0.0000,  0.0000]]],


        [[[-1.0020, -1.0020,  0.0000],
          [-1.0020, -1.0020,  1.0020],
          [-1.0020,  0.0000,  0.0000]],

         [[ 1.0020, -1.0020,  0.0000],
          [ 1.0020, -1.0020, -1.0020],
          [ 0.0000, -1.0020,  0.0000]],

         [[ 1.0020,  1.0020,  0.0000],
          [ 1.0020,  1.0020,  1.0020],
          [ 0.0000,  0.0000,  1.0020]],

         ...,

         [[ 0.0000, -1.0020,  1.0020],
          [ 0.0000,  1.0020,  0.0000],
          [ 1.0020,  0.0000,  1.0020]],

         [[ 1.0020,  0.0000,  1.0020],
          [ 0.0000,  0.0000,  0.0000],
          [ 1.0020,  0.0000,  0.0000]],

         [[-1.0020, -1.0020, -1.0020],
          [ 0.0000, -1.0020, -1.0020],
          [-1.0020,  1.0020,  0.0000]]]], device='cuda:0', requires_grad=True)
Param: encoder.layer1.1.bn2.weight
	Parameter containing:
tensor([0.5689, 0.7823, 0.7651, 0.6960, 0.7040, 0.7704, 0.7559, 0.8168, 0.6423,
        0.6424, 0.8359, 0.7416, 0.8682, 0.7130, 0.7419, 0.8572, 0.7904, 0.8255,
        0.8289, 0.8055, 0.8193, 0.7475, 0.7185, 0.7498, 0.8231, 0.7570, 0.8058,
        0.7284, 0.6853, 0.6071, 0.8106, 0.8250, 0.7802, 0.7951, 0.9323, 0.8167,
        0.8468, 0.6481, 0.7981, 0.6137, 0.8515, 0.7690, 0.6933, 0.6300, 0.7055,
        0.7953, 0.8763, 0.7715, 0.7633, 0.7279, 0.8600, 0.6930, 0.7444, 0.6646,
        0.7577, 0.8180, 0.7064, 0.6452, 0.8597, 0.7074, 0.6883, 0.8318, 0.8222,
        0.8037], device='cuda:0', requires_grad=True)
Param: encoder.layer1.1.bn2.bias
	Parameter containing:
tensor([-0.2479, -0.2895, -0.2576, -0.2999, -0.3265, -0.2401, -0.3584, -0.3076,
        -0.3091, -0.2878, -0.2277, -0.2230, -0.2736, -0.3244, -0.1939, -0.3497,
        -0.2321, -0.2578, -0.1893, -0.1457, -0.1862, -0.2397, -0.2931, -0.1950,
        -0.2121, -0.3689, -0.1762, -0.0573, -0.2685, -0.2950, -0.1842, -0.3116,
        -0.3520, -0.2037, -0.2200, -0.3875, -0.1472, -0.2624, -0.2727, -0.2776,
        -0.3095, -0.3407, -0.3326, -0.1597, -0.2244, -0.1886, -0.2152, -0.2229,
        -0.2352, -0.1390, -0.3005, -0.2187, -0.1804, -0.2370, -0.2078, -0.3229,
        -0.3230, -0.1172, -0.2515, -0.3862, -0.2227, -0.1416, -0.1418, -0.1931],
       device='cuda:0', requires_grad=True)
Param: encoder.layer2.0.conv1.weight
	Parameter containing:
tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 1.0000,  1.0000,  0.0000],
          [ 1.0000,  0.0000,  1.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0000, -1.0000],
          [ 1.0000,  0.0000,  1.0000]],

         [[ 0.0000,  1.0000,  0.0000],
          [ 1.0000,  0.0000,  0.0000],
          [-1.0000,  0.0000,  1.0000]],

         ...,

         [[-1.0000,  1.0000,  0.0000],
          [ 0.0000,  1.0000, -1.0000],
          [-1.0000, -1.0000,  1.0000]],

         [[ 0.0000, -1.0000,  1.0000],
          [-1.0000, -1.0000,  1.0000],
          [ 0.0000,  1.0000,  0.0000]],

         [[ 0.0000, -1.0000, -1.0000],
          [ 0.0000,  0.0000, -1.0000],
          [ 0.0000,  1.0000, -1.0000]]],


        [[[-1.0000,  1.0000,  0.0000],
          [ 0.0000,  0.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 1.0000,  1.0000,  0.0000]],

         [[ 0.0000, -1.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0000,  0.0000]],

         ...,

         [[ 0.0000,  1.0000,  0.0000],
          [ 1.0000,  1.0000,  0.0000],
          [ 1.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000, -1.0000],
          [ 0.0000,  1.0000,  1.0000],
          [ 0.0000,  1.0000, -1.0000]],

         [[-1.0000, -1.0000, -1.0000],
          [ 0.0000,  0.0000, -1.0000],
          [ 1.0000,  0.0000, -1.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  1.0000]],

         [[ 1.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [-1.0000, -1.0000, -1.0000]],

         [[ 0.0000, -1.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  1.0000],
          [-1.0000,  1.0000,  1.0000]],

         [[ 0.0000,  0.0000,  1.0000],
          [-1.0000,  1.0000,  1.0000],
          [-1.0000,  0.0000,  1.0000]],

         [[-1.0000, -1.0000,  0.0000],
          [ 0.0000,  1.0000, -1.0000],
          [-1.0000,  0.0000, -1.0000]]],


        ...,


        [[[-1.0000, -1.0000, -1.0000],
          [-1.0000,  0.0000, -1.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[-1.0000,  1.0000,  0.0000],
          [-1.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0000,  0.0000]],

         [[ 0.0000,  0.0000, -1.0000],
          [ 1.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 1.0000,  1.0000, -1.0000],
          [ 0.0000, -1.0000,  1.0000]],

         [[-1.0000,  0.0000, -1.0000],
          [ 1.0000,  1.0000, -1.0000],
          [ 0.0000, -1.0000,  0.0000]],

         [[ 1.0000,  1.0000, -1.0000],
          [ 1.0000,  0.0000, -1.0000],
          [-1.0000, -1.0000, -1.0000]]],


        [[[ 0.0000,  0.0000, -1.0000],
          [-1.0000,  0.0000, -1.0000],
          [ 0.0000,  1.0000, -1.0000]],

         [[ 0.0000,  0.0000, -1.0000],
          [ 0.0000,  1.0000,  0.0000],
          [-1.0000, -1.0000, -1.0000]],

         [[ 0.0000, -1.0000, -1.0000],
          [ 1.0000,  0.0000,  1.0000],
          [ 1.0000,  0.0000,  0.0000]],

         ...,

         [[-1.0000,  1.0000,  1.0000],
          [ 0.0000,  0.0000,  1.0000],
          [ 0.0000,  0.0000, -1.0000]],

         [[-1.0000, -1.0000,  0.0000],
          [ 1.0000,  0.0000, -1.0000],
          [-1.0000, -1.0000,  0.0000]],

         [[-1.0000, -1.0000,  0.0000],
          [-1.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0000, -1.0000]]],


        [[[ 1.0000,  0.0000,  1.0000],
          [ 0.0000, -1.0000,  1.0000],
          [ 1.0000,  0.0000,  0.0000]],

         [[ 0.0000, -1.0000,  0.0000],
          [ 1.0000,  1.0000,  0.0000],
          [ 0.0000,  1.0000,  0.0000]],

         [[-1.0000,  0.0000,  0.0000],
          [ 1.0000,  1.0000, -1.0000],
          [ 1.0000,  1.0000,  0.0000]],

         ...,

         [[ 1.0000, -1.0000,  1.0000],
          [ 0.0000, -1.0000,  1.0000],
          [ 0.0000, -1.0000, -1.0000]],

         [[ 1.0000,  0.0000,  0.0000],
          [ 1.0000, -1.0000,  1.0000],
          [ 1.0000,  0.0000,  0.0000]],

         [[-1.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  1.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0', requires_grad=True)
Param: encoder.layer2.0.bn1.weight
	Parameter containing:
tensor([1.0615, 1.0397, 0.8310, 0.8588, 0.8843, 1.1067, 0.9332, 1.1405, 0.9587,
        0.9631, 1.0444, 0.9435, 0.9959, 0.9336, 0.8669, 1.0775, 0.6919, 0.9513,
        0.7979, 0.9126, 0.7678, 0.8723, 1.1690, 0.9862, 0.8721, 0.9026, 0.8345,
        0.6750, 1.0071, 0.6229, 1.1382, 1.0935, 1.1505, 0.8817, 0.6986, 1.1249,
        0.8082, 0.9694, 1.0032, 0.9475, 0.6605, 1.0478, 0.9655, 0.8064, 0.6796,
        1.0022, 0.9237, 0.7211, 1.2792, 0.5923, 1.0008, 1.1663, 1.2424, 1.0562,
        1.0379, 1.0393, 1.0219, 0.9844, 1.1010, 0.8405, 0.9267, 0.6521, 0.8153,
        0.9558, 0.7775, 1.0095, 0.9406, 0.8770, 0.7756, 0.9026, 1.0414, 0.9560,
        1.2377, 1.0752, 0.5352, 1.0135, 1.0782, 1.0145, 1.0193, 0.9919, 0.8192,
        0.6612, 1.0302, 0.6496, 1.0398, 1.0357, 0.7874, 1.1038, 0.8943, 1.0741,
        0.9642, 0.9696, 1.0947, 1.0372, 1.0916, 1.0210, 0.9923, 0.9092, 1.1671,
        0.8312, 0.8940, 1.0168, 0.9285, 1.0144, 0.8931, 0.7856, 0.7187, 0.7255,
        0.7624, 1.0598, 0.8430, 0.9502, 0.8242, 0.6109, 1.1216, 1.1399, 0.9194,
        0.7337, 1.0222, 0.8792, 0.7042, 1.0421, 0.9168, 0.9849, 0.9662, 0.7974,
        1.2207, 1.2927], device='cuda:0', requires_grad=True)
Param: encoder.layer2.0.bn1.bias
	Parameter containing:
tensor([-0.1657, -0.2039, -0.1947, -0.2158, -0.1896, -0.1402, -0.2596, -0.1422,
        -0.1470, -0.2019, -0.0182, -0.1685, -0.1235, -0.1876, -0.2211, -0.1081,
        -0.3206, -0.1956, -0.1425, -0.2084, -0.2019, -0.1575, -0.1546, -0.2120,
        -0.1839, -0.2572, -0.1370, -0.2735, -0.2259, -0.2586, -0.1731, -0.1142,
        -0.0967, -0.1028, -0.2631, -0.1344, -0.2655, -0.0759, -0.2214, -0.2136,
        -0.3801, -0.1762, -0.1166, -0.1982, -0.3489, -0.1999, -0.2057, -0.1869,
        -0.1981, -0.2306, -0.1142, -0.1988, -0.1894, -0.1446, -0.1829, -0.1188,
        -0.1865, -0.2570, -0.2070, -0.2472, -0.1897, -0.2603, -0.3303, -0.0996,
        -0.1907, -0.1663, -0.2297, -0.1819, -0.2649, -0.2179, -0.2252, -0.1800,
        -0.1821, -0.1588, -0.2833, -0.1842, -0.1082, -0.1850, -0.2192, -0.2354,
        -0.2293, -0.2499, -0.1671, -0.1723, -0.1417, -0.1314, -0.3127, -0.1334,
        -0.1603, -0.1470, -0.1573, -0.2343, -0.1195, -0.1918, -0.1832, -0.2424,
        -0.1178, -0.1080, -0.1800, -0.1977, -0.1132, -0.2576, -0.1286, -0.1244,
        -0.1506, -0.2504, -0.1499, -0.2285, -0.3374, -0.1722, -0.1424, -0.1789,
        -0.1179, -0.3013, -0.2095, -0.1973, -0.2079, -0.1188, -0.1047, -0.1729,
        -0.2495, -0.1964, -0.1527, -0.2432, -0.1819, -0.2277, -0.2472, -0.0783],
       device='cuda:0', requires_grad=True)
Param: encoder.layer2.0.conv2.weight
	Parameter containing:
tensor([[[[ 1.0007,  1.0007, -1.0007],
          [ 0.0000,  0.0000,  1.0007],
          [ 1.0007,  0.0000,  1.0007]],

         [[ 0.0000,  0.0000, -1.0007],
          [ 0.0000, -1.0007,  0.0000],
          [ 0.0000, -1.0007, -1.0007]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 1.0007,  0.0000,  0.0000],
          [ 0.0000, -1.0007, -1.0007]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [-1.0007, -1.0007, -1.0007],
          [ 1.0007,  0.0000,  0.0000]],

         [[ 0.0000, -1.0007, -1.0007],
          [ 0.0000,  1.0007,  1.0007],
          [ 0.0000,  0.0000,  1.0007]],

         [[-1.0007,  1.0007,  0.0000],
          [ 1.0007,  0.0000,  1.0007],
          [ 0.0000,  0.0000, -1.0007]]],


        [[[ 1.0007,  0.0000, -1.0007],
          [ 1.0007,  0.0000,  0.0000],
          [ 1.0007,  0.0000,  1.0007]],

         [[ 1.0007, -1.0007, -1.0007],
          [-1.0007,  0.0000,  0.0000],
          [ 0.0000,  1.0007, -1.0007]],

         [[-1.0007,  0.0000,  0.0000],
          [ 1.0007,  1.0007,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         ...,

         [[-1.0007,  1.0007, -1.0007],
          [-1.0007,  0.0000,  1.0007],
          [-1.0007,  0.0000, -1.0007]],

         [[-1.0007,  0.0000, -1.0007],
          [-1.0007,  1.0007,  0.0000],
          [ 0.0000,  0.0000, -1.0007]],

         [[ 0.0000, -1.0007,  1.0007],
          [ 0.0000, -1.0007, -1.0007],
          [ 0.0000, -1.0007,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 1.0007, -1.0007,  0.0000],
          [-1.0007,  1.0007,  1.0007]],

         [[ 1.0007,  0.0000,  1.0007],
          [ 0.0000,  0.0000,  0.0000],
          [-1.0007,  0.0000,  1.0007]],

         [[ 0.0000, -1.0007, -1.0007],
          [-1.0007,  0.0000,  1.0007],
          [ 0.0000,  0.0000,  1.0007]],

         ...,

         [[ 0.0000, -1.0007, -1.0007],
          [-1.0007,  0.0000,  1.0007],
          [ 0.0000,  1.0007,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0007, -1.0007],
          [ 0.0000,  1.0007,  0.0000]],

         [[ 0.0000, -1.0007,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0000,  0.0000,  1.0007],
          [ 0.0000,  1.0007,  1.0007],
          [-1.0007,  0.0000, -1.0007]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0007,  1.0007],
          [-1.0007, -1.0007,  0.0000]],

         [[ 0.0000, -1.0007,  0.0000],
          [ 0.0000,  0.0000, -1.0007],
          [ 0.0000,  1.0007,  0.0000]],

         ...,

         [[ 1.0007,  0.0000,  0.0000],
          [-1.0007,  0.0000,  0.0000],
          [-1.0007,  0.0000, -1.0007]],

         [[ 0.0000,  0.0000,  1.0007],
          [ 1.0007, -1.0007,  0.0000],
          [ 0.0000,  1.0007,  1.0007]],

         [[ 0.0000, -1.0007, -1.0007],
          [ 0.0000,  1.0007,  1.0007],
          [ 0.0000,  0.0000, -1.0007]]],


        [[[ 0.0000, -1.0007,  0.0000],
          [ 0.0000,  0.0000, -1.0007],
          [ 1.0007,  0.0000,  0.0000]],

         [[ 0.0000, -1.0007, -1.0007],
          [ 0.0000,  0.0000, -1.0007],
          [ 1.0007,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  1.0007],
          [ 1.0007, -1.0007,  1.0007],
          [-1.0007,  0.0000, -1.0007]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [-1.0007,  0.0000,  0.0000],
          [-1.0007,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  1.0007],
          [ 0.0000,  0.0000,  0.0000],
          [ 1.0007, -1.0007, -1.0007]],

         [[-1.0007,  0.0000, -1.0007],
          [ 0.0000, -1.0007,  0.0000],
          [ 0.0000,  1.0007,  1.0007]]],


        [[[ 1.0007,  0.0000,  0.0000],
          [-1.0007,  0.0000,  0.0000],
          [ 1.0007,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000, -1.0007],
          [ 0.0000, -1.0007,  0.0000],
          [ 1.0007,  0.0000, -1.0007]],

         [[-1.0007, -1.0007,  0.0000],
          [ 0.0000, -1.0007, -1.0007],
          [ 0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000, -1.0007,  0.0000],
          [ 0.0000, -1.0007,  0.0000],
          [-1.0007,  0.0000,  0.0000]],

         [[ 1.0007, -1.0007, -1.0007],
          [ 0.0000,  1.0007,  0.0000],
          [ 0.0000, -1.0007,  0.0000]],

         [[ 0.0000,  1.0007,  0.0000],
          [ 0.0000,  1.0007, -1.0007],
          [ 1.0007, -1.0007,  0.0000]]]], device='cuda:0', requires_grad=True)
Param: encoder.layer2.0.bn2.weight
	Parameter containing:
tensor([0.8982, 0.9192, 1.0642, 0.9895, 0.9002, 0.9711, 1.0365, 0.9718, 0.9227,
        0.8737, 1.0276, 0.8680, 0.9459, 0.9416, 0.9893, 0.8624, 0.9764, 0.8786,
        0.9248, 0.8780, 1.0365, 0.9653, 1.1365, 1.1515, 0.7742, 0.8421, 1.0241,
        1.0668, 0.9916, 0.8828, 1.0262, 0.9067, 0.9477, 0.8400, 0.9029, 1.0264,
        1.1235, 0.8928, 0.9402, 0.7973, 0.8119, 0.9154, 0.9313, 0.8478, 0.8634,
        1.0862, 0.8938, 0.9002, 0.8684, 1.0889, 0.8980, 0.7581, 0.8831, 0.7839,
        0.9323, 0.9763, 0.9707, 0.8384, 0.9261, 0.9058, 0.9190, 0.9900, 0.9552,
        0.8075, 0.9779, 0.9341, 1.0935, 0.9695, 0.9257, 1.0530, 1.0825, 1.1898,
        0.9895, 0.8197, 0.8734, 0.9537, 0.9447, 0.9688, 0.9583, 0.8121, 0.8375,
        0.8072, 0.9024, 0.7737, 0.8444, 0.8523, 0.9095, 1.1544, 0.8816, 1.0133,
        1.0244, 0.9733, 1.0437, 0.9169, 0.9063, 1.0158, 0.9667, 0.7143, 0.9765,
        0.8562, 0.9256, 1.0012, 0.8221, 0.7540, 1.0246, 0.8850, 1.0672, 0.9064,
        0.8744, 0.8305, 0.8440, 0.9606, 1.1083, 0.9183, 0.8295, 1.0368, 1.1027,
        0.9357, 0.7682, 1.0165, 0.9922, 0.9285, 1.0695, 1.0667, 0.8394, 1.0411,
        0.8986, 0.8735], device='cuda:0', requires_grad=True)
Param: encoder.layer2.0.bn2.bias
	Parameter containing:
tensor([-1.1654e-02, -4.1522e-02,  6.9850e-02,  3.1803e-02, -6.7043e-02,
        -6.1858e-02,  2.3498e-02, -5.3363e-02, -1.3868e-02, -6.7242e-02,
        -3.5210e-02, -2.8820e-02, -2.9287e-02,  6.0734e-02, -1.2053e-02,
         4.3909e-02, -3.8797e-02,  2.7228e-02, -1.0999e-02, -6.5044e-02,
        -4.6210e-02,  1.2420e-02, -2.2852e-02,  1.0525e-01, -2.0340e-01,
        -2.7437e-02,  3.7901e-02,  8.6083e-02,  2.0847e-02, -6.7052e-02,
        -6.5073e-03, -1.1480e-01,  1.6079e-03, -1.5292e-01, -1.8615e-01,
        -3.1900e-02, -9.6469e-03, -1.6494e-02, -3.6947e-02, -2.5548e-02,
        -1.1182e-01, -1.2553e-01, -6.2313e-02, -1.2594e-01, -6.4318e-02,
        -2.6891e-02, -1.1452e-01, -1.4177e-01, -9.5505e-02,  1.8758e-02,
        -5.5776e-02, -4.5396e-02, -1.0511e-01, -2.2336e-03, -6.9899e-02,
         4.0602e-02,  8.8361e-03, -3.9553e-02, -1.1886e-01, -8.1239e-02,
        -3.1767e-02, -4.3974e-02,  5.8626e-03, -8.9030e-02,  6.1043e-02,
        -8.2538e-02,  3.1859e-03, -1.1418e-01,  2.8371e-02, -2.8528e-02,
        -3.4100e-02,  1.1812e-01, -2.7419e-02, -8.3396e-02, -3.6241e-02,
        -2.9171e-03, -1.1088e-01, -4.6996e-02, -7.5110e-02, -1.4675e-04,
        -9.8986e-02, -8.6855e-02, -7.3818e-02, -2.3339e-02, -1.6451e-01,
        -1.3816e-01, -6.9221e-02,  1.1503e-01, -4.6768e-02, -4.0806e-02,
        -2.7212e-02, -1.0780e-01, -5.9421e-02, -4.0470e-02, -8.4996e-02,
        -1.3308e-02, -7.8877e-02, -1.4736e-01,  5.4409e-02, -1.8511e-01,
        -7.3766e-02, -1.4154e-02, -9.8466e-02, -7.8395e-02,  1.8496e-02,
        -1.0934e-01,  3.2195e-02, -3.8767e-02, -6.1744e-02,  6.3391e-02,
        -4.0253e-02, -3.1533e-02, -5.0359e-03, -7.8363e-02, -1.9159e-01,
        -3.5942e-03,  5.8054e-02, -3.7754e-02, -1.5902e-01, -1.0979e-01,
         2.8039e-04, -5.8018e-02,  7.2782e-03,  1.4692e-03, -1.6094e-01,
         3.3993e-02, -7.2958e-02, -1.1978e-05], device='cuda:0',
       requires_grad=True)
Param: encoder.layer2.0.shortcut.0.weight
	Parameter containing:
tensor([[[[ 0.0177]],

         [[-0.2075]],

         [[-0.1056]],

         ...,

         [[ 0.2077]],

         [[ 0.0321]],

         [[-0.1387]]],


        [[[-0.0343]],

         [[-0.0651]],

         [[ 0.1318]],

         ...,

         [[ 0.1540]],

         [[ 0.1936]],

         [[ 0.0279]]],


        [[[-0.1168]],

         [[-0.1542]],

         [[-0.0906]],

         ...,

         [[ 0.0281]],

         [[-0.0599]],

         [[-0.0941]]],


        ...,


        [[[ 0.1102]],

         [[-0.0966]],

         [[-0.1749]],

         ...,

         [[-0.0245]],

         [[-0.0289]],

         [[-0.1531]]],


        [[[ 0.0395]],

         [[-0.0131]],

         [[-0.1237]],

         ...,

         [[-0.0200]],

         [[-0.1499]],

         [[-0.0342]]],


        [[[-0.0899]],

         [[ 0.0718]],

         [[ 0.1598]],

         ...,

         [[-0.0658]],

         [[-0.0920]],

         [[-0.1483]]]], device='cuda:0', requires_grad=True)
Param: encoder.layer2.0.shortcut.1.weight
	Parameter containing:
tensor([1.0936, 0.8940, 1.0801, 1.0849, 1.2039, 1.1029, 1.0665, 0.9806, 1.2470,
        1.2377, 0.9327, 1.2096, 0.9154, 1.0510, 0.9246, 1.1605, 0.9676, 1.2245,
        1.0259, 1.0177, 1.0037, 1.0526, 1.0103, 1.0499, 0.9491, 1.1839, 1.0192,
        0.9437, 1.1310, 1.1626, 1.1926, 1.0712, 1.1127, 0.9919, 1.1474, 1.2013,
        1.1313, 1.0268, 1.1499, 0.9827, 1.1394, 1.1913, 1.0578, 0.9928, 1.1183,
        1.1519, 1.1523, 1.1070, 1.2322, 0.8817, 1.0600, 1.0209, 1.1761, 0.9621,
        1.0946, 1.0285, 0.9206, 1.1521, 1.1412, 1.1973, 0.8401, 1.0404, 1.2070,
        1.0540, 1.2317, 1.2543, 1.0912, 1.1538, 1.1290, 1.0935, 1.1434, 0.9332,
        1.2189, 1.1341, 1.0358, 1.0397, 1.1169, 0.9528, 1.1099, 1.1281, 1.2418,
        1.0999, 1.0558, 1.0658, 1.1171, 1.0456, 1.1004, 0.9264, 1.3430, 1.0753,
        1.1001, 1.0397, 1.2369, 1.1083, 1.2123, 1.0288, 1.1207, 1.1201, 1.1719,
        1.1312, 1.0439, 1.0431, 1.1086, 1.0263, 1.3307, 1.0895, 0.8621, 1.0309,
        1.1118, 1.2995, 1.3112, 1.0717, 0.8846, 1.2950, 1.1143, 0.8990, 1.0510,
        1.1654, 1.1395, 1.0904, 1.0841, 0.9525, 1.2903, 1.0237, 1.0446, 1.0967,
        0.9271, 1.0857], device='cuda:0', requires_grad=True)
Param: encoder.layer2.0.shortcut.1.bias
	Parameter containing:
tensor([-1.1654e-02, -4.1522e-02,  6.9850e-02,  3.1803e-02, -6.7043e-02,
        -6.1858e-02,  2.3498e-02, -5.3363e-02, -1.3868e-02, -6.7242e-02,
        -3.5210e-02, -2.8820e-02, -2.9287e-02,  6.0734e-02, -1.2053e-02,
         4.3909e-02, -3.8797e-02,  2.7228e-02, -1.0999e-02, -6.5044e-02,
        -4.6210e-02,  1.2420e-02, -2.2852e-02,  1.0525e-01, -2.0340e-01,
        -2.7437e-02,  3.7901e-02,  8.6083e-02,  2.0847e-02, -6.7052e-02,
        -6.5073e-03, -1.1480e-01,  1.6079e-03, -1.5292e-01, -1.8615e-01,
        -3.1900e-02, -9.6469e-03, -1.6494e-02, -3.6947e-02, -2.5548e-02,
        -1.1182e-01, -1.2553e-01, -6.2313e-02, -1.2594e-01, -6.4318e-02,
        -2.6891e-02, -1.1452e-01, -1.4177e-01, -9.5505e-02,  1.8758e-02,
        -5.5776e-02, -4.5396e-02, -1.0511e-01, -2.2336e-03, -6.9899e-02,
         4.0602e-02,  8.8361e-03, -3.9553e-02, -1.1886e-01, -8.1239e-02,
        -3.1767e-02, -4.3974e-02,  5.8626e-03, -8.9030e-02,  6.1043e-02,
        -8.2538e-02,  3.1859e-03, -1.1418e-01,  2.8371e-02, -2.8528e-02,
        -3.4100e-02,  1.1812e-01, -2.7419e-02, -8.3396e-02, -3.6241e-02,
        -2.9171e-03, -1.1088e-01, -4.6996e-02, -7.5110e-02, -1.4675e-04,
        -9.8986e-02, -8.6855e-02, -7.3818e-02, -2.3339e-02, -1.6451e-01,
        -1.3816e-01, -6.9221e-02,  1.1503e-01, -4.6768e-02, -4.0806e-02,
        -2.7212e-02, -1.0780e-01, -5.9421e-02, -4.0470e-02, -8.4996e-02,
        -1.3308e-02, -7.8877e-02, -1.4736e-01,  5.4409e-02, -1.8511e-01,
        -7.3766e-02, -1.4154e-02, -9.8466e-02, -7.8395e-02,  1.8496e-02,
        -1.0934e-01,  3.2195e-02, -3.8767e-02, -6.1744e-02,  6.3391e-02,
        -4.0253e-02, -3.1533e-02, -5.0359e-03, -7.8363e-02, -1.9159e-01,
        -3.5942e-03,  5.8054e-02, -3.7754e-02, -1.5902e-01, -1.0979e-01,
         2.8039e-04, -5.8018e-02,  7.2782e-03,  1.4692e-03, -1.6094e-01,
         3.3993e-02, -7.2958e-02, -1.1978e-05], device='cuda:0',
       requires_grad=True)
Param: encoder.layer2.1.conv1.weight
	Parameter containing:
tensor([[[[-1.0001, -1.0001,  0.0000],
          [ 0.0000, -1.0001,  0.0000],
          [ 0.0000,  0.0000,  1.0001]],

         [[-1.0001,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  1.0001],
          [-1.0001,  0.0000,  0.0000]],

         [[-1.0001,  0.0000,  0.0000],
          [-1.0001, -1.0001,  1.0001],
          [-1.0001,  1.0001,  1.0001]],

         ...,

         [[-1.0001, -1.0001, -1.0001],
          [-1.0001,  0.0000,  1.0001],
          [ 0.0000,  0.0000, -1.0001]],

         [[ 0.0000,  0.0000,  1.0001],
          [-1.0001,  0.0000,  0.0000],
          [ 0.0000, -1.0001,  1.0001]],

         [[ 0.0000,  1.0001,  0.0000],
          [ 0.0000,  0.0000,  1.0001],
          [ 0.0000,  1.0001,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 1.0001,  1.0001,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -1.0001],
          [ 1.0001,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  1.0001],
          [ 0.0000,  0.0000, -1.0001],
          [ 0.0000,  1.0001,  1.0001]],

         ...,

         [[ 0.0000,  0.0000,  1.0001],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  1.0001]],

         [[ 0.0000,  1.0001,  1.0001],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -1.0001]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0001, -1.0001],
          [-1.0001,  1.0001,  0.0000]]],


        [[[ 0.0000, -1.0001, -1.0001],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  1.0001,  0.0000],
          [ 1.0001, -1.0001,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  1.0001,  0.0000],
          [ 0.0000,  0.0000, -1.0001],
          [ 1.0001,  1.0001,  0.0000]]],


        ...,


        [[[-1.0001, -1.0001, -1.0001],
          [-1.0001,  0.0000,  1.0001],
          [ 1.0001,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  1.0001]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 1.0001,  0.0000,  0.0000],
          [ 0.0000, -1.0001,  1.0001]],

         ...,

         [[ 1.0001,  0.0000,  1.0001],
          [ 0.0000, -1.0001,  0.0000],
          [ 0.0000,  0.0000,  1.0001]],

         [[ 0.0000,  0.0000,  0.0000],
          [-1.0001, -1.0001,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0001,  1.0001],
          [ 0.0000,  1.0001,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 1.0001,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000, -1.0001],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 1.0001,  1.0001,  1.0001],
          [-1.0001, -1.0001, -1.0001],
          [ 1.0001,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  1.0001],
          [ 0.0000, -1.0001,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  1.0001],
          [ 0.0000,  0.0000, -1.0001]],

         [[ 0.0000,  0.0000, -1.0001],
          [ 0.0000,  0.0000,  0.0000],
          [-1.0001,  1.0001,  0.0000]]],


        [[[ 0.0000,  0.0000,  1.0001],
          [ 0.0000,  0.0000,  0.0000],
          [ 1.0001,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  1.0001],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  1.0001,  1.0001],
          [ 0.0000, -1.0001, -1.0001],
          [ 0.0000,  1.0001,  1.0001]],

         ...,

         [[ 0.0000,  1.0001,  1.0001],
          [-1.0001,  0.0000, -1.0001],
          [ 1.0001,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -1.0001]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  1.0001]]]], device='cuda:0', requires_grad=True)
Param: encoder.layer2.1.bn1.weight
	Parameter containing:
tensor([1.0368, 0.8794, 1.2322, 0.8698, 0.9201, 0.9816, 1.0207, 1.1524, 1.0157,
        1.2221, 1.0460, 1.0592, 1.1675, 0.9546, 1.0964, 1.1684, 1.0754, 1.1669,
        1.1191, 1.0004, 1.1345, 0.8474, 1.1137, 1.0116, 0.8495, 0.9614, 0.9330,
        0.9747, 0.9741, 1.0921, 0.9178, 1.2088, 0.9490, 1.1639, 1.1820, 1.0439,
        1.0515, 1.1769, 1.0719, 0.9971, 0.8523, 1.1098, 0.8642, 0.8419, 0.9534,
        1.0986, 1.0339, 0.9543, 1.0234, 1.1727, 0.7904, 0.9826, 0.9450, 0.8179,
        0.9286, 1.0897, 1.0174, 0.9625, 1.1654, 1.0744, 0.9390, 0.9226, 1.0095,
        0.9611, 0.8949, 0.9297, 0.9356, 1.1807, 0.9171, 0.9532, 0.8744, 1.0182,
        0.8789, 0.8816, 1.0520, 0.9511, 1.1014, 1.0519, 1.1282, 0.9770, 0.9905,
        1.1747, 0.9086, 0.8963, 0.9705, 0.9674, 0.9806, 0.9965, 0.8883, 1.0558,
        1.0328, 0.9644, 1.0018, 1.1592, 1.0846, 1.1255, 0.9212, 0.9479, 1.1246,
        0.9526, 0.9263, 0.8614, 1.0295, 1.1021, 1.1002, 1.0196, 1.0094, 1.2211,
        0.9076, 1.1243, 0.9425, 0.8581, 0.8809, 0.9210, 1.0288, 1.0704, 0.9077,
        1.1216, 1.0559, 0.9506, 0.9662, 0.9417, 0.9544, 1.0350, 0.9084, 0.9449,
        0.9413, 0.9677], device='cuda:0', requires_grad=True)
Param: encoder.layer2.1.bn1.bias
	Parameter containing:
tensor([ 8.9753e-02,  1.6463e-01,  1.8784e-01,  1.9160e-02,  1.2449e-01,
         4.7800e-02,  7.2095e-02,  1.5934e-01,  3.2965e-02,  1.2897e-01,
         5.8572e-02, -4.1880e-02,  1.6746e-01,  1.0915e-01,  3.3865e-02,
         1.2504e-01, -1.6293e-02,  2.0084e-01,  6.4322e-02,  3.5113e-02,
         1.7049e-01, -4.2910e-02,  1.0477e-01, -1.0452e-01,  1.0223e-01,
        -5.3189e-02, -5.3851e-03,  1.0927e-01,  1.0742e-01,  2.6319e-01,
        -2.5955e-03,  2.8219e-01, -4.5366e-02,  3.5989e-01,  5.6170e-02,
         2.3114e-01, -2.2588e-02,  1.0416e-01,  5.2337e-02,  2.4747e-02,
        -8.0959e-02,  2.6536e-02,  6.6705e-02,  1.5513e-01,  9.4005e-02,
         1.5994e-01,  3.5283e-02, -1.3193e-02,  2.6365e-01,  2.2368e-01,
         1.1749e-01,  1.1162e-01,  6.7643e-02,  8.8704e-02,  1.3326e-01,
         4.0140e-02,  1.3496e-01, -1.0082e-02,  2.2205e-01,  9.5058e-03,
         1.9482e-02,  2.4625e-01,  1.3033e-01, -3.2477e-03,  2.8487e-02,
        -2.8203e-02,  1.1224e-01,  2.3331e-01,  2.7089e-02,  7.5286e-02,
         1.0046e-02,  9.4819e-02, -7.4965e-03,  1.0181e-01, -4.6791e-02,
         3.6854e-02,  2.0711e-01,  8.1880e-02,  1.6669e-01,  2.0214e-01,
         7.6745e-02,  5.1751e-02,  5.6748e-02,  1.0593e-01, -7.3511e-03,
         7.0766e-03, -3.1276e-02,  5.2485e-02,  2.8140e-02,  5.5075e-02,
        -6.8912e-02,  2.0872e-01, -1.3961e-02,  2.4207e-01, -2.5107e-02,
         2.6077e-01,  3.6581e-02, -2.9985e-02,  2.6135e-01,  2.1274e-01,
         1.7064e-01,  1.0389e-01,  7.6675e-02,  1.0840e-04,  6.2275e-02,
         1.1422e-01,  2.6174e-01,  2.7001e-01, -4.7600e-03,  1.1869e-01,
         1.0819e-01,  1.4051e-02,  1.0224e-01,  3.3802e-02, -1.2861e-02,
         9.6543e-02,  1.6379e-02,  8.4431e-03,  1.6248e-01,  1.4866e-01,
         9.8460e-02,  6.7019e-02, -1.8478e-02,  9.9460e-02,  2.0643e-02,
        -5.6697e-02,  1.4040e-01,  6.2865e-02], device='cuda:0',
       requires_grad=True)
Param: encoder.layer2.1.conv2.weight
	Parameter containing:
tensor([[[[ 1.0017,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  1.0017],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [-1.0017, -1.0017, -1.0017],
          [-1.0017, -1.0017,  1.0017]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0017,  0.0000],
          [ 0.0000, -1.0017,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [-1.0017, -1.0017,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -1.0017],
          [-1.0017,  0.0000,  0.0000]],

         [[ 1.0017,  1.0017,  0.0000],
          [ 0.0000,  0.0000,  1.0017],
          [-1.0017,  0.0000, -1.0017]]],


        [[[ 0.0000,  1.0017,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 1.0017, -1.0017,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0017,  0.0000],
          [ 0.0000, -1.0017,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0017,  1.0017],
          [ 0.0000,  0.0000,  1.0017]],

         ...,

         [[ 0.0000,  1.0017,  0.0000],
          [-1.0017,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  1.0017],
          [ 0.0000,  1.0017,  1.0017],
          [ 0.0000,  0.0000,  0.0000]],

         [[-1.0017,  1.0017,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  1.0017],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [-1.0017, -1.0017,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000, -1.0017],
          [ 0.0000, -1.0017,  0.0000],
          [ 0.0000,  0.0000, -1.0017]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [-1.0017,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0017,  0.0000],
          [ 0.0000,  1.0017, -1.0017]],

         [[ 1.0017,  0.0000,  0.0000],
          [-1.0017, -1.0017, -1.0017],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[-1.0017,  0.0000,  0.0000],
          [-1.0017,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000, -1.0017,  0.0000],
          [ 0.0000,  0.0000, -1.0017],
          [ 0.0000,  1.0017,  0.0000]],

         [[ 0.0000,  1.0017, -1.0017],
          [ 0.0000,  0.0000, -1.0017],
          [ 0.0000,  0.0000, -1.0017]],

         ...,

         [[ 0.0000,  0.0000, -1.0017],
          [ 0.0000, -1.0017, -1.0017],
          [ 0.0000,  0.0000, -1.0017]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0017,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0017,  0.0000],
          [ 1.0017,  1.0017,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 1.0017,  0.0000, -1.0017],
          [ 1.0017,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0017,  0.0000],
          [ 0.0000,  0.0000, -1.0017]],

         [[ 0.0000,  0.0000,  1.0017],
          [ 0.0000,  0.0000,  1.0017],
          [ 0.0000,  0.0000,  1.0017]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0017,  0.0000],
          [-1.0017,  0.0000,  0.0000]],

         [[-1.0017,  0.0000,  0.0000],
          [-1.0017,  0.0000,  1.0017],
          [ 0.0000, -1.0017,  0.0000]],

         [[-1.0017,  0.0000,  0.0000],
          [ 1.0017,  0.0000,  1.0017],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000, -1.0017,  0.0000],
          [ 1.0017, -1.0017,  0.0000],
          [ 1.0017,  0.0000,  1.0017]],

         [[-1.0017,  0.0000, -1.0017],
          [ 1.0017,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000, -1.0017,  1.0017],
          [ 0.0000,  0.0000,  1.0017],
          [ 0.0000,  0.0000,  1.0017]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [-1.0017,  1.0017,  0.0000],
          [ 1.0017,  1.0017,  0.0000]],

         [[-1.0017, -1.0017,  0.0000],
          [ 1.0017,  1.0017,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[-1.0017, -1.0017,  0.0000],
          [ 1.0017,  1.0017,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0', requires_grad=True)
Param: encoder.layer2.1.bn2.weight
	Parameter containing:
tensor([0.6704, 0.9028, 0.6838, 0.7743, 0.7021, 0.7163, 0.8049, 0.7703, 0.8299,
        0.7547, 0.8844, 0.9073, 0.7441, 0.6753, 0.7774, 0.6298, 0.7943, 0.8209,
        0.8316, 0.9117, 0.8947, 0.8024, 0.7630, 0.7463, 0.9135, 0.6950, 0.7596,
        0.7843, 0.7720, 0.7829, 0.7421, 0.8994, 0.7328, 0.9199, 0.8944, 0.8509,
        0.7091, 0.8462, 0.8629, 0.7975, 0.9428, 0.8402, 0.8606, 0.8847, 0.7937,
        0.8807, 0.8429, 0.8488, 0.8065, 0.7833, 0.7810, 0.7149, 0.8036, 0.8084,
        0.8132, 0.8034, 0.6869, 0.8330, 0.8651, 0.7885, 0.7701, 0.8742, 0.7256,
        0.8569, 0.8152, 0.7370, 0.7190, 0.8509, 0.7520, 0.8744, 0.7790, 0.9117,
        0.7997, 0.7691, 0.7388, 0.7721, 0.9419, 0.8037, 0.8646, 0.6959, 0.7939,
        0.8693, 0.8368, 0.8018, 0.8650, 0.8753, 0.7575, 0.7911, 0.7441, 0.8598,
        0.8123, 0.8970, 0.7742, 0.8524, 0.9052, 0.7802, 0.8223, 0.7722, 0.7517,
        0.9151, 0.7744, 0.8075, 0.8179, 0.8184, 0.6969, 0.7436, 0.9038, 0.8491,
        0.8641, 0.8458, 0.8615, 0.8367, 0.8329, 0.7399, 0.9424, 0.8189, 0.7592,
        0.7958, 0.9280, 0.8553, 0.8137, 0.8009, 0.7515, 0.7805, 0.9409, 0.7329,
        0.8541, 0.7432], device='cuda:0', requires_grad=True)
Param: encoder.layer2.1.bn2.bias
	Parameter containing:
tensor([ 2.4650e-02, -4.6239e-02, -1.6945e-02,  3.2070e-03, -6.9443e-02,
         1.8251e-02,  6.6077e-02,  4.4959e-02,  4.6276e-02, -6.3102e-02,
         5.2323e-03, -9.8829e-02, -1.9050e-02,  4.7599e-02,  7.2884e-03,
         5.8592e-02,  1.4335e-02, -2.7893e-02,  4.5675e-02, -6.9246e-02,
        -1.3129e-01, -4.5856e-02,  1.6528e-02, -2.0318e-02, -7.2676e-02,
        -6.6194e-03,  8.5579e-02, -1.0416e-02,  2.4086e-02, -1.7287e-02,
         4.1958e-02, -9.0132e-02,  5.3064e-02, -1.3218e-01, -1.3175e-01,
        -7.9382e-02,  4.6935e-02, -7.4218e-02, -1.0966e-02,  1.3053e-02,
        -7.4038e-02, -3.4045e-02,  4.2589e-02, -7.8971e-02, -1.2855e-04,
        -1.3828e-02, -2.0168e-02, -1.0505e-01, -7.0212e-02,  2.6716e-02,
         5.7628e-04,  2.5675e-02,  8.3152e-02,  5.3834e-02, -6.2553e-02,
         8.0904e-02,  5.2970e-02, -1.0457e-01, -1.0856e-01,  1.1075e-02,
         1.6098e-02, -9.9630e-02,  5.2241e-02, -5.1400e-02, -6.0105e-02,
        -1.1406e-01,  6.7610e-02, -7.8057e-02,  2.8887e-02, -5.6223e-02,
        -6.9026e-02,  7.5656e-03, -1.4551e-03, -7.1767e-02,  1.2530e-02,
         1.2128e-01, -4.7886e-02, -1.1924e-01, -2.4253e-02,  5.9617e-02,
        -4.5947e-03, -8.4175e-02, -2.6062e-02, -1.0217e-01, -5.8904e-02,
        -4.9522e-02,  4.0229e-02,  4.2849e-02, -6.1082e-03, -7.7695e-02,
        -2.5687e-03, -1.4193e-01,  5.8302e-02, -4.7658e-02, -3.8418e-02,
        -2.4757e-03, -5.3619e-02, -7.9315e-02, -2.9800e-02, -1.0766e-01,
        -5.7597e-02, -1.4831e-02, -1.8414e-02, -8.7728e-02,  1.5154e-02,
         1.2412e-02,  1.9429e-02, -2.4868e-02, -3.3296e-02, -1.0963e-02,
        -1.9659e-02, -4.3968e-02,  6.1546e-02, -5.9880e-02, -1.1882e-01,
         5.9773e-02,  1.1250e-01, -5.1937e-02, -1.5613e-01, -1.7869e-02,
        -7.1109e-02, -1.0426e-01, -2.7582e-02, -1.7889e-02, -1.3500e-01,
         3.4465e-02, -4.6865e-02,  1.8713e-02], device='cuda:0',
       requires_grad=True)
Param: encoder.layer3.0.conv1.weight
	Parameter containing:
tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0009,  0.0000],
          [ 0.0000, -1.0010, -1.0010]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0009,  0.0000],
          [ 0.0000,  1.0009,  1.0009]],

         [[ 0.0000,  1.0009,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0010,  0.0000]],

         ...,

         [[-1.0010,  0.0000,  0.0000],
          [-1.0010,  0.0000,  0.0000],
          [ 0.0000,  1.0009,  0.0000]],

         [[-1.0010,  0.0000, -1.0010],
          [-1.0010,  0.0000,  0.0000],
          [ 0.0000,  1.0009,  0.0000]],

         [[ 0.0000, -1.0010,  0.0000],
          [ 1.0009,  0.0000,  1.0009],
          [-1.0010,  0.0000,  1.0009]]],


        [[[ 0.0000,  0.0000, -1.0010],
          [-1.0010, -1.0010,  1.0009],
          [ 0.0000,  0.0000, -1.0010]],

         [[ 0.0000,  1.0009, -1.0010],
          [ 0.0000, -1.0010, -1.0010],
          [-1.0010, -1.0010, -1.0010]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0009,  1.0009],
          [ 0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [-1.0010,  0.0000, -1.0010],
          [ 0.0000, -1.0010,  0.0000]],

         [[ 0.0000,  0.0000,  1.0009],
          [-1.0010,  0.0000, -1.0010],
          [ 0.0000,  0.0000,  0.0000]],

         [[-1.0010,  1.0009,  1.0009],
          [ 0.0000,  0.0000,  0.0000],
          [-1.0010, -1.0010,  0.0000]]],


        [[[-1.0010, -1.0010,  1.0009],
          [-1.0010, -1.0010,  1.0009],
          [-1.0010,  0.0000,  1.0009]],

         [[-1.0010,  0.0000,  0.0000],
          [-1.0010,  1.0009,  1.0009],
          [-1.0010,  0.0000,  1.0009]],

         [[ 0.0000,  0.0000, -1.0010],
          [ 0.0000,  0.0000,  1.0009],
          [ 0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000, -1.0010],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000, -1.0010],
          [ 0.0000, -1.0010,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[-1.0010,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0010,  0.0000]]],


        ...,


        [[[ 0.0000, -1.0010,  0.0000],
          [-1.0010,  0.0000, -1.0010],
          [-1.0010,  1.0009,  0.0000]],

         [[ 0.0000, -1.0010,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 1.0009,  1.0009, -1.0010]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0009,  0.0000],
          [ 1.0009,  1.0009,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [-1.0010,  1.0009,  0.0000],
          [ 0.0000, -1.0010,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 1.0009,  0.0000,  0.0000],
          [ 0.0000,  1.0009,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [-1.0010,  1.0009,  0.0000]],

         [[-1.0010,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  1.0009],
          [ 0.0000, -1.0010, -1.0010]],

         [[ 0.0000,  0.0000,  1.0009],
          [ 0.0000,  1.0009,  0.0000],
          [-1.0010,  0.0000,  0.0000]],

         ...,

         [[ 0.0000, -1.0010,  0.0000],
          [-1.0010, -1.0010,  0.0000],
          [ 1.0009,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0010, -1.0010],
          [ 0.0000,  1.0009, -1.0010]],

         [[-1.0010,  0.0000,  1.0009],
          [ 0.0000, -1.0010,  0.0000],
          [ 1.0009,  0.0000, -1.0010]]],


        [[[ 0.0000,  0.0000, -1.0010],
          [ 1.0009,  1.0009, -1.0010],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000, -1.0010],
          [-1.0010, -1.0010,  1.0009],
          [-1.0010, -1.0010, -1.0010]],

         [[-1.0010,  0.0000,  1.0009],
          [ 0.0000, -1.0010, -1.0010],
          [-1.0010,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  1.0009,  0.0000],
          [ 0.0000, -1.0010,  0.0000],
          [ 0.0000, -1.0010,  0.0000]],

         [[-1.0010,  0.0000,  0.0000],
          [-1.0010,  0.0000, -1.0010],
          [ 0.0000, -1.0010, -1.0010]],

         [[ 0.0000,  0.0000,  0.0000],
          [-1.0010,  0.0000,  1.0009],
          [ 0.0000,  0.0000, -1.0010]]]], device='cuda:0', requires_grad=True)
Param: encoder.layer3.0.bn1.weight
	Parameter containing:
tensor([1.0572, 0.9679, 1.0641, 0.9814, 1.0582, 1.0362, 0.9691, 1.0088, 0.9743,
        0.9987, 1.0097, 0.9450, 1.0335, 1.0611, 1.0621, 0.9959, 0.9799, 0.9929,
        1.0301, 1.0178, 1.0192, 1.0561, 0.9275, 1.1290, 1.0053, 0.9812, 0.9729,
        0.9931, 0.9784, 0.9925, 0.9675, 1.0545, 1.0047, 1.0820, 1.0094, 1.0037,
        0.9575, 0.9930, 1.0362, 0.9841, 1.0186, 0.9237, 1.0049, 1.0347, 1.0653,
        1.0730, 0.7337, 0.9104, 1.0219, 0.9690, 0.9809, 0.9165, 1.1354, 1.0492,
        1.0441, 0.9905, 1.0251, 0.9565, 0.9426, 1.0446, 1.0249, 0.8635, 0.9800,
        1.0366, 0.9359, 0.9995, 1.0450, 0.9968, 0.9988, 1.0012, 1.0651, 1.0292,
        1.0013, 1.0713, 1.0420, 1.0087, 1.0171, 0.9686, 0.9797, 0.9928, 1.1058,
        0.9267, 0.9813, 0.9473, 1.0099, 0.9794, 0.9193, 1.0708, 0.9281, 1.0279,
        0.8743, 0.8954, 1.0331, 0.9901, 0.9994, 0.9921, 0.9698, 1.0339, 0.9481,
        1.0431, 0.9720, 0.9115, 0.9796, 1.0296, 0.9714, 1.0200, 1.0810, 1.0623,
        0.9650, 0.9926, 1.0017, 1.0104, 0.9877, 1.0084, 0.9447, 1.0501, 1.0718,
        0.8931, 0.7927, 0.9733, 0.9964, 1.0115, 0.9542, 1.0397, 1.0397, 0.8342,
        0.8960, 0.9739, 0.9690, 0.9190, 1.0049, 1.0049, 1.0036, 0.9428, 0.9825,
        1.0360, 1.0832, 0.8944, 0.9777, 0.9912, 1.0175, 1.0154, 1.1245, 0.9978,
        0.9195, 0.9256, 0.9598, 1.0061, 1.0299, 0.9664, 1.0466, 0.9738, 0.9321,
        0.9801, 0.9238, 1.0188, 1.0659, 0.9483, 0.9961, 0.9392, 0.9826, 0.9543,
        0.9789, 1.0692, 1.0180, 1.0142, 1.0649, 0.9991, 1.0225, 0.8987, 0.9335,
        0.9529, 0.9912, 0.9393, 0.9983, 1.0544, 1.0620, 1.0018, 1.0755, 0.9725,
        1.0153, 0.9432, 0.9470, 0.9786, 0.9132, 1.0424, 0.9387, 0.9230, 1.0165,
        0.9957, 1.0961, 0.9816, 1.0271, 0.9201, 0.9900, 1.0472, 0.9625, 0.8826,
        1.0036, 0.9465, 1.0058, 1.0844, 1.0014, 0.9705, 1.0459, 1.0735, 0.9691,
        1.0206, 1.0380, 0.9221, 1.0394, 1.0375, 0.9481, 1.0041, 1.0109, 1.1281,
        1.0411, 0.9508, 1.0342, 0.9397, 0.9665, 0.9935, 1.0600, 0.9745, 0.9851,
        1.0378, 0.9507, 1.0819, 0.9896, 0.9702, 1.0788, 0.8716, 1.0907, 1.0482,
        0.9527, 0.9889, 0.9331, 0.9297, 0.9411, 0.9457, 1.0178, 0.9668, 0.9037,
        1.0097, 1.0546, 1.0134, 1.0199, 0.9660, 0.9684, 1.0596, 0.9491, 1.0222,
        0.9953, 1.0197, 0.9626, 1.1021], device='cuda:0', requires_grad=True)
Param: encoder.layer3.0.bn1.bias
	Parameter containing:
tensor([ 0.1446,  0.0984,  0.1740, -0.0867,  0.1665,  0.1041,  0.1562,  0.0486,
         0.0748,  0.1194,  0.1150,  0.0659,  0.0772,  0.1233,  0.1899,  0.0861,
         0.0187,  0.1758,  0.0240,  0.1583,  0.0055,  0.0602,  0.0414,  0.1286,
         0.0999,  0.1550,  0.1236,  0.0775,  0.0548,  0.1208,  0.1064,  0.1444,
         0.0616,  0.1192,  0.0523,  0.1166,  0.0623,  0.1597,  0.1768,  0.0774,
         0.0466,  0.1252,  0.1550,  0.0866,  0.0898,  0.1219, -0.1719,  0.0316,
         0.1023,  0.0200,  0.1191,  0.0549,  0.2520,  0.0551, -0.0580,  0.0927,
         0.1361,  0.1417,  0.1011,  0.0466,  0.0520,  0.0997,  0.1490,  0.1808,
         0.0916,  0.0514,  0.1232,  0.1513,  0.1207,  0.0833,  0.0227,  0.1441,
         0.1182,  0.0832,  0.1215,  0.0972,  0.1526,  0.1439,  0.0107,  0.1426,
         0.0135,  0.1212,  0.1077,  0.0915, -0.0412,  0.0543,  0.1111,  0.1784,
         0.0278,  0.0722,  0.1171,  0.0483,  0.1462,  0.0826,  0.1588, -0.0527,
         0.1567,  0.0852, -0.0235,  0.0230,  0.0899,  0.0923,  0.1317,  0.1057,
         0.0537,  0.1058,  0.1239,  0.1798,  0.0909,  0.1886,  0.0543,  0.1010,
         0.1649,  0.0663,  0.1019,  0.1679,  0.0742,  0.0155, -0.0366,  0.0850,
         0.1304,  0.1799,  0.0441,  0.0018,  0.1215, -0.0050,  0.0956,  0.0749,
         0.0777,  0.0145,  0.0180,  0.1021,  0.1751,  0.1863,  0.1289,  0.0931,
         0.1810,  0.0822,  0.0820,  0.1782,  0.1868,  0.1090,  0.1434,  0.2114,
         0.0937,  0.0420,  0.1105,  0.0871,  0.0498,  0.1363,  0.1486,  0.0400,
         0.1122,  0.0704,  0.0762,  0.0441,  0.0553,  0.1374,  0.1292,  0.1254,
         0.1655,  0.0401,  0.1416,  0.1799,  0.1537, -0.0035,  0.1232,  0.0539,
         0.1221, -0.0198,  0.1105,  0.1319,  0.0995,  0.1201,  0.1232,  0.0835,
         0.1285,  0.0983,  0.0721,  0.1029,  0.0715,  0.0446,  0.0407,  0.0965,
         0.1400,  0.1589,  0.1091,  0.0924,  0.0235,  0.1034,  0.1656,  0.0304,
         0.0769,  0.0538,  0.2332,  0.1000,  0.0863, -0.0662, -0.0190,  0.1263,
         0.1208,  0.1294, -0.0035,  0.1279,  0.0429,  0.2058, -0.0199,  0.1278,
         0.0326,  0.0678,  0.0868,  0.1140,  0.1308,  0.0868,  0.2017,  0.1425,
         0.1902,  0.0317,  0.1546,  0.1056,  0.0621, -0.1315,  0.1486,  0.1261,
         0.0627,  0.1607,  0.0467,  0.0785,  0.0657,  0.0728,  0.0139,  0.0069,
         0.2069,  0.2294,  0.1264,  0.1087, -0.0104,  0.0794,  0.1421,  0.0592,
        -0.0293,  0.1568, -0.1012,  0.0936, -0.0559,  0.1219,  0.1185,  0.1011,
         0.1253,  0.1202,  0.0620,  0.1887,  0.0850,  0.0946,  0.0932,  0.1290],
       device='cuda:0', requires_grad=True)
Param: encoder.layer3.0.conv2.weight
	Parameter containing:
tensor([[[[ 1.0013,  0.0000,  0.0000],
          [ 1.0013, -1.0013,  0.0000],
          [ 0.0000,  0.0000, -1.0013]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0013,  0.0000],
          [ 0.0000, -1.0013,  0.0000]],

         [[-1.0013, -1.0013,  0.0000],
          [ 0.0000, -1.0013,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000, -1.0013, -1.0013],
          [ 0.0000,  0.0000, -1.0013],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 1.0013,  0.0000,  1.0013],
          [ 0.0000,  0.0000, -1.0013],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[-1.0013,  0.0000,  0.0000],
          [-1.0013,  0.0000,  0.0000],
          [ 0.0000, -1.0013, -1.0013]],

         [[ 0.0000,  0.0000,  0.0000],
          [-1.0013,  0.0000,  0.0000],
          [-1.0013,  0.0000,  0.0000]],

         [[-1.0013,  0.0000,  0.0000],
          [-1.0013,  1.0013,  0.0000],
          [-1.0013, -1.0013,  0.0000]],

         ...,

         [[ 0.0000, -1.0013,  0.0000],
          [ 0.0000, -1.0013, -1.0013],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000, -1.0013,  0.0000],
          [ 0.0000, -1.0013,  1.0013],
          [-1.0013,  1.0013,  0.0000]],

         [[ 0.0000,  0.0000, -1.0013],
          [ 0.0000, -1.0013,  0.0000],
          [-1.0013, -1.0013,  0.0000]]],


        [[[ 1.0013,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  1.0013],
          [ 0.0000,  0.0000, -1.0013]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -1.0013],
          [ 0.0000, -1.0013, -1.0013]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0013,  0.0000],
          [ 1.0013, -1.0013,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -1.0013],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -1.0013],
          [ 0.0000, -1.0013,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0013,  0.0000],
          [ 0.0000,  0.0000, -1.0013]]],


        ...,


        [[[ 0.0000, -1.0013,  0.0000],
          [-1.0013,  1.0013, -1.0013],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0013,  0.0000],
          [-1.0013,  0.0000,  0.0000]],

         [[ 1.0013, -1.0013,  0.0000],
          [ 0.0000, -1.0013,  0.0000],
          [-1.0013,  1.0013,  0.0000]],

         ...,

         [[ 0.0000,  0.0000, -1.0013],
          [ 0.0000, -1.0013,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000, -1.0013],
          [ 0.0000, -1.0013,  1.0013],
          [ 0.0000, -1.0013,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -1.0013],
          [-1.0013, -1.0013,  1.0013]]],


        [[[ 0.0000,  1.0013,  0.0000],
          [ 0.0000,  1.0013,  0.0000],
          [ 0.0000, -1.0013, -1.0013]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [-1.0013, -1.0013,  1.0013]],

         [[ 1.0013,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [-1.0013, -1.0013,  0.0000]],

         ...,

         [[ 0.0000,  1.0013, -1.0013],
          [ 0.0000, -1.0013, -1.0013],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [-1.0013,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  1.0013],
          [-1.0013, -1.0013, -1.0013]]],


        [[[-1.0013,  0.0000,  0.0000],
          [ 1.0013, -1.0013,  1.0013],
          [ 0.0000,  0.0000, -1.0013]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0013,  0.0000]],

         [[ 0.0000,  1.0013,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  1.0013],
          [ 0.0000,  0.0000, -1.0013],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0013,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  1.0013,  0.0000],
          [ 0.0000,  0.0000,  1.0013],
          [ 0.0000,  0.0000, -1.0013]]]], device='cuda:0', requires_grad=True)
Param: encoder.layer3.0.bn2.weight
	Parameter containing:
tensor([1.0065, 1.0364, 0.9190, 0.9425, 1.0461, 0.8688, 0.8631, 1.0471, 1.0218,
        0.9055, 0.9926, 0.9680, 1.0221, 1.0837, 0.9764, 0.7615, 0.9438, 1.0582,
        0.8663, 1.0188, 0.8741, 0.9715, 1.0377, 0.9655, 1.0266, 0.9514, 0.9815,
        0.9983, 0.9998, 0.8733, 0.9366, 0.9721, 0.8147, 0.9237, 0.9358, 0.8721,
        1.0115, 0.9075, 0.8856, 1.0213, 0.9527, 0.9012, 0.9209, 0.8616, 0.9539,
        0.9886, 0.8907, 0.9295, 0.8953, 0.9781, 0.9957, 0.9134, 0.9439, 0.9145,
        0.9351, 0.8959, 0.9026, 1.0386, 0.9442, 0.9483, 1.0643, 0.9845, 1.0213,
        0.8297, 1.0399, 0.8733, 0.8930, 0.9292, 1.0458, 1.0036, 0.8802, 0.9133,
        0.9169, 0.9900, 0.9997, 0.9714, 0.8890, 0.8963, 1.0443, 1.0118, 0.9589,
        0.9417, 0.9124, 1.0977, 0.8292, 0.9782, 0.9192, 0.9636, 0.9145, 0.9012,
        0.8283, 0.9524, 1.1068, 0.9091, 0.9115, 0.9745, 0.8169, 0.9997, 0.9289,
        1.0202, 1.0053, 0.9314, 0.9954, 0.8530, 0.8895, 0.8062, 0.9181, 1.0110,
        0.9010, 0.9558, 0.9319, 0.9039, 1.0743, 1.1059, 0.9535, 0.9525, 1.1146,
        0.8617, 1.0022, 0.7857, 0.8303, 0.9953, 0.7556, 0.8406, 0.9396, 0.9127,
        0.9058, 0.8471, 1.0249, 0.9911, 0.9857, 0.9361, 1.0290, 0.9952, 0.9191,
        0.9594, 0.9872, 0.9072, 0.9684, 1.0208, 0.8320, 0.9848, 0.9724, 0.9713,
        0.8239, 0.9101, 0.8918, 0.9697, 1.1570, 1.0910, 0.9768, 0.9081, 0.8626,
        1.0021, 0.9163, 0.9081, 0.9583, 1.0146, 1.0671, 0.9786, 0.8790, 0.9875,
        1.0254, 1.0189, 0.8894, 0.9812, 1.0589, 0.9749, 0.9265, 0.9031, 0.8657,
        1.0039, 0.9385, 1.0853, 0.9535, 0.8377, 0.9147, 0.9650, 0.9858, 1.0268,
        0.9688, 0.9513, 0.9270, 0.9516, 0.9761, 0.8896, 1.0889, 0.9248, 0.9542,
        0.8912, 1.0050, 0.8929, 1.0252, 0.9074, 0.9364, 0.9504, 0.9379, 0.9521,
        0.8592, 0.9461, 0.9684, 0.9027, 0.8184, 0.9016, 0.9050, 0.9214, 0.8936,
        1.0892, 1.0018, 1.0404, 0.8565, 0.8204, 1.0164, 1.0782, 0.8934, 0.7235,
        0.9368, 0.9794, 0.9445, 0.9219, 0.9575, 0.7924, 0.8921, 1.0697, 0.8962,
        0.9161, 0.8641, 0.8543, 0.9308, 0.8589, 1.1352, 0.9681, 1.0157, 0.9526,
        0.8802, 0.8247, 0.9800, 0.9429, 1.0632, 1.0220, 1.0673, 0.9536, 0.9834,
        0.9564, 1.0377, 0.9796, 0.8589, 0.8482, 0.9228, 0.9100, 0.9495, 0.9354,
        0.9355, 0.8991, 1.0683, 0.9352], device='cuda:0', requires_grad=True)
Param: encoder.layer3.0.bn2.bias
	Parameter containing:
tensor([ 0.0632,  0.1065,  0.1958,  0.0151,  0.1700,  0.0240,  0.0317,  0.1393,
         0.1609, -0.1410,  0.1442,  0.0835,  0.0831,  0.0149,  0.0243,  0.0208,
         0.0677,  0.1337,  0.0946,  0.0291,  0.0526, -0.0038,  0.0023,  0.0927,
         0.0881,  0.0490,  0.0309,  0.0654,  0.1650,  0.1712,  0.0381,  0.0833,
         0.0216,  0.1010, -0.0106,  0.0331,  0.0963, -0.0766,  0.1227,  0.0809,
         0.0640,  0.0056, -0.0634,  0.0744,  0.0372,  0.0586, -0.1567, -0.0735,
         0.1369,  0.0272,  0.0603, -0.0286,  0.0264,  0.0403,  0.1120, -0.1056,
         0.0618,  0.2610,  0.1440,  0.0616,  0.1413, -0.0286,  0.0872,  0.0652,
         0.1717,  0.0277,  0.0414,  0.0441,  0.0828,  0.1496,  0.0795,  0.0146,
         0.1045,  0.1591,  0.0854,  0.0408,  0.0100,  0.1463,  0.0623,  0.1029,
         0.0889,  0.1082, -0.0112,  0.1000, -0.0238, -0.0230, -0.0531,  0.0265,
         0.0479,  0.1654,  0.2452,  0.0302,  0.1847,  0.0023, -0.0319, -0.1225,
        -0.0324,  0.0440,  0.0432,  0.1489,  0.0167, -0.0363,  0.2133,  0.1281,
         0.0367,  0.0851,  0.0922,  0.0145,  0.2308,  0.0187,  0.1182,  0.0909,
         0.1610,  0.0887, -0.0093,  0.1490,  0.1819,  0.0070,  0.0504,  0.0265,
        -0.0413,  0.0004,  0.1048,  0.0648, -0.0090, -0.0333, -0.0593,  0.0264,
         0.0194,  0.1145,  0.0123,  0.0795,  0.0075,  0.0777, -0.0061,  0.0716,
         0.1482, -0.0853,  0.0978,  0.1443, -0.0248,  0.0962,  0.0226, -0.0164,
         0.0774, -0.0158,  0.0899,  0.1028,  0.0933,  0.1280,  0.0157, -0.0069,
        -0.0295,  0.0781,  0.0964,  0.0036,  0.0615, -0.0991,  0.1555,  0.0728,
         0.0903,  0.0495, -0.1069,  0.0842,  0.0234,  0.0327,  0.1617,  0.0527,
         0.0136, -0.0431, -0.0055,  0.0685,  0.0392,  0.2404,  0.0008, -0.0302,
         0.0882,  0.1961, -0.0060,  0.1855,  0.0906,  0.1230, -0.0274,  0.1148,
         0.0614,  0.1458,  0.2678,  0.1070,  0.0025,  0.0197,  0.0829,  0.1364,
         0.0505, -0.1277,  0.1006,  0.0147,  0.1008, -0.0093,  0.1364, -0.0474,
         0.0273,  0.0801,  0.1368, -0.0140,  0.0016, -0.0082,  0.1921,  0.1197,
         0.0514,  0.0631, -0.0070,  0.1318,  0.1849,  0.0094, -0.0524,  0.1165,
        -0.0686,  0.0859, -0.0469,  0.0017,  0.1478,  0.0006,  0.0642,  0.1970,
         0.0638,  0.0400, -0.0149,  0.0072, -0.0404,  0.0700,  0.1704,  0.1068,
         0.0225,  0.1543,  0.1051, -0.0420,  0.0567,  0.0111,  0.0473,  0.1106,
         0.1347,  0.0434,  0.1233, -0.0488,  0.0941,  0.0919,  0.0325,  0.1088,
         0.0072, -0.1195,  0.0241,  0.0354, -0.0677,  0.0700,  0.1942, -0.0191],
       device='cuda:0', requires_grad=True)
Param: encoder.layer3.0.shortcut.0.weight
	Parameter containing:
tensor([[[[ 2.9201e-02]],

         [[-4.2452e-02]],

         [[ 5.0087e-02]],

         ...,

         [[-1.2697e-02]],

         [[-3.0760e-02]],

         [[-6.0431e-02]]],


        [[[ 7.8379e-02]],

         [[-4.7040e-05]],

         [[ 4.5877e-03]],

         ...,

         [[-1.2045e-01]],

         [[-3.1567e-03]],

         [[-1.0573e-01]]],


        [[[-1.6189e-01]],

         [[ 1.1400e-01]],

         [[-5.1758e-02]],

         ...,

         [[-2.8557e-02]],

         [[ 2.8116e-02]],

         [[-7.9072e-04]]],


        ...,


        [[[ 1.8311e-01]],

         [[-1.2784e-01]],

         [[-4.4587e-02]],

         ...,

         [[ 1.5188e-02]],

         [[-3.5676e-02]],

         [[ 1.1950e-02]]],


        [[[-1.3862e-02]],

         [[ 1.7420e-01]],

         [[ 2.1248e-03]],

         ...,

         [[ 1.1158e-01]],

         [[ 1.4281e-02]],

         [[-5.3552e-02]]],


        [[[-6.0296e-02]],

         [[ 9.5121e-02]],

         [[ 1.5701e-03]],

         ...,

         [[ 2.8023e-02]],

         [[-1.5183e-02]],

         [[-3.0862e-03]]]], device='cuda:0', requires_grad=True)
Param: encoder.layer3.0.shortcut.1.weight
	Parameter containing:
tensor([1.1102, 1.0058, 1.1407, 1.1874, 1.0024, 0.8940, 0.8388, 1.0259, 1.0930,
        1.0498, 1.1585, 1.1644, 1.0229, 0.9478, 1.0090, 0.9930, 1.0809, 0.9433,
        0.8286, 1.0448, 0.8973, 1.0283, 0.8292, 0.9778, 1.0982, 1.0437, 1.1001,
        0.8419, 1.0890, 1.1698, 1.0476, 0.9833, 0.8506, 0.8121, 0.8348, 0.8540,
        0.9474, 1.1357, 0.9774, 1.0534, 1.1093, 1.0790, 0.8595, 1.1261, 0.9696,
        1.1837, 1.0275, 1.0628, 1.0511, 0.9302, 0.9575, 1.0717, 1.0545, 1.0951,
        1.0112, 0.9813, 0.9207, 1.3065, 0.8413, 0.9944, 1.1955, 0.8872, 1.0873,
        0.8242, 1.0862, 1.1537, 1.1213, 0.9327, 1.0637, 0.7667, 0.9267, 0.9994,
        1.0644, 0.9900, 1.1185, 1.0055, 0.9385, 0.9112, 1.0889, 1.0938, 1.0828,
        1.0443, 0.9203, 1.0071, 1.2325, 1.1224, 0.9596, 0.9044, 0.9947, 0.9564,
        0.8870, 0.9368, 1.1202, 0.9927, 1.0963, 0.9913, 0.9150, 1.0341, 1.0387,
        1.1570, 1.1628, 1.0252, 0.9408, 1.0549, 1.0292, 1.1360, 1.0269, 1.1149,
        0.8832, 1.1414, 0.9284, 1.0812, 1.0129, 0.9449, 1.0421, 1.0921, 0.9558,
        1.0252, 0.9832, 1.0195, 0.8914, 1.0507, 0.9704, 1.0198, 0.9487, 0.8949,
        1.1244, 0.9113, 1.0098, 1.1056, 1.0569, 0.9641, 1.0078, 0.9595, 1.1414,
        1.1789, 1.0562, 0.8644, 0.9273, 0.9083, 1.0538, 0.8882, 1.0677, 0.8652,
        1.1385, 0.8025, 1.0915, 0.9902, 0.9705, 0.9426, 1.0258, 1.0798, 1.0472,
        1.0728, 0.8929, 1.0492, 1.1723, 1.0227, 0.9863, 1.0069, 1.0481, 1.0870,
        0.9315, 1.1124, 0.9634, 0.9086, 1.2647, 1.1951, 1.0822, 1.0018, 0.8441,
        1.0915, 1.0277, 1.0316, 0.9733, 0.9371, 0.8885, 0.8840, 0.9755, 0.9383,
        0.9955, 1.0518, 0.9707, 0.9756, 1.2243, 0.9182, 1.0790, 1.1712, 0.9145,
        1.1104, 1.0155, 0.8996, 1.0114, 1.0286, 1.1668, 0.9618, 1.0658, 0.9232,
        1.1849, 0.9837, 1.0455, 1.0375, 1.1129, 1.1077, 1.1207, 1.0246, 1.1020,
        1.0210, 1.2016, 1.1226, 1.0675, 0.8134, 1.0525, 0.9139, 0.8760, 0.7254,
        1.0811, 0.9165, 0.9667, 0.9859, 1.1961, 1.1697, 1.1914, 0.9763, 0.9697,
        0.8989, 0.9804, 1.0319, 0.9223, 1.1201, 1.0224, 1.0430, 0.9166, 1.0251,
        1.0048, 1.0894, 1.1258, 1.0909, 1.0622, 0.9606, 0.8897, 1.0961, 1.0066,
        0.9156, 1.0548, 1.1451, 1.0622, 1.1974, 0.9763, 0.8889, 1.0719, 1.0349,
        1.0402, 1.1131, 1.1108, 0.9087], device='cuda:0', requires_grad=True)
Param: encoder.layer3.0.shortcut.1.bias
	Parameter containing:
tensor([ 0.0632,  0.1065,  0.1958,  0.0151,  0.1700,  0.0240,  0.0317,  0.1393,
         0.1609, -0.1410,  0.1442,  0.0835,  0.0831,  0.0149,  0.0243,  0.0208,
         0.0677,  0.1337,  0.0946,  0.0291,  0.0526, -0.0038,  0.0023,  0.0927,
         0.0881,  0.0490,  0.0309,  0.0654,  0.1650,  0.1712,  0.0381,  0.0833,
         0.0216,  0.1010, -0.0106,  0.0331,  0.0963, -0.0766,  0.1227,  0.0809,
         0.0640,  0.0056, -0.0634,  0.0744,  0.0372,  0.0586, -0.1567, -0.0735,
         0.1369,  0.0272,  0.0603, -0.0286,  0.0264,  0.0403,  0.1120, -0.1056,
         0.0618,  0.2610,  0.1440,  0.0616,  0.1413, -0.0286,  0.0872,  0.0652,
         0.1717,  0.0277,  0.0414,  0.0441,  0.0828,  0.1496,  0.0795,  0.0146,
         0.1045,  0.1591,  0.0854,  0.0408,  0.0100,  0.1463,  0.0623,  0.1029,
         0.0889,  0.1082, -0.0112,  0.1000, -0.0238, -0.0230, -0.0531,  0.0265,
         0.0479,  0.1654,  0.2452,  0.0302,  0.1847,  0.0023, -0.0319, -0.1225,
        -0.0324,  0.0440,  0.0432,  0.1489,  0.0167, -0.0363,  0.2133,  0.1281,
         0.0367,  0.0851,  0.0922,  0.0145,  0.2308,  0.0187,  0.1182,  0.0909,
         0.1610,  0.0887, -0.0093,  0.1490,  0.1819,  0.0070,  0.0504,  0.0265,
        -0.0413,  0.0004,  0.1048,  0.0648, -0.0090, -0.0333, -0.0593,  0.0264,
         0.0194,  0.1145,  0.0123,  0.0795,  0.0075,  0.0777, -0.0061,  0.0716,
         0.1482, -0.0853,  0.0978,  0.1443, -0.0248,  0.0962,  0.0226, -0.0164,
         0.0774, -0.0158,  0.0899,  0.1028,  0.0933,  0.1280,  0.0157, -0.0069,
        -0.0295,  0.0781,  0.0964,  0.0036,  0.0615, -0.0991,  0.1555,  0.0728,
         0.0903,  0.0495, -0.1069,  0.0842,  0.0234,  0.0327,  0.1617,  0.0527,
         0.0136, -0.0431, -0.0055,  0.0685,  0.0392,  0.2404,  0.0008, -0.0302,
         0.0882,  0.1961, -0.0060,  0.1855,  0.0906,  0.1230, -0.0274,  0.1148,
         0.0614,  0.1458,  0.2678,  0.1070,  0.0025,  0.0197,  0.0829,  0.1364,
         0.0505, -0.1277,  0.1006,  0.0147,  0.1008, -0.0093,  0.1364, -0.0474,
         0.0273,  0.0801,  0.1368, -0.0140,  0.0016, -0.0082,  0.1921,  0.1197,
         0.0514,  0.0631, -0.0070,  0.1318,  0.1849,  0.0094, -0.0524,  0.1165,
        -0.0686,  0.0859, -0.0469,  0.0017,  0.1478,  0.0006,  0.0642,  0.1970,
         0.0638,  0.0400, -0.0149,  0.0072, -0.0404,  0.0700,  0.1704,  0.1068,
         0.0225,  0.1543,  0.1051, -0.0420,  0.0567,  0.0111,  0.0473,  0.1106,
         0.1347,  0.0434,  0.1233, -0.0488,  0.0941,  0.0919,  0.0325,  0.1088,
         0.0072, -0.1195,  0.0241,  0.0354, -0.0677,  0.0700,  0.1942, -0.0191],
       device='cuda:0', requires_grad=True)
Param: encoder.layer3.1.conv1.weight
	Parameter containing:
tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [-0.9980,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.9980],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -0.9980,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [-0.9980,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.9980,  0.0000, -0.9980],
          [ 0.0000,  0.0000, -0.9980],
          [ 0.9980,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000, -0.9980],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.9980,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -0.9980]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -0.9980]]],


        [[[ 0.0000, -0.9980,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -0.9980]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000, -0.9980],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         ...,

         [[-0.9980,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -0.9980]],

         [[ 0.0000,  0.0000,  0.0000],
          [-0.9980,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -0.9980],
          [ 0.0000,  0.0000, -0.9980]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.9980, -0.9980],
          [ 0.0000,  0.0000, -0.9980],
          [ 0.0000,  0.0000, -0.9980]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -0.9980],
          [ 0.0000,  0.0000, -0.9980]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -0.9980],
          [ 0.0000,  0.0000, -0.9980]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -0.9980, -0.9980]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -0.9980,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [-0.9980, -0.9980,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -0.9980, -0.9980]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -0.9980]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [-0.9980, -0.9980,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.9980],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -0.9980]],

         [[ 0.0000,  0.9980,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -0.9980]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0', requires_grad=True)
Param: encoder.layer3.1.bn1.weight
	Parameter containing:
tensor([0.9085, 0.8414, 0.7924, 0.9927, 1.0145, 0.9944, 0.8977, 0.9605, 1.0795,
        1.0621, 1.0469, 0.9562, 1.0068, 0.9553, 0.9312, 1.0673, 0.7801, 0.8476,
        1.0333, 1.0362, 0.8670, 0.9269, 0.9496, 0.8786, 0.9648, 0.9348, 1.0201,
        0.8981, 0.9180, 0.9690, 0.9636, 1.0416, 1.0177, 0.8842, 0.9259, 0.9488,
        1.0188, 1.0031, 1.0359, 1.0557, 0.9195, 0.9252, 1.0146, 0.9555, 0.8911,
        0.8953, 0.9051, 1.0379, 0.9889, 1.0196, 0.9308, 0.9148, 0.8207, 1.0624,
        0.9771, 0.9821, 0.8945, 1.0210, 0.9520, 0.8892, 0.9511, 0.9691, 0.9780,
        0.9238, 1.1166, 0.8930, 0.8863, 0.8609, 0.9872, 0.8761, 0.9266, 0.8500,
        1.0545, 1.0077, 0.9137, 0.8752, 1.0739, 0.9611, 1.0368, 0.9769, 0.9200,
        0.8376, 0.9556, 0.9393, 0.8564, 1.0662, 0.9071, 0.9213, 0.9676, 0.9680,
        1.1042, 1.0032, 0.9568, 0.9554, 0.8951, 0.9987, 1.0351, 0.9140, 0.8989,
        1.0683, 0.9809, 0.9473, 0.9070, 0.9598, 1.0150, 1.0185, 1.0682, 0.9703,
        0.8395, 0.8474, 1.0848, 0.8963, 1.0509, 0.9543, 0.8957, 0.9459, 0.9856,
        1.0741, 1.0070, 0.9388, 1.0447, 0.9940, 0.9645, 0.8299, 0.9363, 0.9603,
        0.8064, 1.0171, 1.1272, 1.1586, 0.8749, 0.9965, 1.0508, 0.9750, 0.9241,
        0.9477, 0.9344, 0.9719, 0.9424, 0.9477, 0.9072, 1.0571, 0.8969, 1.0340,
        1.0637, 0.8796, 0.8774, 0.8666, 0.9456, 0.9088, 0.9783, 0.7980, 1.0147,
        0.9648, 0.9599, 0.8978, 0.9924, 0.8536, 1.0574, 1.0118, 1.0348, 1.0199,
        1.0537, 0.9704, 1.0650, 1.0733, 1.1130, 1.0198, 0.9102, 0.8611, 0.8909,
        0.9060, 0.9584, 1.0230, 0.9405, 0.8766, 0.9650, 1.0665, 0.9815, 1.0864,
        1.0461, 0.9633, 1.1192, 0.9990, 0.9242, 1.0432, 0.7973, 1.0852, 0.9620,
        0.9626, 0.9310, 1.0525, 0.8888, 0.9477, 0.9933, 0.9446, 0.9421, 1.0418,
        1.0700, 0.9259, 0.9948, 0.8734, 0.9239, 0.9954, 0.9381, 0.9147, 0.8141,
        1.1155, 0.9698, 1.0213, 0.9676, 1.0149, 0.9113, 0.9752, 0.9398, 0.9053,
        0.8634, 1.0029, 0.9835, 0.9868, 1.0523, 0.9281, 0.8841, 0.9341, 0.8772,
        0.9410, 0.8940, 1.1017, 0.8771, 0.9524, 1.0288, 0.8905, 1.1108, 0.9929,
        0.9257, 1.0848, 1.0286, 1.0132, 0.7600, 0.9886, 0.9782, 0.9065, 0.9795,
        1.0564, 0.9845, 0.9428, 0.8892, 0.8834, 0.9112, 0.9319, 0.9917, 1.0275,
        0.9033, 0.9744, 1.0111, 1.0264], device='cuda:0', requires_grad=True)
Param: encoder.layer3.1.bn1.bias
	Parameter containing:
tensor([0.1951, 0.2416, 0.2949, 0.6073, 0.2682, 0.2943, 0.2989, 0.2583, 0.2150,
        0.3610, 0.2993, 0.2855, 0.3796, 0.2495, 0.1759, 0.5102, 0.3268, 0.2889,
        0.4988, 0.3787, 0.2474, 0.1745, 0.3991, 0.3452, 0.2703, 0.2554, 0.1473,
        0.4736, 0.2758, 0.3274, 0.3550, 0.2139, 0.3877, 0.2391, 0.2411, 0.3441,
        0.2550, 0.3709, 0.1794, 0.4205, 0.1692, 0.2183, 0.2495, 0.3790, 0.2405,
        0.3078, 0.3680, 0.3551, 0.1762, 0.2236, 0.3261, 0.1590, 0.2744, 0.5164,
        0.2752, 0.3378, 0.3676, 0.3563, 0.3755, 0.2625, 0.3186, 0.4679, 0.4401,
        0.2173, 0.5385, 0.1183, 0.2965, 0.2304, 0.3007, 0.1538, 0.2951, 0.3206,
        0.5584, 0.2946, 0.1910, 0.2409, 0.4751, 0.2605, 0.6438, 0.3471, 0.3200,
        0.3201, 0.2518, 0.2864, 0.2202, 0.2111, 0.2892, 0.1791, 0.2276, 0.2663,
        0.6198, 0.2996, 0.3592, 0.2993, 0.3452, 0.5230, 0.1571, 0.1817, 0.2596,
        0.1666, 0.1739, 0.3309, 0.3480, 0.2750, 0.4264, 0.2541, 0.2649, 0.2650,
        0.1614, 0.3606, 0.4924, 0.1955, 0.5136, 0.2846, 0.4865, 0.3367, 0.2173,
        0.3673, 0.1965, 0.2522, 0.3598, 0.1299, 0.2683, 0.2270, 0.2551, 0.2724,
        0.3830, 0.2732, 0.4201, 0.5300, 0.4466, 0.1515, 0.4056, 0.3314, 0.4726,
        0.2406, 0.2532, 0.3093, 0.3189, 0.1811, 0.3661, 0.1775, 0.1483, 0.5149,
        0.4919, 0.2910, 0.1749, 0.1567, 0.4635, 0.2477, 0.2066, 0.3362, 0.1759,
        0.2380, 0.2475, 0.2773, 0.3141, 0.1553, 0.1217, 0.1939, 0.3915, 0.2180,
        0.4269, 0.1485, 0.3318, 0.1990, 0.4984, 0.4167, 0.3334, 0.2594, 0.4797,
        0.3656, 0.2159, 0.5434, 0.2843, 0.1643, 0.2800, 0.3508, 0.3663, 0.4908,
        0.3519, 0.3211, 0.1889, 0.4935, 0.2234, 0.1625, 0.2661, 0.0871, 0.3460,
        0.2907, 0.7465, 0.5385, 0.2347, 0.1052, 0.4705, 0.4576, 0.4341, 0.3263,
        0.3709, 0.2367, 0.3291, 0.2628, 0.3962, 0.3900, 0.2714, 0.2284, 0.2355,
        0.4516, 0.2194, 0.5514, 0.4337, 0.3269, 0.2533, 0.4279, 0.2420, 0.2644,
        0.3043, 0.1836, 0.3621, 0.4812, 0.2888, 0.2325, 0.2481, 0.2504, 0.3123,
        0.2795, 0.3812, 0.1625, 0.1747, 0.2370, 0.4917, 0.3639, 0.5861, 0.2919,
        0.2310, 0.1869, 0.1915, 0.2626, 0.3639, 0.3062, 0.4448, 0.2480, 0.1957,
        0.1709, 0.2768, 0.3773, 0.3724, 0.2265, 0.2797, 0.1908, 0.0840, 0.3201,
        0.2466, 0.2858, 0.3507, 0.2038], device='cuda:0', requires_grad=True)
Param: encoder.layer3.1.conv2.weight
	Parameter containing:
tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0010,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -1.0010]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -1.0010]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -1.0010]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0010,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [-1.0010,  0.0000,  0.0000],
          [-1.0010,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  1.0010],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000, -1.0010,  1.0010],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000, -1.0010,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [-1.0010,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [-1.0010,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0010,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -1.0010]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -1.0010],
          [ 1.0010,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -1.0010]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0000,  0.0000,  0.0000],
          [ 1.0010, -1.0010,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000, -1.0010],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000, -1.0010],
          [ 0.0000, -1.0010,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -1.0010],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -1.0010],
          [ 0.0000,  0.0000,  1.0010]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0010,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [-1.0010,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0010,  0.0000],
          [-1.0010,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [-1.0010,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [-1.0010,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000, -1.0010,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0', requires_grad=True)
Param: encoder.layer3.1.bn2.weight
	Parameter containing:
tensor([0.8683, 0.7616, 0.7734, 0.8624, 0.7789, 0.8806, 0.9971, 0.7426, 0.6353,
        0.9481, 0.7458, 0.8302, 0.7216, 0.5645, 0.9550, 1.0640, 0.8241, 0.7752,
        0.8328, 1.0377, 0.8335, 0.8651, 0.9480, 0.6472, 0.8542, 0.8401, 0.7831,
        0.7552, 0.8046, 0.6686, 0.6686, 0.9229, 0.7767, 0.7661, 0.8961, 0.9798,
        0.6929, 0.9914, 0.8364, 0.8092, 0.7798, 0.8547, 0.9186, 0.7522, 0.7795,
        0.8777, 0.9560, 0.9385, 0.9261, 0.9626, 0.8458, 0.9793, 1.0065, 0.7755,
        0.6529, 0.9566, 0.7360, 0.6666, 0.8918, 0.8183, 0.8189, 0.9639, 0.8739,
        0.8057, 0.7497, 0.7120, 0.9448, 0.6617, 0.7658, 0.7926, 0.7895, 0.9023,
        0.6496, 0.7027, 0.6673, 0.7529, 0.9023, 0.7525, 0.8221, 0.6897, 0.8858,
        0.6062, 0.9106, 0.7373, 0.8610, 0.8856, 0.9479, 0.7546, 0.7749, 0.7254,
        0.8845, 0.7415, 0.7309, 0.8589, 0.8442, 0.9908, 0.8090, 0.6679, 0.8368,
        0.8247, 0.8908, 1.0018, 0.5135, 0.6898, 0.8790, 0.7032, 0.7322, 0.9208,
        0.7451, 0.9527, 0.7612, 0.9414, 0.7291, 0.8747, 0.8002, 0.7820, 0.7467,
        0.8279, 0.9406, 0.6982, 0.7588, 0.9587, 0.8099, 0.8637, 0.8753, 0.7866,
        0.8179, 0.7449, 0.8600, 0.8925, 0.8926, 0.6902, 0.6831, 0.8974, 0.9381,
        0.7528, 0.8111, 1.0408, 0.7889, 0.8048, 0.7364, 0.8435, 0.9020, 1.0259,
        0.9469, 0.9645, 0.7927, 0.8876, 0.7758, 0.5716, 0.8934, 0.8915, 0.9471,
        0.7841, 0.9578, 0.9643, 0.8908, 0.9218, 0.7795, 0.7138, 0.8554, 0.9582,
        0.9175, 0.7578, 0.9250, 0.8782, 0.7323, 0.7118, 0.7973, 0.7957, 0.9146,
        0.7614, 0.7927, 0.8512, 0.8465, 0.8713, 0.7746, 0.7560, 0.9124, 0.7423,
        0.8076, 0.6901, 0.8591, 0.7208, 0.8291, 0.8552, 0.7809, 0.6795, 0.8058,
        0.7474, 0.7907, 0.8444, 0.8405, 0.9486, 0.7792, 0.9398, 0.8408, 0.8896,
        0.7499, 0.9213, 0.8910, 0.9022, 0.7833, 0.9004, 0.8738, 0.9237, 0.8126,
        0.7231, 0.8762, 0.9231, 0.9407, 0.7704, 0.7424, 0.9009, 0.9888, 0.7143,
        0.8752, 0.7126, 0.8844, 0.8847, 0.7212, 0.8667, 0.8727, 0.6017, 0.8671,
        0.9205, 0.7916, 0.8395, 0.8694, 0.7846, 0.6935, 0.7462, 0.7165, 0.7900,
        0.6191, 0.7440, 0.7432, 0.9563, 0.8111, 0.6819, 0.6418, 0.7308, 0.8300,
        0.8136, 0.7240, 0.7508, 0.8064, 0.7517, 0.9152, 0.9148, 0.9304, 0.8924,
        0.8480, 0.7818, 0.7680, 0.9217], device='cuda:0', requires_grad=True)
Param: encoder.layer3.1.bn2.bias
	Parameter containing:
tensor([ 0.0401,  0.0056, -0.0052,  0.0139,  0.0038, -0.0341, -0.0526,  0.0147,
         0.0672, -0.0535,  0.0141, -0.0204,  0.0495, -0.0015, -0.0704, -0.1550,
        -0.0134,  0.0432,  0.0531, -0.0945, -0.0726, -0.0110, -0.1155,  0.0161,
        -0.0555,  0.0264,  0.0333,  0.0510, -0.0712,  0.0347,  0.0109, -0.0145,
         0.0196,  0.0088,  0.0425, -0.0325, -0.0019, -0.0207,  0.0084,  0.0301,
        -0.0959,  0.0831, -0.0415, -0.0011,  0.0153,  0.0695, -0.0441, -0.0309,
        -0.0672, -0.0193,  0.0906, -0.0374, -0.1817,  0.0010,  0.0319, -0.1242,
         0.0082,  0.0186,  0.0488,  0.0607, -0.0320,  0.0075,  0.0509,  0.0575,
         0.0296,  0.0456, -0.0488,  0.0292,  0.1411,  0.1279,  0.0399,  0.0458,
         0.0484, -0.0716,  0.1117,  0.0108,  0.0618,  0.0305, -0.0311,  0.0053,
         0.0004, -0.0057, -0.0148,  0.0320, -0.0379, -0.0081, -0.0097,  0.1142,
         0.0625,  0.0398,  0.0051,  0.0006,  0.0198,  0.0295, -0.0144, -0.0558,
         0.0208,  0.0130,  0.0409,  0.1803,  0.0176, -0.0581,  0.1491,  0.0157,
         0.0638,  0.0024,  0.0342, -0.0894, -0.0655, -0.0608,  0.0271,  0.0155,
         0.0679, -0.0621, -0.0156,  0.0126, -0.0375, -0.0079, -0.0843, -0.0689,
         0.0301,  0.0405,  0.1044, -0.0148, -0.0321, -0.0518, -0.0282,  0.0086,
        -0.0240, -0.0424, -0.0022,  0.0053,  0.0105, -0.1068, -0.0523,  0.0441,
         0.0213, -0.0525, -0.0032,  0.0075, -0.0119,  0.0029, -0.0132, -0.0531,
        -0.0738, -0.0100,  0.0443,  0.0295,  0.0449,  0.0303, -0.0493, -0.0131,
        -0.0518, -0.0532,  0.0033,  0.0058,  0.0228,  0.0174, -0.0104,  0.0070,
         0.0060, -0.0515, -0.0429,  0.0710,  0.0135, -0.0263, -0.0010,  0.0199,
         0.0056, -0.0528,  0.0323,  0.0598,  0.0022,  0.0092,  0.0390, -0.1216,
         0.0023,  0.0161, -0.0073, -0.0142,  0.0374,  0.0257, -0.0311,  0.0295,
         0.0227, -0.0423,  0.0105,  0.0066,  0.0057, -0.0215, -0.0698,  0.0300,
         0.0274, -0.0681,  0.1283,  0.0012,  0.0379, -0.0219,  0.0065, -0.0486,
         0.0529,  0.0502,  0.0314, -0.0392, -0.0067, -0.0712,  0.0433,  0.0934,
         0.0388,  0.0056, -0.0344,  0.0151,  0.0390, -0.0448, -0.0199,  0.0081,
        -0.0193,  0.0304, -0.0234,  0.0475, -0.0071, -0.0053,  0.0008,  0.0373,
         0.1132, -0.0572,  0.0279,  0.0266,  0.0348,  0.0068,  0.0133,  0.0229,
        -0.0074,  0.0349,  0.0629,  0.0590, -0.0118, -0.0037,  0.0795, -0.0007,
         0.0041,  0.0735,  0.1112,  0.0243, -0.0078,  0.0202,  0.0025, -0.0048,
         0.0207,  0.0086,  0.0117, -0.0688, -0.0164,  0.0412,  0.0618, -0.0211],
       device='cuda:0', requires_grad=True)
Param: encoder.layer4.0.conv1.weight
	Parameter containing:
tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  1.0008]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0008,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  1.0008],
          [ 0.0000,  0.0000,  1.0008]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  1.0008]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0008,  0.0000],
          [ 0.0000,  1.0008, -1.0008]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  1.0008]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -1.0008],
          [ 0.0000,  0.0000,  1.0008]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0008,  0.0000],
          [ 0.0000,  1.0008,  1.0008]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  1.0008],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -1.0008],
          [ 0.0000,  0.0000,  1.0008]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0008,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  1.0008],
          [ 0.0000,  0.0000, -1.0008]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0008,  1.0008],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0008,  0.0000],
          [ 0.0000,  1.0008, -1.0008]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  1.0008],
          [ 0.0000,  1.0008,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0008,  0.0000],
          [ 0.0000, -1.0008,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  1.0008],
          [ 0.0000,  0.0000,  1.0008]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -1.0008],
          [ 0.0000,  0.0000, -1.0008]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  1.0008]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  1.0008],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  1.0008]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  1.0008],
          [ 0.0000,  0.0000, -1.0008]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0008,  0.0000],
          [ 0.0000,  0.0000, -1.0008]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -1.0008]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -1.0008],
          [ 0.0000, -1.0008, -1.0008]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0008, -1.0008]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0008,  1.0008],
          [ 0.0000,  1.0008,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  1.0008],
          [ 0.0000, -1.0008,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0008, -1.0008],
          [ 0.0000,  0.0000, -1.0008]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000, -1.0008],
          [ 0.0000,  0.0000,  1.0008]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  1.0008],
          [ 0.0000, -1.0008,  0.0000]]]], device='cuda:0', requires_grad=True)
Param: encoder.layer4.0.bn1.weight
	Parameter containing:
tensor([1.0889, 1.0438, 0.9360, 0.9538, 1.0926, 0.8892, 0.8676, 0.9468, 0.9631,
        1.0959, 1.1237, 1.0016, 1.1048, 0.9895, 1.0195, 0.9861, 1.0062, 1.0799,
        1.0309, 0.9884, 1.0801, 1.0617, 0.8965, 0.9657, 0.9999, 1.1149, 1.0403,
        1.1179, 1.0655, 0.9671, 1.1320, 0.9628, 1.0977, 0.9025, 0.9018, 1.0650,
        0.9404, 1.0086, 0.9891, 1.0054, 1.0301, 0.9754, 1.0160, 1.0897, 0.9830,
        1.0220, 1.1137, 1.0591, 0.9735, 0.8348, 0.9210, 1.0114, 1.0629, 1.1279,
        1.0179, 0.9652, 0.7546, 1.0346, 0.9812, 0.9857, 1.0276, 0.8734, 0.9852,
        0.9473, 0.9663, 0.9121, 1.1248, 1.0733, 1.0762, 1.0954, 0.9990, 1.0247,
        0.9478, 0.8992, 1.0840, 1.1283, 0.8824, 1.0616, 0.9782, 1.0304, 0.9721,
        0.8599, 0.9669, 0.9736, 0.9836, 1.0495, 1.0431, 1.0631, 0.9161, 1.0105,
        1.0474, 1.0128, 0.8877, 0.9692, 1.1088, 0.9000, 0.9606, 1.0694, 0.8606,
        1.0331, 0.8802, 0.9973, 1.0372, 1.0716, 0.9325, 1.0117, 1.0658, 1.0262,
        0.9284, 1.0427, 1.1330, 1.0614, 1.0739, 0.9934, 0.9167, 1.0054, 1.0051,
        0.8953, 1.0200, 0.9341, 1.0745, 1.0842, 0.9695, 1.0447, 1.0794, 0.9209,
        1.0195, 0.9821, 0.8571, 1.0097, 1.1653, 1.0546, 0.9537, 1.0738, 1.0008,
        1.0884, 0.8899, 1.1551, 0.9138, 0.9776, 1.0632, 1.0063, 0.8848, 1.0111,
        0.9361, 0.9815, 0.9579, 1.0417, 0.9598, 1.0535, 0.9646, 0.9562, 1.0039,
        0.9706, 0.9415, 1.0278, 0.9202, 0.9670, 1.0102, 0.9473, 1.0072, 1.0108,
        0.9801, 1.0055, 0.8121, 0.9385, 1.0493, 1.0707, 0.9139, 0.9744, 1.0391,
        1.1407, 1.0126, 0.8539, 0.8142, 1.0218, 0.8718, 0.9781, 1.0606, 1.0579,
        0.9745, 0.8913, 0.9277, 1.1319, 1.0020, 1.0283, 1.0131, 0.9136, 1.0024,
        0.9789, 0.9010, 1.0223, 0.8508, 1.0504, 1.0149, 1.0003, 1.1055, 0.9570,
        1.0097, 1.0152, 0.9782, 0.9449, 1.0184, 0.9768, 0.9961, 0.9759, 1.0143,
        1.0148, 0.8797, 1.0755, 0.9832, 0.9234, 0.9997, 1.0199, 1.0816, 0.8721,
        1.0807, 1.0660, 0.9099, 0.9769, 1.0380, 0.9366, 0.9624, 0.9845, 1.1064,
        0.9266, 0.9367, 0.9642, 1.0696, 0.8621, 1.0255, 0.9768, 1.0436, 0.9473,
        1.0861, 0.9513, 0.8817, 0.9846, 0.9107, 0.9607, 0.9598, 0.7974, 1.0190,
        1.0903, 0.9395, 0.8870, 1.1044, 0.9450, 0.9787, 0.9818, 0.9694, 1.1126,
        1.0123, 1.0089, 0.9391, 1.1417, 1.1143, 1.0177, 1.0658, 0.9609, 0.9361,
        1.0300, 1.0903, 1.0675, 0.9638, 1.0851, 0.9634, 1.0690, 1.0679, 1.0524,
        1.0975, 1.0313, 0.8848, 0.9968, 1.0222, 1.0162, 1.0064, 0.9815, 0.9580,
        1.1250, 1.0370, 1.0269, 0.9608, 1.0426, 0.9877, 0.9646, 1.1386, 0.9915,
        0.9086, 1.0117, 0.8706, 0.9511, 1.0343, 0.9644, 0.9847, 1.0348, 0.9935,
        0.9287, 1.1450, 1.0230, 1.1016, 1.0368, 1.0388, 1.0161, 1.0972, 0.9807,
        1.0535, 0.9264, 0.9352, 1.0226, 0.9845, 1.0176, 0.8456, 1.0263, 0.9432,
        0.8647, 1.1623, 0.9182, 0.9471, 1.0586, 1.1138, 1.0720, 1.0507, 0.9320,
        0.8694, 1.0537, 0.9371, 0.9242, 0.9682, 0.7791, 1.0808, 1.0249, 1.0724,
        0.9359, 0.9670, 0.9066, 1.0421, 0.9272, 0.9652, 0.9245, 1.0845, 0.9189,
        1.1202, 1.0201, 1.0990, 1.0359, 0.9508, 1.0729, 1.0638, 1.0108, 1.0734,
        0.9866, 1.0476, 0.8636, 0.9357, 0.9927, 0.9895, 1.0589, 0.9597, 1.1197,
        1.0683, 0.9951, 1.0377, 0.9837, 1.1105, 0.9735, 0.9708, 0.9650, 1.1323,
        1.0178, 0.9619, 0.9240, 1.0489, 0.9527, 1.1665, 1.0078, 0.9933, 1.0125,
        0.9348, 0.9514, 0.9211, 1.0895, 0.9179, 1.1002, 1.0464, 0.9096, 1.0418,
        1.0033, 1.0664, 1.0485, 1.1221, 1.0485, 1.1135, 0.9076, 0.8835, 0.9246,
        0.9772, 1.0091, 1.1172, 0.9902, 0.9719, 0.9709, 1.0491, 1.0975, 1.0037,
        1.0951, 0.8419, 0.9257, 1.0291, 0.9181, 0.8925, 0.8583, 0.9392, 0.9317,
        0.9102, 0.9370, 0.9451, 0.9289, 0.9974, 1.0237, 0.9726, 0.9779, 1.0731,
        0.9918, 1.0158, 1.0696, 1.0303, 1.0774, 1.0700, 0.8439, 0.9061, 1.0097,
        0.9614, 1.0798, 1.0328, 1.0416, 0.9947, 0.9278, 0.9901, 1.0108, 0.9848,
        1.0360, 0.9487, 1.0799, 1.0067, 1.0150, 1.0882, 0.9318, 0.9181, 1.0546,
        1.0302, 1.0143, 0.8055, 0.9740, 1.0572, 1.0755, 1.0293, 0.9466, 0.8556,
        1.1004, 1.0004, 0.8530, 1.1648, 0.9598, 1.0131, 1.0933, 1.0645, 0.9937,
        0.9822, 1.0203, 1.0069, 0.9908, 1.0435, 0.8971, 1.0599, 0.9618, 0.9924,
        0.8958, 0.9343, 1.0090, 0.9764, 0.8913, 1.0493, 1.0663, 1.0704, 0.9938,
        1.1401, 1.0151, 0.9053, 1.0139, 0.8999, 0.9873, 1.0732, 1.0407, 0.8900,
        0.9107, 0.9665, 1.0087, 0.9685, 1.0757, 1.0151, 0.9670, 0.9267, 0.9551,
        1.0025, 0.8974, 0.9421, 1.0165, 0.9723, 0.9002, 0.9380, 1.0700],
       device='cuda:0', requires_grad=True)
Param: encoder.layer4.0.bn1.bias
	Parameter containing:
tensor([-0.1235, -0.1065, -0.0086, -0.0722,  0.0932, -0.0683, -0.0719, -0.2430,
        -0.0566, -0.0642,  0.0745, -0.0755, -0.0658,  0.0295,  0.0071, -0.0914,
        -0.1624, -0.0313,  0.0349, -0.0344, -0.0967,  0.0159, -0.1798, -0.1211,
        -0.0350,  0.0113,  0.0407, -0.0446, -0.0209, -0.0411, -0.0849, -0.0978,
         0.0317, -0.1519, -0.0932, -0.0396,  0.0019, -0.0347,  0.0205, -0.0578,
        -0.1219, -0.1070, -0.0556, -0.0280, -0.1215, -0.1056,  0.0091, -0.1089,
        -0.0170, -0.2151, -0.1548, -0.0339,  0.0673, -0.1108, -0.0115, -0.0229,
        -0.1818,  0.0147, -0.1218, -0.0044, -0.0142,  0.0071, -0.1687, -0.0841,
         0.0171, -0.0251,  0.0103, -0.0073,  0.0092, -0.0211,  0.0266,  0.0162,
        -0.0810, -0.1277, -0.0352, -0.0288, -0.1763,  0.0432, -0.0125, -0.1240,
        -0.0857, -0.1858, -0.1067,  0.0660, -0.0723,  0.0660, -0.0263,  0.0720,
        -0.0352, -0.0687,  0.0057, -0.0215, -0.1513, -0.0337,  0.0411, -0.0356,
        -0.1042, -0.1515,  0.0086, -0.0158, -0.1596, -0.1288,  0.0343,  0.0628,
        -0.0731, -0.0798, -0.0531, -0.0367, -0.1570, -0.0203,  0.0378,  0.0167,
        -0.0512, -0.0904, -0.1288, -0.0244,  0.0498, -0.0939, -0.0367, -0.2019,
        -0.0025,  0.0149,  0.1095, -0.0077, -0.0198, -0.0613, -0.0918,  0.0292,
        -0.0852, -0.0703,  0.0822, -0.1492, -0.0361, -0.1641, -0.0477, -0.0022,
        -0.1268, -0.0582, -0.1183, -0.0648,  0.0213,  0.0013, -0.0564, -0.1232,
        -0.1235, -0.0337, -0.0963, -0.0962, -0.2822, -0.1090,  0.0129,  0.1223,
        -0.0721, -0.0724, -0.0813,  0.0535, -0.1931, -0.0372, -0.0008, -0.0819,
        -0.0574,  0.0187, -0.0991,  0.0388, -0.0557, -0.1712,  0.0566,  0.0063,
        -0.0672, -0.1277,  0.0341, -0.0269,  0.1025, -0.2905, -0.1057, -0.0019,
        -0.0600, -0.0032,  0.0386, -0.1322, -0.0920, -0.1710, -0.0893,  0.0161,
        -0.0464, -0.0393, -0.0209, -0.1177, -0.0239,  0.0315, -0.0667, -0.1227,
        -0.1410,  0.0343, -0.1202,  0.0081, -0.0732, -0.0449, -0.0055, -0.1263,
        -0.1417, -0.0042, -0.0265, -0.1114,  0.0582, -0.1254, -0.1844, -0.0651,
        -0.0074, -0.0655, -0.1518, -0.1280, -0.1401, -0.0458, -0.0709, -0.0920,
        -0.0415, -0.0849, -0.1697,  0.0894, -0.0280,  0.0582, -0.0934, -0.0470,
        -0.0507, -0.1001, -0.0844, -0.1299, -0.0520, -0.0738, -0.0156, -0.0718,
        -0.0957, -0.0470,  0.0427, -0.1093, -0.0869, -0.1105, -0.0823, -0.0963,
         0.0344, -0.1521, -0.1039,  0.0176, -0.0438, -0.1933, -0.0600, -0.1159,
        -0.0132, -0.0875, -0.0680, -0.0077, -0.1592, -0.1011, -0.1258, -0.1970,
        -0.1425, -0.0602,  0.0587,  0.0267, -0.0239, -0.0666,  0.0211,  0.0286,
        -0.1537,  0.0186,  0.0302, -0.0108, -0.0330,  0.1028, -0.0963,  0.0684,
        -0.0964, -0.0970,  0.0210,  0.0677, -0.0203,  0.0054, -0.0497, -0.0596,
        -0.0856, -0.0693, -0.1200,  0.0571, -0.1325, -0.0950, -0.1148, -0.0355,
        -0.0258,  0.0201, -0.1106, -0.0670, -0.1780, -0.2506,  0.0241,  0.0683,
        -0.1151, -0.0195, -0.0480, -0.0369, -0.1951,  0.0496, -0.2126, -0.0325,
        -0.1581,  0.0519, -0.0833,  0.0021, -0.1191, -0.1637, -0.0304, -0.0013,
        -0.1409,  0.0056, -0.0010, -0.1373, -0.0827,  0.0297,  0.0714, -0.0723,
        -0.1040, -0.1262, -0.0401, -0.0221, -0.1932, -0.1022,  0.0758, -0.1132,
        -0.0578, -0.1914, -0.0476, -0.0094, -0.0347, -0.0933, -0.0894, -0.1513,
         0.0010, -0.0458,  0.0812, -0.1199, -0.0766, -0.0476,  0.0286, -0.0918,
        -0.0688,  0.0699,  0.0290,  0.0192, -0.0831, -0.0508,  0.0582, -0.1692,
        -0.1388, -0.0611, -0.0868, -0.0451, -0.0268, -0.0189,  0.0707, -0.0498,
         0.0400,  0.0645,  0.0005, -0.0355, -0.0366,  0.0054, -0.0469, -0.0520,
        -0.0763, -0.0599,  0.0172, -0.1471, -0.0851, -0.0707, -0.1120, -0.0106,
        -0.0512, -0.0257, -0.1275, -0.0920, -0.0125, -0.1344, -0.0797, -0.0987,
         0.1355, -0.0918, -0.0406, -0.1146, -0.0863, -0.0252,  0.0455, -0.1485,
        -0.1146, -0.0747, -0.0336, -0.0750,  0.0003, -0.1610, -0.0003,  0.0308,
        -0.1802,  0.0310, -0.0119, -0.0453, -0.0369, -0.1580, -0.1455, -0.0438,
        -0.0624, -0.1231, -0.0554, -0.1970, -0.0004, -0.0656, -0.1278, -0.1473,
        -0.0563, -0.0980, -0.1143,  0.0039, -0.1432, -0.1364, -0.0657, -0.0340,
        -0.0428, -0.0789,  0.0183,  0.0020,  0.0630,  0.0229,  0.0052, -0.1396,
        -0.2126, -0.0815, -0.0206, -0.1020, -0.1136,  0.0698, -0.0344, -0.1062,
        -0.0053, -0.2031, -0.0767, -0.0252, -0.0978, -0.1342, -0.1104, -0.0474,
        -0.0493, -0.0133, -0.0007, -0.0752, -0.1993, -0.0548, -0.0675,  0.0235,
         0.0089, -0.0950, -0.1566,  0.0148, -0.1062, -0.1005,  0.0326, -0.0817,
        -0.0135, -0.0189, -0.0321, -0.0559,  0.0241,  0.0011, -0.0850, -0.0791,
        -0.1581, -0.1010,  0.0875, -0.1373, -0.1471, -0.0593, -0.1445, -0.1129,
         0.0422, -0.0138,  0.0196, -0.0358, -0.0431, -0.0788, -0.0848, -0.1389,
        -0.2120, -0.0127, -0.0349, -0.0667, -0.1802,  0.0678, -0.1307, -0.1461,
         0.0020, -0.0502, -0.0709, -0.0785, -0.1944, -0.1243, -0.0203, -0.1772,
        -0.0301, -0.0993, -0.1463,  0.0246, -0.0363, -0.0905, -0.0785, -0.0600],
       device='cuda:0', requires_grad=True)
Param: encoder.layer4.0.conv2.weight
	Parameter containing:
tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0016,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0016,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0016,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0016,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0016,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0016,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0016,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0016,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0016,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0016,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0016,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0016,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0016,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0016,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0016,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0016,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0016,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0016,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0', requires_grad=True)
Param: encoder.layer4.0.bn2.weight
	Parameter containing:
tensor([0.9606, 0.9895, 0.9447, 0.9987, 1.1024, 1.1267, 0.9988, 1.1569, 1.0726,
        1.0881, 1.0012, 0.9055, 1.0138, 1.0043, 1.0983, 1.0331, 1.1074, 1.1026,
        0.9924, 1.0724, 1.0386, 1.0443, 1.0902, 1.0548, 0.9769, 1.0724, 1.0107,
        1.0770, 0.9836, 1.0261, 0.9347, 1.0304, 0.9477, 0.9538, 0.9758, 1.0518,
        0.9463, 1.0817, 1.1345, 1.0009, 1.0312, 1.0589, 1.0310, 0.9660, 1.0923,
        1.1082, 1.0581, 0.9914, 0.9734, 1.0367, 0.9613, 0.9937, 1.1405, 1.0780,
        1.1183, 1.1542, 0.9451, 0.9900, 0.9853, 1.0231, 1.0976, 0.9471, 1.0380,
        1.1105, 1.0709, 0.9733, 1.0526, 0.9361, 1.1361, 1.0424, 1.0630, 1.0483,
        1.0631, 1.0392, 1.0526, 0.9681, 1.0816, 1.1387, 1.1220, 1.0226, 1.0824,
        1.0758, 1.0967, 1.0069, 1.0688, 1.0213, 1.1456, 0.9789, 1.1301, 0.9565,
        0.9997, 1.0641, 0.9994, 1.0653, 1.0609, 1.2014, 1.1554, 1.0663, 1.0321,
        1.0799, 1.0118, 1.1024, 0.9549, 1.1080, 1.0683, 0.9601, 1.0375, 0.9595,
        1.0617, 1.0924, 0.9451, 1.0008, 1.0304, 1.0317, 0.9228, 1.0059, 1.1398,
        0.9995, 1.0533, 1.1138, 1.0596, 0.9547, 1.0516, 0.9733, 1.0039, 1.1102,
        0.9736, 0.9451, 0.9977, 1.0947, 1.0889, 0.9266, 0.9757, 1.0182, 0.9528,
        0.9802, 1.0054, 1.0171, 1.0896, 0.9888, 1.1555, 1.0664, 0.9499, 1.0456,
        1.0859, 1.0433, 0.9857, 1.0962, 1.0331, 1.1113, 1.0223, 1.0294, 0.8710,
        1.2129, 0.9897, 1.1380, 0.9899, 1.0917, 1.1150, 1.0949, 0.9955, 1.0993,
        1.0629, 0.9324, 1.0434, 1.1392, 1.0682, 1.1161, 0.9650, 1.0683, 1.0766,
        1.0573, 1.0719, 0.9506, 1.0473, 1.0256, 1.0602, 1.0675, 1.0504, 1.0851,
        0.9501, 1.1416, 1.0615, 1.0473, 1.0580, 0.9893, 1.0651, 1.1033, 1.1167,
        1.0186, 1.0808, 1.1280, 1.0782, 0.9730, 1.0966, 1.0417, 1.0380, 1.0791,
        0.9722, 1.0442, 1.0646, 0.9555, 1.0604, 1.0211, 1.0166, 1.0784, 1.0538,
        1.0817, 1.0207, 0.9395, 0.9928, 0.9371, 1.0633, 1.1276, 0.8938, 0.8696,
        1.0286, 1.0603, 1.1118, 1.1553, 1.1019, 1.1349, 1.0419, 1.0075, 0.9801,
        1.0501, 1.0511, 1.0774, 1.0236, 1.0287, 1.0228, 1.0806, 0.8425, 1.0550,
        1.0766, 1.0114, 1.0877, 1.1361, 1.0911, 1.0832, 1.0385, 1.0127, 0.9486,
        1.0111, 0.9471, 0.9725, 1.0230, 1.0439, 1.0075, 1.0114, 0.9786, 1.0776,
        1.1156, 1.0190, 1.0967, 1.1317, 1.0846, 1.0762, 0.9685, 1.0601, 1.0652,
        0.9950, 1.0180, 1.0253, 1.0187, 1.1024, 1.0593, 1.0538, 1.0542, 1.1503,
        1.0477, 1.0459, 1.0377, 0.9848, 1.0778, 1.1432, 1.0523, 0.9757, 1.1711,
        1.1125, 1.0865, 0.9761, 1.1730, 1.0840, 0.9676, 1.0521, 0.9423, 1.0714,
        1.0514, 0.9807, 1.0229, 1.0102, 1.0862, 1.0277, 1.0277, 1.0390, 1.1038,
        1.0530, 0.9496, 1.0542, 0.9927, 0.9768, 1.0120, 1.0892, 1.1542, 1.0648,
        1.0076, 1.1321, 0.9511, 1.0993, 1.0080, 0.9554, 1.0216, 1.0935, 1.0268,
        1.0635, 1.0371, 1.0490, 1.0517, 0.9182, 0.9856, 1.0802, 1.1487, 1.1178,
        1.0676, 0.9771, 1.1340, 1.0280, 1.1300, 0.9987, 0.9537, 1.0444, 1.0112,
        1.0404, 1.0720, 1.1492, 1.1145, 0.9732, 0.9709, 1.1016, 1.0278, 1.0037,
        1.0610, 1.0343, 1.0294, 1.0691, 1.0003, 0.9717, 1.1180, 0.9143, 1.0905,
        1.1328, 1.1449, 1.0074, 0.9648, 1.0117, 1.0195, 1.1131, 0.9795, 1.1196,
        0.9676, 0.9843, 1.0431, 1.0274, 1.1272, 1.1796, 1.0095, 1.1207, 1.0567,
        1.0373, 1.0266, 1.0479, 0.9599, 1.0524, 0.9853, 1.1569, 1.0227, 0.8737,
        1.0680, 0.9635, 1.0259, 0.9611, 1.0633, 0.9925, 1.0216, 1.0675, 0.9166,
        1.1239, 1.0762, 1.0465, 1.0158, 1.0108, 1.0122, 1.0163, 1.1061, 1.0028,
        1.1431, 1.1613, 1.0409, 0.9126, 1.0492, 1.0152, 0.9981, 0.9942, 1.0572,
        0.9982, 1.0514, 1.0708, 1.1498, 1.1466, 1.0748, 1.0515, 1.0511, 1.0964,
        1.0481, 1.0551, 1.0590, 1.1351, 0.9777, 1.0739, 1.0201, 0.9757, 0.9730,
        1.1062, 1.1228, 1.0603, 1.0147, 0.9185, 0.9616, 1.0162, 1.0252, 1.1127,
        0.9579, 1.0070, 1.0384, 1.0520, 1.1980, 1.0856, 0.9834, 0.9335, 1.0626,
        1.0874, 0.9618, 1.1041, 0.8329, 0.8630, 1.0147, 1.0401, 0.9799, 0.9587,
        1.0852, 1.0727, 1.0289, 1.0977, 1.0048, 1.0017, 1.0154, 1.0247, 1.0826,
        1.1011, 1.2420, 1.0185, 0.9980, 1.0954, 1.0010, 0.9977, 1.1858, 1.0771,
        1.1224, 1.0007, 1.0944, 1.1061, 1.0951, 1.0812, 1.0212, 1.0836, 1.0095,
        1.0890, 1.0613, 0.9862, 1.0077, 1.0171, 1.1127, 1.0184, 0.9712, 1.0170,
        1.0233, 1.0398, 0.9843, 1.1152, 0.9826, 1.1436, 0.9821, 0.9808, 0.9077,
        0.9992, 1.0294, 0.9941, 1.0044, 1.0327, 1.1222, 1.0633, 0.9315, 0.9852,
        1.0700, 0.8698, 1.0950, 1.0966, 1.0374, 1.0866, 1.0022, 1.0195],
       device='cuda:0', requires_grad=True)
Param: encoder.layer4.0.bn2.bias
	Parameter containing:
tensor([ 1.2557e-02, -3.4510e-02, -9.5699e-02, -3.4962e-02, -8.1041e-02,
         2.1014e-02, -1.5412e-02,  6.2073e-02, -1.8034e-02,  1.2377e-01,
        -7.1079e-02,  2.4216e-03, -1.0072e-01, -6.5893e-02,  5.0141e-02,
        -1.2052e-01,  2.7968e-03, -2.9625e-03,  1.7702e-02, -3.3288e-02,
        -2.5006e-02, -8.3974e-02, -3.3259e-03,  5.0014e-03, -1.6111e-01,
        -1.0494e-01,  2.0428e-02, -6.5319e-02, -1.4515e-02, -6.7769e-02,
        -8.5462e-03, -8.5958e-02, -1.2075e-01, -3.0047e-02,  3.0146e-03,
         1.9226e-02,  2.9345e-03,  1.5996e-02,  1.5846e-02, -3.3887e-02,
         4.5219e-02,  6.7827e-03,  2.8417e-02, -3.9599e-02,  1.4430e-02,
        -5.4591e-03, -3.3476e-02, -1.1987e-01, -5.0119e-02, -1.5952e-02,
        -2.4094e-02, -1.8293e-01, -7.1031e-03,  8.4063e-02,  1.7285e-02,
        -8.1644e-02, -1.8208e-01, -1.9260e-01, -9.3939e-02,  4.7441e-02,
         7.2421e-02,  6.1495e-03, -5.2822e-02, -4.5970e-02,  2.8795e-02,
        -2.5511e-02, -1.6583e-02, -1.6825e-02, -4.1354e-02, -6.3390e-03,
        -4.5240e-02,  2.1038e-02,  1.4648e-02,  2.8920e-02, -3.3989e-02,
        -4.7873e-02, -4.2247e-02, -7.0389e-02, -8.2068e-03,  3.5695e-02,
        -1.7177e-03,  6.1366e-02, -2.6115e-02, -1.4712e-02, -1.1621e-01,
        -3.1765e-02, -3.8005e-02, -1.5311e-01, -2.0629e-02, -1.4043e-01,
         1.2084e-02, -7.2977e-02, -6.1450e-02, -8.8252e-02, -7.7029e-03,
        -6.4317e-02,  1.9280e-02,  5.5691e-02,  4.6258e-02,  6.8354e-03,
        -1.0551e-02, -1.4447e-02, -6.6787e-02,  4.5308e-02, -1.7157e-02,
        -3.9136e-02, -1.0636e-02, -3.9473e-03, -1.0854e-01, -8.4404e-02,
        -2.4289e-02, -4.0809e-02, -5.9162e-02,  1.1397e-03,  6.8425e-02,
        -6.5858e-02, -3.4812e-02, -5.7542e-02, -3.3856e-02,  4.3957e-02,
        -4.7755e-02, -6.5255e-02, -1.1840e-02, -5.4892e-02,  1.5661e-02,
         9.7595e-02, -5.3090e-02, -2.3233e-02, -1.4707e-01,  3.1267e-02,
        -7.4172e-03, -3.0385e-02, -2.1151e-01, -5.9187e-02, -8.8411e-02,
        -1.7644e-02, -2.1784e-02, -2.0753e-02,  1.8969e-02, -6.7719e-02,
         4.9478e-02,  2.0436e-02, -1.3391e-01,  9.0158e-02, -2.9760e-02,
        -7.5535e-02, -5.5353e-02,  7.1362e-03, -3.4729e-02, -4.2101e-02,
        -8.0184e-02, -7.5549e-02, -2.0761e-01, -5.8410e-02,  5.0635e-02,
        -6.5215e-02,  3.7501e-02,  9.7702e-03,  1.6800e-02, -1.9360e-02,
         2.1214e-02, -7.5223e-02, -6.6893e-02, -1.2670e-01, -4.4671e-02,
        -2.8157e-02, -1.8812e-02, -7.2641e-02, -8.7250e-02, -6.2231e-02,
         5.3537e-02, -7.3826e-02,  1.5696e-02, -4.2454e-02, -2.0268e-02,
        -7.1388e-02, -2.2256e-02, -2.6457e-03, -4.9665e-02,  2.7209e-02,
        -1.0178e-01, -4.3298e-02, -1.0035e-01, -1.9922e-02,  8.1337e-03,
        -6.7757e-02,  1.1037e-01, -6.6142e-03, -8.8029e-02, -1.9672e-02,
         1.1103e-02, -9.6295e-03, -3.1717e-02, -8.0892e-03, -2.6171e-02,
         5.3878e-02,  1.1554e-02, -1.5085e-02, -1.0581e-01, -7.9620e-02,
         3.8086e-02,  9.2058e-04, -1.1589e-02,  1.1777e-02, -4.9729e-04,
         3.0914e-02, -3.8442e-02,  8.9028e-02, -5.0105e-02, -6.3620e-02,
        -9.9753e-02, -1.0059e-01, -8.9605e-03,  2.3206e-02, -1.8420e-01,
        -9.9346e-02, -5.1684e-02, -7.5532e-02,  1.7784e-02,  3.7303e-02,
        -4.3954e-02, -3.7832e-02,  1.7912e-02, -2.7769e-02, -1.1113e-01,
        -4.7085e-02,  1.0036e-03,  2.2654e-03,  2.6136e-02,  3.2379e-02,
        -1.2202e-01, -1.4276e-02, -1.2450e-02, -2.8245e-02, -1.8092e-02,
         5.3545e-02, -6.9918e-02, -9.9450e-02, -3.6917e-02, -1.0529e-01,
        -6.3872e-02,  4.9654e-03, -1.5427e-02, -1.1378e-01, -2.6185e-02,
         3.5076e-02, -1.1756e-01,  2.2707e-02, -5.1129e-02,  1.3128e-02,
        -1.1774e-02, -3.7682e-02,  6.8485e-03, -1.6407e-02,  5.3049e-02,
         1.5737e-02, -5.0535e-02,  4.1970e-02, -7.1631e-02,  1.3517e-03,
        -7.7581e-02, -1.1662e-02, -2.2467e-02, -9.9832e-02, -1.2775e-02,
        -9.0801e-02, -4.9489e-02, -3.1558e-02, -7.3381e-02,  7.4397e-02,
         6.7714e-03, -7.5495e-02,  7.5317e-02,  3.1609e-03, -9.2787e-02,
         3.7286e-03, -1.1012e-02, -7.3831e-02, -6.3583e-02, -1.1672e-02,
         1.3785e-02, -1.2373e-01, -3.6602e-02, -5.9431e-02, -5.9879e-02,
        -1.9944e-02, -1.2920e-01,  8.7528e-04, -2.4643e-02, -4.2501e-04,
        -6.8449e-02,  4.9533e-02,  1.3231e-02,  2.9516e-03,  7.7085e-02,
         1.6776e-02,  3.6549e-02,  4.8235e-02, -1.0302e-01,  5.1425e-03,
        -3.7529e-02,  9.8040e-04,  4.7065e-02, -2.4276e-02,  8.2564e-02,
         1.1704e-02, -8.1790e-02, -2.9285e-02,  2.1505e-03,  1.1538e-02,
        -5.1537e-03, -7.3970e-03, -1.2592e-01,  8.7202e-02,  3.3054e-02,
        -6.2491e-02,  1.2622e-03,  8.5898e-02,  6.6801e-02, -6.9260e-02,
        -1.2517e-01, -7.2013e-02, -1.1775e-02,  3.1026e-02, -1.5754e-01,
        -1.5252e-01, -6.1606e-02, -2.6766e-02,  2.4808e-02, -1.8789e-02,
        -3.3857e-02,  3.6919e-02,  6.5840e-02, -1.0816e-02,  2.6390e-03,
        -4.0511e-02,  4.0922e-02,  8.2421e-02,  5.6457e-02, -2.9484e-02,
        -7.2969e-02, -6.2644e-02, -5.7880e-02, -9.5500e-02, -1.3269e-02,
        -4.7556e-02, -8.9284e-02, -6.5450e-02, -5.9416e-02, -4.0735e-02,
        -4.2521e-02,  4.9757e-02,  9.6847e-03, -1.0386e-01, -8.7419e-03,
         3.9260e-02,  1.8632e-02, -2.4638e-02, -7.5218e-02, -9.0341e-02,
        -9.8209e-02, -9.3193e-02, -3.7894e-02,  2.7957e-02,  2.2001e-02,
        -6.1645e-02, -9.6039e-02, -2.3543e-01, -2.5407e-02, -9.7050e-03,
        -8.0836e-02, -5.9588e-02, -2.4652e-01, -3.5072e-02, -1.5717e-01,
        -4.6511e-03, -4.4432e-02, -1.1239e-01, -5.5706e-02,  1.5125e-03,
        -8.6480e-02, -4.0682e-02, -1.6409e-01, -2.0359e-02,  4.4605e-02,
        -9.2675e-02, -1.4511e-01, -8.9242e-02, -3.9843e-02, -7.9482e-03,
         1.0453e-02, -6.4067e-02, -6.3126e-02, -5.1381e-02, -9.0947e-02,
        -3.7384e-02, -4.0583e-02, -1.0263e-02,  4.2012e-02, -7.6674e-04,
        -1.3007e-02, -2.0721e-02, -6.1431e-02, -8.3795e-02,  1.1955e-02,
        -6.3821e-02, -2.9414e-03, -3.2345e-02, -4.2489e-02, -1.7660e-02,
         6.4783e-03, -2.8175e-02, -2.1898e-02, -3.6762e-02,  6.6746e-02,
        -5.7793e-02,  1.8975e-02,  4.6668e-02, -9.2695e-02, -4.2569e-03,
        -1.9443e-02, -6.4407e-02, -7.5846e-02,  8.6789e-02, -2.9930e-02,
        -7.8688e-02, -1.0259e-01, -3.3415e-03, -4.5228e-02, -6.6855e-02,
        -2.4670e-02, -1.2042e-01, -1.3362e-01, -1.0409e-01, -2.0383e-01,
        -9.0248e-02, -1.6292e-02, -6.1261e-02, -9.9040e-02, -6.2202e-02,
         6.8741e-02,  2.9185e-03, -1.3225e-02, -3.7504e-02,  1.6589e-03,
        -4.3154e-02,  8.3925e-02, -4.0735e-02, -1.0433e-01, -6.1051e-02,
         3.4171e-03, -1.0199e-01, -1.1452e-01, -6.9225e-02, -1.1300e-01,
        -2.2198e-02,  6.1297e-02, -1.2565e-02,  2.9758e-02, -1.2469e-01,
        -5.5992e-05, -1.0240e-01, -4.3720e-02,  5.4557e-03, -6.1504e-02,
        -1.2013e-01, -9.8159e-02, -2.4193e-02, -2.3596e-02, -5.9358e-02,
         6.9610e-02, -1.1845e-01,  9.9327e-03, -4.8936e-02,  3.7809e-02,
         1.6006e-02, -1.1894e-01,  1.3980e-02, -9.2628e-03,  2.0739e-03,
        -5.1735e-02,  6.1215e-02, -1.4201e-02, -3.4982e-02,  4.4506e-02,
        -1.1805e-01,  3.2304e-02,  1.0677e-02,  2.5806e-03,  3.2007e-02,
        -6.3287e-02, -4.0977e-02,  6.7292e-02, -8.4978e-02, -1.0107e-01,
        -9.8503e-04, -4.6954e-02,  2.3721e-02, -2.0580e-02, -8.9808e-02,
        -5.4493e-02,  7.0147e-02, -6.7757e-02,  7.2880e-02, -4.1892e-02,
        -6.2788e-02,  4.0507e-03,  1.0685e-02, -2.8471e-02, -2.2416e-02,
        -8.2918e-02, -2.7621e-02], device='cuda:0', requires_grad=True)
Param: encoder.layer4.0.shortcut.0.weight
	Parameter containing:
tensor([[[[ 0.0471]],

         [[ 0.0195]],

         [[ 0.0455]],

         ...,

         [[ 0.0820]],

         [[-0.0212]],

         [[-0.0249]]],


        [[[ 0.0607]],

         [[-0.0250]],

         [[-0.0227]],

         ...,

         [[ 0.0305]],

         [[ 0.0429]],

         [[-0.0493]]],


        [[[-0.0567]],

         [[ 0.0838]],

         [[-0.0508]],

         ...,

         [[ 0.0078]],

         [[ 0.0730]],

         [[ 0.0004]]],


        ...,


        [[[-0.0278]],

         [[-0.0034]],

         [[ 0.0486]],

         ...,

         [[-0.0117]],

         [[-0.0215]],

         [[ 0.0043]]],


        [[[-0.0560]],

         [[-0.1079]],

         [[-0.0273]],

         ...,

         [[-0.0150]],

         [[ 0.0136]],

         [[ 0.0381]]],


        [[[-0.0493]],

         [[ 0.0363]],

         [[ 0.0488]],

         ...,

         [[ 0.0243]],

         [[-0.0166]],

         [[-0.0425]]]], device='cuda:0', requires_grad=True)
Param: encoder.layer4.0.shortcut.1.weight
	Parameter containing:
tensor([1.1105, 0.9860, 0.9720, 0.9828, 0.9722, 1.1065, 1.0994, 0.9971, 1.0483,
        1.1636, 0.9424, 1.1322, 0.9767, 1.0569, 1.1051, 0.9722, 1.0161, 1.0085,
        1.0764, 1.0420, 1.1093, 1.0640, 1.1410, 1.0416, 1.0309, 0.8637, 1.1625,
        1.0469, 1.0411, 1.0178, 0.9542, 1.0120, 0.9342, 1.0172, 1.0758, 1.0532,
        1.0899, 1.0950, 1.0152, 1.1367, 1.0919, 1.0893, 1.0921, 0.9571, 1.0375,
        1.1005, 1.1379, 0.9707, 1.1385, 1.0417, 1.0481, 0.9436, 0.9438, 1.0856,
        0.9991, 1.0198, 0.9801, 0.8886, 1.0199, 1.0059, 1.0410, 1.0131, 1.0694,
        1.0644, 1.1032, 1.1238, 1.0568, 1.0922, 1.0185, 1.0634, 1.0501, 1.1780,
        1.0758, 1.0257, 1.0692, 1.1109, 1.0805, 0.8867, 1.0501, 1.0906, 1.0582,
        1.0812, 0.9949, 1.0702, 0.9271, 1.1589, 0.9973, 0.9095, 1.1294, 0.9953,
        1.0817, 0.9999, 1.0147, 0.9723, 0.9481, 1.0860, 1.0532, 1.1278, 1.0229,
        1.1136, 1.0357, 0.9520, 0.9859, 1.0185, 1.0342, 0.9821, 1.0619, 1.0409,
        0.9779, 0.9377, 1.0655, 0.9878, 1.0943, 1.1056, 1.2509, 0.9587, 0.9749,
        1.0408, 1.0094, 1.0697, 0.9346, 1.0321, 1.0515, 0.9952, 1.1493, 1.0413,
        0.9533, 1.1068, 0.9783, 1.1080, 1.0893, 1.0024, 0.9980, 1.1819, 1.0709,
        1.0775, 1.0162, 1.1136, 1.0900, 1.1123, 1.1509, 1.0854, 1.0946, 1.1861,
        1.0192, 1.0637, 1.0532, 1.0958, 1.1686, 0.9900, 0.9788, 1.1023, 0.9360,
        0.9066, 1.2360, 1.0071, 1.0239, 1.0032, 0.9982, 0.9598, 1.0502, 1.1827,
        1.0425, 1.0358, 0.9890, 1.0355, 0.9926, 1.0313, 1.0960, 0.9948, 1.0355,
        1.0392, 0.9899, 1.0417, 1.0605, 1.0568, 1.0065, 1.0689, 1.0655, 1.0693,
        1.0139, 0.9599, 0.9265, 0.9910, 1.0513, 0.9478, 1.0499, 1.0691, 1.0764,
        1.0630, 1.0448, 1.0191, 1.0568, 1.1233, 1.0383, 1.1725, 1.0698, 1.0077,
        1.0266, 1.1207, 1.1133, 1.1614, 1.0335, 1.0213, 1.1659, 1.0607, 1.0297,
        1.0643, 1.0698, 1.0700, 1.1615, 1.0158, 1.0636, 1.0081, 1.0705, 0.9940,
        0.9398, 1.0648, 0.9463, 1.0132, 0.9838, 0.9281, 1.1030, 0.9733, 1.0316,
        1.0566, 1.0768, 0.9347, 1.1499, 1.0084, 1.0253, 1.1189, 1.2320, 1.0523,
        1.0969, 1.1245, 1.1519, 1.0079, 0.9777, 1.0411, 0.9867, 1.0498, 1.0779,
        1.0426, 1.0798, 1.2078, 0.9758, 1.1029, 1.0490, 1.1338, 1.0315, 1.0357,
        1.0721, 1.0560, 1.0334, 1.1090, 1.0079, 1.0159, 1.0104, 0.9479, 1.0867,
        0.9934, 0.9680, 0.9386, 1.1147, 1.0218, 1.0548, 1.0432, 0.9663, 1.1212,
        0.9249, 0.9749, 1.0949, 1.1553, 0.8925, 1.0457, 1.1099, 0.9982, 0.9102,
        1.0546, 1.0403, 1.1001, 0.9200, 1.0175, 1.1179, 1.0396, 0.9296, 1.0937,
        1.0643, 1.0847, 0.9814, 1.1027, 1.0942, 1.0434, 0.9922, 0.9855, 1.0374,
        1.1656, 0.9854, 1.1723, 1.0356, 1.0387, 1.1071, 1.0387, 1.0098, 1.0716,
        1.0573, 1.0269, 1.1271, 1.0820, 1.0126, 1.1080, 1.0384, 1.2257, 1.1452,
        0.9993, 1.0351, 1.1778, 1.0826, 0.8804, 0.9546, 0.9949, 1.0832, 1.0585,
        0.8425, 0.8786, 1.0806, 1.1299, 1.1308, 1.0010, 1.0363, 1.0061, 1.0534,
        1.1344, 1.1543, 1.0953, 1.0124, 1.1599, 1.1292, 1.0284, 1.0445, 0.9447,
        1.0272, 1.0132, 1.0739, 1.1557, 0.9831, 1.0677, 1.0557, 1.0001, 1.0466,
        1.0452, 0.9751, 1.0038, 1.0618, 1.1297, 1.1236, 1.0304, 0.9889, 1.0488,
        1.0345, 1.0542, 0.9679, 1.0825, 0.9560, 1.0656, 0.9586, 1.1055, 1.0311,
        1.0030, 1.0713, 1.0643, 1.1292, 1.0319, 1.0198, 0.9957, 0.9930, 1.0432,
        0.9608, 1.1226, 1.0034, 1.0402, 0.9205, 1.0460, 0.9846, 1.0862, 1.0214,
        1.0099, 0.8950, 1.0579, 1.0914, 1.0738, 1.0425, 0.9929, 1.0207, 1.1057,
        1.0757, 1.0024, 1.1409, 1.2199, 1.1084, 1.1118, 1.0541, 1.0623, 1.1101,
        1.1001, 1.0351, 1.0025, 1.0712, 1.1134, 1.0164, 1.1333, 1.0056, 0.9725,
        1.0911, 0.9368, 0.9400, 1.0176, 0.9774, 1.0826, 1.0906, 1.0899, 0.9871,
        1.1811, 1.0040, 0.9685, 1.0284, 1.1119, 1.0837, 1.0351, 0.9201, 1.0957,
        0.9771, 0.9641, 0.9385, 1.0057, 1.0774, 1.0635, 0.9669, 1.0049, 1.0347,
        1.0245, 1.0721, 0.9957, 1.0597, 1.0814, 1.1521, 0.9275, 1.0241, 1.0029,
        1.0678, 0.9734, 1.0361, 1.0487, 0.9957, 1.0908, 1.1920, 1.0264, 1.0624,
        0.9578, 0.9568, 1.0006, 1.0614, 1.1146, 0.9585, 1.0177, 0.9898, 0.9323,
        1.0528, 1.0608, 1.0511, 0.9459, 1.0529, 1.0992, 1.1151, 1.1404, 1.0243,
        1.0742, 1.0281, 1.1374, 1.0049, 1.1301, 1.0143, 1.1249, 1.1992, 1.0265,
        1.1371, 1.0418, 1.1021, 0.9938, 1.0834, 1.1006, 1.1209, 1.0421, 1.0242,
        1.1715, 0.9726, 1.0550, 1.0745, 1.0274, 1.0347, 1.0555, 1.0594, 1.0397,
        1.0609, 1.1253, 1.0859, 0.9613, 0.9433, 1.0883, 1.0824, 0.9674],
       device='cuda:0', requires_grad=True)
Param: encoder.layer4.0.shortcut.1.bias
	Parameter containing:
tensor([ 1.2557e-02, -3.4510e-02, -9.5699e-02, -3.4962e-02, -8.1041e-02,
         2.1014e-02, -1.5412e-02,  6.2073e-02, -1.8034e-02,  1.2377e-01,
        -7.1079e-02,  2.4216e-03, -1.0072e-01, -6.5893e-02,  5.0141e-02,
        -1.2052e-01,  2.7968e-03, -2.9625e-03,  1.7702e-02, -3.3288e-02,
        -2.5006e-02, -8.3974e-02, -3.3259e-03,  5.0014e-03, -1.6111e-01,
        -1.0494e-01,  2.0428e-02, -6.5319e-02, -1.4515e-02, -6.7769e-02,
        -8.5462e-03, -8.5958e-02, -1.2075e-01, -3.0047e-02,  3.0146e-03,
         1.9226e-02,  2.9345e-03,  1.5996e-02,  1.5846e-02, -3.3887e-02,
         4.5219e-02,  6.7827e-03,  2.8417e-02, -3.9599e-02,  1.4430e-02,
        -5.4591e-03, -3.3476e-02, -1.1987e-01, -5.0119e-02, -1.5952e-02,
        -2.4094e-02, -1.8293e-01, -7.1031e-03,  8.4063e-02,  1.7285e-02,
        -8.1644e-02, -1.8208e-01, -1.9260e-01, -9.3939e-02,  4.7441e-02,
         7.2421e-02,  6.1495e-03, -5.2822e-02, -4.5970e-02,  2.8795e-02,
        -2.5511e-02, -1.6583e-02, -1.6825e-02, -4.1354e-02, -6.3390e-03,
        -4.5240e-02,  2.1038e-02,  1.4648e-02,  2.8920e-02, -3.3989e-02,
        -4.7873e-02, -4.2247e-02, -7.0389e-02, -8.2068e-03,  3.5695e-02,
        -1.7177e-03,  6.1366e-02, -2.6115e-02, -1.4712e-02, -1.1621e-01,
        -3.1765e-02, -3.8005e-02, -1.5311e-01, -2.0629e-02, -1.4043e-01,
         1.2084e-02, -7.2977e-02, -6.1450e-02, -8.8252e-02, -7.7029e-03,
        -6.4317e-02,  1.9280e-02,  5.5691e-02,  4.6258e-02,  6.8354e-03,
        -1.0551e-02, -1.4447e-02, -6.6787e-02,  4.5308e-02, -1.7157e-02,
        -3.9136e-02, -1.0636e-02, -3.9473e-03, -1.0854e-01, -8.4404e-02,
        -2.4289e-02, -4.0809e-02, -5.9162e-02,  1.1397e-03,  6.8425e-02,
        -6.5858e-02, -3.4812e-02, -5.7542e-02, -3.3856e-02,  4.3957e-02,
        -4.7755e-02, -6.5255e-02, -1.1840e-02, -5.4892e-02,  1.5661e-02,
         9.7595e-02, -5.3090e-02, -2.3233e-02, -1.4707e-01,  3.1267e-02,
        -7.4172e-03, -3.0385e-02, -2.1151e-01, -5.9187e-02, -8.8411e-02,
        -1.7644e-02, -2.1784e-02, -2.0753e-02,  1.8969e-02, -6.7719e-02,
         4.9478e-02,  2.0436e-02, -1.3391e-01,  9.0158e-02, -2.9760e-02,
        -7.5535e-02, -5.5353e-02,  7.1362e-03, -3.4729e-02, -4.2101e-02,
        -8.0184e-02, -7.5549e-02, -2.0761e-01, -5.8410e-02,  5.0635e-02,
        -6.5215e-02,  3.7501e-02,  9.7702e-03,  1.6800e-02, -1.9360e-02,
         2.1214e-02, -7.5223e-02, -6.6893e-02, -1.2670e-01, -4.4671e-02,
        -2.8157e-02, -1.8812e-02, -7.2641e-02, -8.7250e-02, -6.2231e-02,
         5.3537e-02, -7.3826e-02,  1.5696e-02, -4.2454e-02, -2.0268e-02,
        -7.1388e-02, -2.2256e-02, -2.6457e-03, -4.9665e-02,  2.7209e-02,
        -1.0178e-01, -4.3298e-02, -1.0035e-01, -1.9922e-02,  8.1337e-03,
        -6.7757e-02,  1.1037e-01, -6.6142e-03, -8.8029e-02, -1.9672e-02,
         1.1103e-02, -9.6295e-03, -3.1717e-02, -8.0892e-03, -2.6171e-02,
         5.3878e-02,  1.1554e-02, -1.5085e-02, -1.0581e-01, -7.9620e-02,
         3.8086e-02,  9.2058e-04, -1.1589e-02,  1.1777e-02, -4.9729e-04,
         3.0914e-02, -3.8442e-02,  8.9028e-02, -5.0105e-02, -6.3620e-02,
        -9.9753e-02, -1.0059e-01, -8.9605e-03,  2.3206e-02, -1.8420e-01,
        -9.9346e-02, -5.1684e-02, -7.5532e-02,  1.7784e-02,  3.7303e-02,
        -4.3954e-02, -3.7832e-02,  1.7912e-02, -2.7769e-02, -1.1113e-01,
        -4.7085e-02,  1.0036e-03,  2.2654e-03,  2.6136e-02,  3.2379e-02,
        -1.2202e-01, -1.4276e-02, -1.2450e-02, -2.8245e-02, -1.8092e-02,
         5.3545e-02, -6.9918e-02, -9.9450e-02, -3.6917e-02, -1.0529e-01,
        -6.3872e-02,  4.9654e-03, -1.5427e-02, -1.1378e-01, -2.6185e-02,
         3.5076e-02, -1.1756e-01,  2.2707e-02, -5.1129e-02,  1.3128e-02,
        -1.1774e-02, -3.7682e-02,  6.8485e-03, -1.6407e-02,  5.3049e-02,
         1.5737e-02, -5.0535e-02,  4.1970e-02, -7.1631e-02,  1.3517e-03,
        -7.7581e-02, -1.1662e-02, -2.2467e-02, -9.9832e-02, -1.2775e-02,
        -9.0801e-02, -4.9489e-02, -3.1558e-02, -7.3381e-02,  7.4397e-02,
         6.7714e-03, -7.5495e-02,  7.5317e-02,  3.1609e-03, -9.2787e-02,
         3.7286e-03, -1.1012e-02, -7.3831e-02, -6.3583e-02, -1.1672e-02,
         1.3785e-02, -1.2373e-01, -3.6602e-02, -5.9431e-02, -5.9879e-02,
        -1.9944e-02, -1.2920e-01,  8.7528e-04, -2.4643e-02, -4.2501e-04,
        -6.8449e-02,  4.9533e-02,  1.3231e-02,  2.9516e-03,  7.7085e-02,
         1.6776e-02,  3.6549e-02,  4.8235e-02, -1.0302e-01,  5.1425e-03,
        -3.7529e-02,  9.8040e-04,  4.7065e-02, -2.4276e-02,  8.2564e-02,
         1.1704e-02, -8.1790e-02, -2.9285e-02,  2.1505e-03,  1.1538e-02,
        -5.1537e-03, -7.3970e-03, -1.2592e-01,  8.7202e-02,  3.3054e-02,
        -6.2491e-02,  1.2622e-03,  8.5898e-02,  6.6801e-02, -6.9260e-02,
        -1.2517e-01, -7.2013e-02, -1.1775e-02,  3.1026e-02, -1.5754e-01,
        -1.5252e-01, -6.1606e-02, -2.6766e-02,  2.4808e-02, -1.8789e-02,
        -3.3857e-02,  3.6919e-02,  6.5840e-02, -1.0816e-02,  2.6390e-03,
        -4.0511e-02,  4.0922e-02,  8.2421e-02,  5.6457e-02, -2.9484e-02,
        -7.2969e-02, -6.2644e-02, -5.7880e-02, -9.5500e-02, -1.3269e-02,
        -4.7556e-02, -8.9284e-02, -6.5450e-02, -5.9416e-02, -4.0735e-02,
        -4.2521e-02,  4.9757e-02,  9.6847e-03, -1.0386e-01, -8.7419e-03,
         3.9260e-02,  1.8632e-02, -2.4638e-02, -7.5218e-02, -9.0341e-02,
        -9.8209e-02, -9.3193e-02, -3.7894e-02,  2.7957e-02,  2.2001e-02,
        -6.1645e-02, -9.6039e-02, -2.3543e-01, -2.5407e-02, -9.7050e-03,
        -8.0836e-02, -5.9588e-02, -2.4652e-01, -3.5072e-02, -1.5717e-01,
        -4.6511e-03, -4.4432e-02, -1.1239e-01, -5.5706e-02,  1.5125e-03,
        -8.6480e-02, -4.0682e-02, -1.6409e-01, -2.0359e-02,  4.4605e-02,
        -9.2675e-02, -1.4511e-01, -8.9242e-02, -3.9843e-02, -7.9482e-03,
         1.0453e-02, -6.4067e-02, -6.3126e-02, -5.1381e-02, -9.0947e-02,
        -3.7384e-02, -4.0583e-02, -1.0263e-02,  4.2012e-02, -7.6674e-04,
        -1.3007e-02, -2.0721e-02, -6.1431e-02, -8.3795e-02,  1.1955e-02,
        -6.3821e-02, -2.9414e-03, -3.2345e-02, -4.2489e-02, -1.7660e-02,
         6.4783e-03, -2.8175e-02, -2.1898e-02, -3.6762e-02,  6.6746e-02,
        -5.7793e-02,  1.8975e-02,  4.6668e-02, -9.2695e-02, -4.2569e-03,
        -1.9443e-02, -6.4407e-02, -7.5846e-02,  8.6789e-02, -2.9930e-02,
        -7.8688e-02, -1.0259e-01, -3.3415e-03, -4.5228e-02, -6.6855e-02,
        -2.4670e-02, -1.2042e-01, -1.3362e-01, -1.0409e-01, -2.0383e-01,
        -9.0248e-02, -1.6292e-02, -6.1261e-02, -9.9040e-02, -6.2202e-02,
         6.8741e-02,  2.9185e-03, -1.3225e-02, -3.7504e-02,  1.6589e-03,
        -4.3154e-02,  8.3925e-02, -4.0735e-02, -1.0433e-01, -6.1051e-02,
         3.4171e-03, -1.0199e-01, -1.1452e-01, -6.9225e-02, -1.1300e-01,
        -2.2198e-02,  6.1297e-02, -1.2565e-02,  2.9758e-02, -1.2469e-01,
        -5.5992e-05, -1.0240e-01, -4.3720e-02,  5.4557e-03, -6.1504e-02,
        -1.2013e-01, -9.8159e-02, -2.4193e-02, -2.3596e-02, -5.9358e-02,
         6.9610e-02, -1.1845e-01,  9.9327e-03, -4.8936e-02,  3.7809e-02,
         1.6006e-02, -1.1894e-01,  1.3980e-02, -9.2628e-03,  2.0739e-03,
        -5.1735e-02,  6.1215e-02, -1.4201e-02, -3.4982e-02,  4.4506e-02,
        -1.1805e-01,  3.2304e-02,  1.0677e-02,  2.5806e-03,  3.2007e-02,
        -6.3287e-02, -4.0977e-02,  6.7292e-02, -8.4978e-02, -1.0107e-01,
        -9.8503e-04, -4.6954e-02,  2.3721e-02, -2.0580e-02, -8.9808e-02,
        -5.4493e-02,  7.0147e-02, -6.7757e-02,  7.2880e-02, -4.1892e-02,
        -6.2788e-02,  4.0507e-03,  1.0685e-02, -2.8471e-02, -2.2416e-02,
        -8.2918e-02, -2.7621e-02], device='cuda:0', requires_grad=True)
Param: encoder.layer4.1.conv1.weight
	Parameter containing:
tensor([[[[0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000]],

         [[0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000]],

         [[0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000]],

         ...,

         [[0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000]],

         [[0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000]],

         [[0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000]]],


        [[[0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000]],

         [[0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000]],

         [[0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000]],

         ...,

         [[0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000]],

         [[0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000]],

         [[0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000]]],


        [[[0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000]],

         [[0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000]],

         [[0.0000, 0.0000, 0.0000],
          [0.0000, 1.0010, 0.0000],
          [0.0000, 0.0000, 0.0000]],

         ...,

         [[0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000]],

         [[0.0000, 0.0000, 0.0000],
          [0.0000, 1.0010, 0.0000],
          [0.0000, 0.0000, 0.0000]],

         [[0.0000, 0.0000, 0.0000],
          [0.0000, 1.0010, 0.0000],
          [0.0000, 0.0000, 0.0000]]],


        ...,


        [[[0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000]],

         [[0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000]],

         [[0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000]],

         ...,

         [[0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000]],

         [[0.0000, 0.0000, 0.0000],
          [0.0000, 1.0010, 0.0000],
          [0.0000, 0.0000, 0.0000]],

         [[0.0000, 0.0000, 0.0000],
          [0.0000, 1.0010, 0.0000],
          [0.0000, 0.0000, 0.0000]]],


        [[[0.0000, 0.0000, 0.0000],
          [0.0000, 1.0010, 0.0000],
          [0.0000, 0.0000, 0.0000]],

         [[0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000]],

         [[0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000]],

         ...,

         [[0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000]],

         [[0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000]],

         [[0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000]]],


        [[[0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000]],

         [[0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000]],

         [[0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000]],

         ...,

         [[0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000]],

         [[0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000]],

         [[0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000],
          [0.0000, 0.0000, 0.0000]]]], device='cuda:0', requires_grad=True)
Param: encoder.layer4.1.bn1.weight
	Parameter containing:
tensor([0.6634, 1.2293, 0.9163, 0.7822, 0.9295, 0.9405, 1.0492, 0.8409, 1.0110,
        0.8234, 0.8315, 0.9989, 0.6981, 0.8646, 0.8291, 1.1465, 0.8427, 1.1832,
        0.8417, 1.1298, 1.4138, 0.8517, 0.9468, 1.2024, 1.0458, 0.7966, 1.2874,
        1.0890, 1.0917, 1.0361, 0.7976, 0.8294, 0.9130, 1.0739, 1.3028, 1.1374,
        0.9526, 0.9242, 0.8553, 0.8152, 0.8732, 0.9721, 1.3670, 0.8612, 0.8964,
        1.1986, 1.3373, 0.9349, 0.6939, 1.0016, 0.7922, 1.2473, 0.8107, 0.9341,
        0.7435, 0.7528, 0.8510, 1.0554, 1.0128, 1.0728, 0.9405, 0.9671, 1.2587,
        0.7506, 0.8014, 1.0514, 0.9347, 1.3118, 0.8552, 1.0958, 0.8333, 1.0152,
        0.8966, 1.1979, 0.9697, 0.7327, 0.8881, 0.8190, 0.9459, 0.8136, 0.8106,
        1.0523, 1.1215, 0.9121, 1.2953, 0.9199, 0.9259, 0.9547, 1.2620, 1.2665,
        0.9827, 0.9494, 1.0531, 0.8153, 0.9024, 1.2279, 0.9489, 1.3612, 0.9964,
        0.8239, 0.8502, 1.4625, 0.7155, 0.9398, 1.3108, 1.2366, 0.7285, 0.9250,
        1.3463, 1.0102, 0.9724, 0.9874, 0.7841, 1.0003, 0.8531, 0.9158, 0.8683,
        0.9338, 1.2141, 0.9447, 0.7264, 0.8810, 1.3607, 0.9164, 1.3336, 1.2842,
        0.9404, 0.8523, 0.7610, 1.0413, 0.8831, 0.9787, 0.7994, 1.0195, 0.7796,
        0.6853, 1.1372, 1.0291, 0.8230, 0.8943, 0.9323, 0.8441, 0.8999, 1.3743,
        1.1068, 0.8945, 1.1473, 1.3499, 1.3236, 1.0154, 0.8681, 0.8437, 0.9136,
        0.7770, 1.3023, 1.1510, 1.3131, 0.8083, 0.9932, 0.7739, 1.3106, 1.1962,
        1.3124, 1.0154, 1.1407, 1.2848, 1.1087, 1.2036, 0.8079, 0.7901, 1.1086,
        0.8370, 1.1692, 0.9857, 0.7790, 0.9181, 0.7130, 0.9928, 0.8800, 0.8573,
        1.2046, 1.1596, 0.8094, 1.0961, 1.0351, 0.8200, 0.8821, 1.1968, 0.9482,
        1.0273, 1.0602, 0.9944, 1.0750, 1.0623, 1.0040, 0.7680, 1.2609, 0.8997,
        0.8063, 1.3598, 0.8391, 0.7713, 1.3070, 1.3985, 1.3030, 0.7908, 0.7577,
        0.9832, 0.8690, 0.9639, 1.0074, 0.9833, 0.8766, 0.8917, 1.0752, 0.7718,
        0.7991, 0.9578, 0.9045, 1.1874, 0.8517, 0.7663, 1.2928, 1.2105, 1.3385,
        1.2911, 1.0966, 1.2232, 0.8434, 1.3221, 0.9815, 0.9346, 0.8611, 0.8291,
        0.7878, 0.7812, 1.1816, 0.8443, 0.8608, 0.8772, 0.9256, 0.9703, 0.9208,
        0.9848, 0.8924, 1.1175, 0.7967, 0.9940, 0.8811, 1.0426, 0.9007, 0.9562,
        1.4014, 0.7831, 0.9843, 1.2120, 0.9535, 0.9057, 0.7489, 0.8070, 0.8186,
        1.3646, 0.9249, 0.9786, 1.3537, 1.0169, 1.2989, 1.3897, 0.8925, 0.8704,
        1.2042, 0.8401, 0.9159, 0.8732, 0.7834, 0.8616, 0.9625, 1.0458, 1.2195,
        0.8515, 1.0132, 0.7443, 0.8439, 0.7965, 0.9467, 1.3622, 0.9212, 1.1455,
        1.4418, 1.2473, 0.8785, 0.9970, 1.1621, 1.3469, 0.7660, 0.9229, 1.0653,
        1.1172, 0.9350, 0.8081, 0.8128, 0.9218, 0.9220, 0.8161, 0.9188, 0.9814,
        0.8759, 0.9545, 1.1106, 0.9168, 1.3879, 0.9533, 0.8092, 0.7790, 1.0627,
        0.8621, 0.8596, 1.1678, 0.7683, 1.3161, 0.9784, 0.9578, 1.2712, 1.1716,
        0.9608, 1.2507, 0.8674, 0.8341, 0.9032, 0.7519, 1.1487, 0.8168, 0.9175,
        0.9998, 1.0337, 0.7688, 1.2621, 1.0089, 1.3385, 0.8654, 0.8086, 0.7742,
        0.9521, 1.0335, 1.2522, 1.0850, 0.8756, 1.2137, 1.2834, 1.3475, 1.0668,
        0.8953, 0.7611, 0.7116, 0.8765, 0.7651, 0.8445, 0.8198, 0.8623, 0.8171,
        0.9391, 0.8128, 1.1977, 1.0351, 0.8149, 1.3023, 0.9629, 1.3735, 1.2448,
        0.7232, 1.2584, 0.8849, 0.9317, 0.8671, 1.0202, 1.4092, 1.1773, 1.0552,
        1.2488, 0.8749, 1.2208, 1.0831, 1.0805, 0.7385, 1.1750, 1.1524, 0.9729,
        0.9854, 1.2729, 0.8927, 0.9691, 0.9531, 0.8701, 0.7873, 0.8571, 1.3096,
        0.8834, 1.2540, 0.8446, 0.8646, 1.1400, 1.2944, 1.0269, 0.9757, 0.8413,
        0.8818, 0.8193, 1.3851, 1.3012, 1.0843, 0.8527, 0.9794, 1.0019, 0.8087,
        1.2710, 1.1626, 0.8899, 0.8826, 0.9607, 0.8829, 0.9231, 0.8332, 0.9482,
        1.1329, 0.8361, 0.8333, 0.9087, 0.9874, 0.8264, 1.1255, 0.9060, 1.1943,
        0.8983, 1.2308, 0.8727, 1.2059, 0.8051, 1.0394, 1.2898, 1.1446, 0.8194,
        1.2830, 1.4029, 0.9801, 0.9495, 1.1314, 0.9320, 0.8960, 0.9433, 1.0623,
        0.7723, 1.3646, 0.8342, 0.9788, 0.9224, 0.8241, 1.2727, 0.9624, 1.0486,
        1.3252, 1.2254, 1.1700, 0.8830, 0.9358, 0.7743, 0.8357, 0.9226, 1.2845,
        0.8309, 1.1957, 1.0367, 0.9541, 1.0217, 1.1933, 0.8087, 0.7785, 1.3139,
        0.8276, 0.9361, 1.2741, 0.9438, 0.9077, 1.0974, 1.2003, 0.9885, 0.8778,
        1.3090, 0.8619, 0.9222, 0.7820, 0.8948, 0.9599, 1.0539, 0.8694, 1.3184,
        0.8083, 0.7908, 1.1119, 1.2218, 0.8883, 1.0302, 0.7900, 1.0380, 1.1939,
        0.7825, 0.8079, 0.8530, 1.2207, 1.3422, 0.8629, 1.0334, 1.2644],
       device='cuda:0', requires_grad=True)
Param: encoder.layer4.1.bn1.bias
	Parameter containing:
tensor([-0.3054, -0.1547, -0.1545, -0.3027, -0.2260, -0.2004, -0.1864, -0.2438,
        -0.2024, -0.2104, -0.2604, -0.1787, -0.2840, -0.1562, -0.2251, -0.1080,
        -0.2539, -0.2195, -0.2497, -0.1712, -0.2214, -0.1587, -0.2268, -0.1940,
        -0.1855, -0.2469, -0.2242, -0.1950, -0.2295, -0.1248, -0.2877, -0.1866,
        -0.1085, -0.1131, -0.1876, -0.1501, -0.2693, -0.1367, -0.2256, -0.2201,
        -0.2548, -0.2130, -0.2349, -0.1910, -0.2545, -0.1494, -0.1068, -0.1361,
        -0.2525, -0.2193, -0.2420, -0.1044, -0.1657, -0.2089, -0.2236, -0.1980,
        -0.2111, -0.2115, -0.1453, -0.1917, -0.1756, -0.2016, -0.1602, -0.3008,
        -0.2343, -0.2083, -0.2201, -0.1674, -0.0997, -0.1944, -0.2033, -0.1894,
        -0.1793, -0.1784, -0.1839, -0.3167, -0.3164, -0.1951, -0.1841, -0.1576,
        -0.1581, -0.1378, -0.0767, -0.2305, -0.1671, -0.3216, -0.1768, -0.1779,
        -0.1568, -0.1715, -0.1479, -0.0981, -0.1228, -0.2486, -0.1559, -0.1468,
        -0.2177, -0.2028, -0.1145, -0.2079, -0.2660, -0.1635, -0.2417, -0.2037,
        -0.1743, -0.1962, -0.3244, -0.1955, -0.1977, -0.2021, -0.2166, -0.1923,
        -0.2205, -0.1357, -0.1503, -0.2392, -0.1952, -0.1999, -0.1968, -0.1686,
        -0.3167, -0.1131, -0.1815, -0.1865, -0.1604, -0.1796, -0.1578, -0.0733,
        -0.2414, -0.1867, -0.1901, -0.1897, -0.1816, -0.1358, -0.2365, -0.2817,
        -0.1760, -0.1733, -0.1772, -0.2317, -0.2510, -0.1925, -0.0859, -0.1001,
        -0.1681, -0.2299, -0.1439, -0.1748, -0.1734, -0.2630, -0.2238, -0.2622,
        -0.1998, -0.2081, -0.1841, -0.1692, -0.1218, -0.2160, -0.0614, -0.2481,
        -0.1390, -0.1520, -0.1690, -0.2270, -0.1597, -0.1353, -0.1211, -0.1848,
        -0.2666, -0.3038, -0.1238, -0.3066, -0.1311, -0.1795, -0.2850, -0.1059,
        -0.2722, -0.1455, -0.2050, -0.2356, -0.1425, -0.1884, -0.2461, -0.0517,
        -0.1871, -0.2255, -0.1966, -0.1205, -0.2680, -0.1989, -0.2309, -0.2037,
        -0.1870, -0.1672, -0.2739, -0.2677, -0.2219, -0.1808, -0.2674, -0.1988,
        -0.2503, -0.1202, -0.1917, -0.2571, -0.2214, -0.1747, -0.1146, -0.2858,
        -0.2610, -0.2552, -0.2137, -0.2279, -0.1282, -0.2737, -0.2254, -0.2677,
        -0.2000, -0.2013, -0.1963, -0.1646, -0.2595, -0.3110, -0.2283, -0.1857,
        -0.2262, -0.1942, -0.2004, -0.2185, -0.2114, -0.1402, -0.1555, -0.1697,
        -0.1965, -0.2656, -0.2821, -0.1287, -0.2084, -0.2086, -0.2289, -0.1386,
        -0.1938, -0.1827, -0.2174, -0.0996, -0.1697, -0.1839, -0.2456, -0.2247,
        -0.1914, -0.2202, -0.2646, -0.1866, -0.1739, -0.1510, -0.1813, -0.1269,
        -0.1362, -0.2670, -0.2071, -0.2386, -0.2590, -0.2415, -0.2049, -0.2061,
        -0.1388, -0.1676, -0.1512, -0.1780, -0.0868, -0.1797, -0.2130, -0.2252,
        -0.0559, -0.2600, -0.2602, -0.1839, -0.1082, -0.2110, -0.1229, -0.1995,
        -0.1670, -0.2126, -0.2110, -0.2203, -0.1599, -0.1702, -0.2068, -0.1646,
        -0.1604, -0.1879, -0.1888, -0.1728, -0.2049, -0.1902, -0.2528, -0.1717,
        -0.1542, -0.2088, -0.1986, -0.2557, -0.2867, -0.1257, -0.1592, -0.2481,
        -0.2455, -0.1983, -0.2444, -0.1903, -0.1373, -0.1325, -0.2622, -0.1669,
        -0.1750, -0.2832, -0.1239, -0.2940, -0.2192, -0.1814, -0.2006, -0.1725,
        -0.2006, -0.2375, -0.1690, -0.0983, -0.1763, -0.1756, -0.2093, -0.2447,
        -0.1646, -0.2007, -0.1961, -0.2170, -0.0927, -0.1037, -0.1563, -0.1944,
        -0.1466, -0.1643, -0.2128, -0.1590, -0.1254, -0.1872, -0.1065, -0.2195,
        -0.1737, -0.1092, -0.2798, -0.1375, -0.1671, -0.2258, -0.1852, -0.2044,
        -0.2432, -0.2703, -0.2459, -0.2874, -0.2391, -0.2260, -0.1839, -0.2081,
        -0.2195, -0.2826, -0.1439, -0.1260, -0.1603, -0.1963, -0.1819, -0.2012,
        -0.1614, -0.3290, -0.1458, -0.1630, -0.2396, -0.1957, -0.1421, -0.2357,
        -0.1151, -0.1287, -0.2025, -0.2052, -0.0960, -0.1938, -0.2078, -0.2784,
        -0.2212, -0.1882, -0.2020, -0.1414, -0.2021, -0.1779, -0.1897, -0.2303,
        -0.2266, -0.2455, -0.2117, -0.1486, -0.1527, -0.1615, -0.2643, -0.1896,
        -0.2108, -0.1956, -0.1688, -0.1799, -0.1568, -0.2640, -0.2912, -0.1686,
        -0.2248, -0.0797, -0.2834, -0.1406, -0.2591, -0.1634, -0.2508, -0.1666,
        -0.2006, -0.1941, -0.1359, -0.1781, -0.1637, -0.0934, -0.2228, -0.1132,
        -0.2433, -0.2360, -0.1839, -0.2107, -0.1421, -0.1473, -0.2294, -0.1593,
        -0.1713, -0.2318, -0.1683, -0.1505, -0.2412, -0.1506, -0.1843, -0.1669,
        -0.2525, -0.1890, -0.2470, -0.1637, -0.1953, -0.1803, -0.2898, -0.2272,
        -0.2515, -0.1870, -0.2483, -0.1429, -0.1805, -0.2365, -0.2115, -0.2749,
        -0.0986, -0.1319, -0.1708, -0.1495, -0.1742, -0.2427, -0.2037, -0.1774,
        -0.2378, -0.2410, -0.2627, -0.2234, -0.1645, -0.1081, -0.2129, -0.2018,
        -0.1467, -0.1714, -0.2319, -0.2356, -0.1809, -0.2886, -0.1399, -0.2283,
        -0.2516, -0.2227, -0.2192, -0.1911, -0.2068, -0.2311, -0.2225, -0.1959,
        -0.1878, -0.2307, -0.2174, -0.1200, -0.2072, -0.2589, -0.1649, -0.2693,
        -0.2726, -0.0373, -0.1684, -0.1677, -0.2843, -0.1804, -0.1937, -0.2113,
        -0.2153, -0.1875, -0.2874, -0.1935, -0.1334, -0.2295, -0.1836, -0.2331],
       device='cuda:0', requires_grad=True)
Param: encoder.layer4.1.conv2.weight
	Parameter containing:
tensor([[[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0012,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0012,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0012,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0012,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0012,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0012,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0012,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0012,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0012,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0012,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0012,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        ...,


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0012,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0012,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0012,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0012,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0012,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0012,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0012,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  1.0012,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]],


        [[[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0012,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         ...,

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0012,  0.0000],
          [ 0.0000,  0.0000,  0.0000]],

         [[ 0.0000,  0.0000,  0.0000],
          [ 0.0000, -1.0012,  0.0000],
          [ 0.0000,  0.0000,  0.0000]]]], device='cuda:0', requires_grad=True)
Param: encoder.layer4.1.bn2.weight
	Parameter containing:
tensor([0.7431, 0.7953, 0.8009, 0.7264, 0.7927, 0.8185, 0.7090, 0.7846, 0.8206,
        0.8051, 0.8268, 0.6271, 0.7951, 0.7379, 0.7271, 0.8563, 0.7943, 0.7995,
        0.7970, 0.8376, 0.7352, 0.7852, 0.8396, 0.7316, 0.7727, 0.7242, 0.6950,
        0.7583, 0.7838, 0.9054, 0.7044, 0.7510, 0.7859, 0.7630, 0.7718, 0.7662,
        0.6932, 0.6884, 0.6870, 0.7430, 0.7308, 0.8612, 0.7515, 0.7340, 0.7741,
        0.7565, 0.8985, 0.7274, 0.8166, 0.7553, 0.7385, 0.7977, 0.8294, 0.7431,
        0.7522, 0.8077, 0.8495, 0.7947, 0.7524, 0.7446, 0.7198, 0.7685, 0.7007,
        0.7300, 0.7811, 0.8282, 0.7445, 0.7544, 0.6830, 0.8071, 0.8089, 0.8217,
        0.7427, 0.7150, 0.7456, 0.6629, 0.8495, 0.7884, 0.8157, 0.8048, 0.7888,
        0.7321, 0.7323, 0.7486, 0.7221, 0.6855, 0.7509, 0.7106, 0.8801, 0.8818,
        0.7928, 0.7449, 0.7332, 0.8088, 0.6048, 0.6958, 0.8370, 0.7999, 0.6617,
        0.7319, 0.7707, 0.8277, 0.7188, 0.7134, 0.7583, 0.6892, 0.8248, 0.7300,
        0.7872, 0.6650, 0.8227, 0.8865, 0.8656, 0.6531, 0.7820, 0.8701, 0.8431,
        0.7403, 0.7211, 0.8557, 0.6471, 0.7333, 0.7224, 0.7320, 0.6866, 0.8189,
        0.7066, 0.7757, 0.7619, 0.6667, 0.7402, 0.5652, 0.7926, 0.7351, 0.7110,
        0.7916, 0.7357, 0.6374, 0.7122, 0.8575, 0.8163, 0.7669, 0.7380, 0.6748,
        0.6837, 0.7645, 0.7975, 0.6597, 0.7775, 0.8691, 0.8665, 0.7872, 0.8098,
        0.8249, 0.8068, 0.7937, 0.6070, 0.6550, 0.7071, 0.8133, 0.7885, 0.7653,
        0.8837, 0.7846, 0.7983, 0.6849, 0.7653, 0.8069, 0.8827, 0.7900, 0.8212,
        0.7193, 0.6959, 0.7750, 0.8440, 0.7955, 0.7636, 0.6936, 0.8820, 0.7627,
        0.7332, 0.7721, 0.7877, 0.7673, 0.7638, 0.8047, 0.7378, 0.7855, 0.7779,
        0.8436, 0.7859, 0.7385, 0.8588, 0.7964, 0.7864, 0.7287, 0.8030, 0.7689,
        0.8353, 0.8056, 0.7201, 0.7897, 0.8355, 0.8248, 0.8067, 0.7991, 0.7964,
        0.7085, 0.7040, 0.8260, 0.6436, 0.6921, 0.8069, 0.7941, 0.7961, 0.8432,
        0.8146, 0.8789, 0.7327, 0.7212, 0.7251, 0.7629, 0.7338, 0.7438, 0.7560,
        0.8120, 0.7141, 0.7802, 0.7906, 0.7436, 0.6839, 0.7656, 0.7457, 0.7282,
        0.7429, 0.7887, 0.8347, 0.8592, 0.6928, 0.7053, 0.8066, 0.7538, 0.6356,
        0.7597, 0.6447, 0.8722, 0.8041, 0.7891, 0.7075, 0.8100, 0.7861, 0.7491,
        0.7639, 0.7088, 0.7860, 0.7822, 0.7482, 0.6931, 0.7642, 0.7251, 0.8588,
        0.7548, 0.7833, 0.7982, 0.6628, 0.7592, 0.7683, 0.7427, 0.8158, 0.6368,
        0.8138, 0.7033, 0.7550, 0.7510, 0.7343, 0.6783, 0.7824, 0.8647, 0.8024,
        0.7187, 0.8302, 0.7869, 0.7439, 0.6399, 0.7530, 0.7683, 0.7732, 0.6974,
        0.8566, 0.6870, 0.7563, 0.7258, 0.7267, 0.7998, 0.7631, 0.6674, 0.6826,
        0.7327, 0.7263, 0.6486, 0.6387, 0.7903, 0.7482, 0.7982, 0.8019, 0.7390,
        0.7928, 0.7686, 0.7480, 0.6728, 0.7440, 0.7618, 0.7349, 0.7818, 0.7775,
        0.8197, 0.7823, 0.7129, 0.7724, 0.7925, 0.6633, 0.7637, 0.7085, 0.8139,
        0.7477, 0.7676, 0.7537, 0.7300, 0.7686, 0.7708, 0.7984, 0.7623, 0.6758,
        0.8574, 0.8254, 0.7456, 0.7328, 0.6199, 0.7174, 0.7258, 0.7525, 0.7405,
        0.7802, 0.7852, 0.8093, 0.6765, 0.6777, 0.7790, 0.8248, 0.7026, 0.6983,
        0.7676, 0.8300, 0.7312, 0.7173, 0.8373, 0.7147, 0.8484, 0.7655, 0.8527,
        0.6984, 0.9120, 0.5534, 0.7521, 0.7773, 0.6659, 0.6901, 0.7679, 0.7878,
        0.7086, 0.8432, 0.8434, 0.7822, 0.7773, 0.7685, 0.7788, 0.7459, 0.7455,
        0.6629, 0.6532, 0.8218, 0.7943, 0.7076, 0.6609, 0.7716, 0.8180, 0.7407,
        0.7017, 0.8547, 0.8298, 0.7451, 0.8115, 0.7882, 0.8136, 0.7439, 0.6968,
        0.7147, 0.7120, 0.8121, 0.8254, 0.7592, 0.7042, 0.8080, 0.7402, 0.6860,
        0.6930, 0.7539, 0.6516, 0.6882, 0.7377, 0.7930, 0.8352, 0.8224, 0.7700,
        0.7438, 0.7573, 0.7542, 0.7267, 0.7659, 0.7848, 0.7220, 0.7911, 0.6471,
        0.7819, 0.7335, 0.7571, 0.7779, 0.7268, 0.7435, 0.8521, 0.6738, 0.8176,
        0.7144, 0.8239, 0.7137, 0.6556, 0.8649, 0.6281, 0.7218, 0.7568, 0.7263,
        0.6854, 0.7166, 0.7611, 0.6726, 0.7907, 0.7523, 0.8137, 0.8729, 0.6558,
        0.7339, 0.8418, 0.7875, 0.6622, 0.7374, 0.7394, 0.7191, 0.8152, 0.7448,
        0.8090, 0.7065, 0.8253, 0.6755, 0.6725, 0.7751, 0.5858, 0.7858, 0.7579,
        0.7346, 0.7903, 0.6995, 0.8695, 0.5746, 0.7797, 0.6284, 0.7063, 0.7764,
        0.6711, 0.8551, 0.7869, 0.7811, 0.7641, 0.7566, 0.8247, 0.6907, 0.8598,
        0.7766, 0.6937, 0.7275, 0.7914, 0.7339, 0.8368, 0.7481, 0.7489, 0.8159,
        0.7413, 0.8809, 0.7103, 0.7417, 0.7735, 0.8033, 0.6331, 0.8112, 0.7810,
        0.7326, 0.8165, 0.7565, 0.6784, 0.7368, 0.7378, 0.8102, 0.7070],
       device='cuda:0', requires_grad=True)
Param: encoder.layer4.1.bn2.bias
	Parameter containing:
tensor([-0.1268, -0.1579, -0.1595, -0.0934, -0.0854, -0.0450, -0.1200, -0.0126,
        -0.0485,  0.0135, -0.1257, -0.1241, -0.1184, -0.0937, -0.1218, -0.1770,
        -0.0687, -0.0563, -0.1521, -0.0733, -0.1366, -0.1566, -0.0344, -0.0601,
        -0.1586, -0.1086, -0.0284, -0.0706, -0.0694, -0.1525, -0.0942, -0.0889,
        -0.1665, -0.1616, -0.1392, -0.0199, -0.0607, -0.0964, -0.0806, -0.0769,
        -0.0729, -0.0519, -0.1273, -0.1767, -0.0808, -0.0242, -0.0736, -0.1099,
        -0.0688, -0.1573, -0.1700, -0.1321, -0.1294, -0.0231, -0.0769, -0.1211,
        -0.1771, -0.2080, -0.2017, -0.0863, -0.1109, -0.0661, -0.1860, -0.2076,
        -0.0309, -0.0659, -0.0945, -0.0697, -0.1395, -0.0233, -0.0772, -0.0075,
        -0.0581, -0.0461, -0.1236, -0.0980, -0.0712, -0.1601, -0.0640, -0.0929,
        -0.0687, -0.0447, -0.1565, -0.0820, -0.1728, -0.0815, -0.0845, -0.1747,
        -0.0790, -0.1766, -0.0081, -0.1346, -0.1210, -0.1284, -0.0819, -0.1515,
         0.0025, -0.0353, -0.1258, -0.1341, -0.0670, -0.1024, -0.1521, -0.1145,
        -0.1608, -0.1154, -0.0638, -0.0921, -0.1687, -0.2041, -0.1226, -0.0867,
        -0.1411, -0.1337, -0.0644, -0.1174, -0.0855, -0.1662, -0.1423, -0.0235,
        -0.1126, -0.0887, -0.1237, -0.1582, -0.1343, -0.0312, -0.1389, -0.1269,
        -0.1437, -0.0396, -0.1281, -0.1896, -0.1775, -0.1135, -0.1038, -0.0591,
        -0.0553, -0.1370, -0.0919, -0.1026, -0.0046, -0.1414, -0.2551, -0.0342,
        -0.1379, -0.1418, -0.1858, -0.1286, -0.0811, -0.0929, -0.0895, -0.1658,
        -0.2986, -0.0982, -0.0064, -0.0993, -0.1041, -0.1048, -0.1079, -0.0688,
        -0.0335, -0.1153, -0.1226, -0.1339, -0.1191, -0.1225, -0.1618, -0.0968,
        -0.1473, -0.1082, -0.0090, -0.1619, -0.1256, -0.1595, -0.0568, -0.1433,
        -0.0781, -0.0746, -0.0767,  0.0092, -0.1653, -0.1238, -0.1691, -0.0904,
        -0.0416, -0.2170,  0.0289, -0.1114, -0.1156, -0.0734, -0.0313, -0.1660,
        -0.0691, -0.0965, -0.0884, -0.1088, -0.0851, -0.1876, -0.1656, -0.1354,
        -0.1072, -0.0056, -0.0760, -0.0274, -0.0694, -0.0218, -0.0960, -0.0942,
        -0.1922, -0.0965, -0.1134, -0.2029, -0.1693, -0.0203, -0.1961, -0.1235,
        -0.0861, -0.1180, -0.1316, -0.1113, -0.1445, -0.1580, -0.0538, -0.1211,
        -0.1473, -0.0868, -0.1309, -0.0657, -0.0622, -0.1568, -0.1731, -0.0962,
        -0.1149, -0.1160, -0.1169, -0.0939, -0.2040, -0.1043, -0.2196, -0.1721,
        -0.1170, -0.0914, -0.1478, -0.1230, -0.1245, -0.0130, -0.1499, -0.0255,
        -0.0945, -0.1055, -0.1555, -0.1429, -0.0989, -0.0628, -0.0196, -0.1269,
        -0.1156, -0.0299, -0.1535, -0.0989, -0.0859, -0.0836, -0.0686, -0.1758,
        -0.1922, -0.0954, -0.1077, -0.0542, -0.1280, -0.0839, -0.0820, -0.1379,
        -0.1338, -0.0926, -0.0899, -0.1196, -0.0702, -0.1135, -0.1141, -0.1527,
        -0.1323, -0.1474, -0.0951, -0.1510, -0.0999, -0.0774, -0.1829, -0.1595,
        -0.0845, -0.1559, -0.1081, -0.1349, -0.0270, -0.0990, -0.1756, -0.1386,
        -0.1049, -0.0902, -0.1768, -0.0859, -0.1576, -0.0988, -0.0780, -0.0629,
         0.0130, -0.0996, -0.1178, -0.1283, -0.1419, -0.1418, -0.1636, -0.1129,
        -0.1854,  0.0288, -0.0331, -0.0871, -0.0715, -0.0091,  0.0034, -0.2104,
        -0.2079, -0.1287, -0.1228, -0.0722, -0.2808, -0.2252, -0.1200, -0.1342,
        -0.1435, -0.0488, -0.0908, -0.1134, -0.0642, -0.0823, -0.0562, -0.1369,
         0.0145, -0.0206, -0.1148, -0.0841, -0.0794, -0.1346, -0.1757, -0.1349,
        -0.0690, -0.0698, -0.1648, -0.1210, -0.1751, -0.1695, -0.1711, -0.0734,
        -0.1127, -0.1585, -0.1427, -0.0215, -0.0428, -0.0833, -0.0907, -0.1419,
        -0.1840, -0.1210, -0.2162, -0.0125, -0.0437, -0.1188, -0.1523, -0.1837,
        -0.1186, -0.0408, -0.1014, -0.0748, -0.2317, -0.0701, -0.2068, -0.0252,
        -0.0724, -0.1795, -0.1312, -0.1119, -0.1106, -0.1295, -0.1479, -0.1419,
        -0.0134, -0.1168, -0.1855, -0.1619, -0.0892, -0.0624, -0.1041, -0.0506,
        -0.1451, -0.1295, -0.1486, -0.1105, -0.1221, -0.0997, -0.0033, -0.0027,
        -0.1176, -0.0739, -0.1203, -0.1410, -0.0352, -0.1657,  0.0015, -0.1723,
        -0.1113, -0.0518, -0.1323, -0.1204, -0.0641, -0.0971,  0.0172, -0.0921,
        -0.1278, -0.1263, -0.1793, -0.1114, -0.1367, -0.0949, -0.1044, -0.0032,
        -0.1041, -0.1822, -0.2177, -0.0914, -0.1441, -0.1471, -0.1471, -0.1251,
        -0.1778, -0.1621, -0.1461, -0.2080, -0.0264, -0.1162, -0.1948, -0.1767,
        -0.0283, -0.1263, -0.0921, -0.1778, -0.1820, -0.1042, -0.0407, -0.0880,
        -0.1567, -0.1910, -0.1296, -0.1062, -0.1018, -0.1652, -0.1560, -0.1377,
        -0.0894, -0.0582, -0.1314, -0.1542, -0.0662, -0.1329, -0.0968, -0.1314,
        -0.0818, -0.1305, -0.1189, -0.0658, -0.1078, -0.1983,  0.0154, -0.1629,
        -0.1437, -0.1701, -0.0585, -0.0529, -0.1447, -0.1503, -0.0619, -0.0194,
        -0.1306, -0.0321, -0.1058, -0.1088, -0.0167, -0.1416, -0.0221, -0.1285,
        -0.1404, -0.0393, -0.1786, -0.1208, -0.1306, -0.1255, -0.0961, -0.1008,
        -0.1051, -0.0533, -0.0686, -0.1224, -0.0831, -0.0143, -0.1130, -0.1586,
        -0.1204, -0.1268, -0.1692, -0.1196, -0.0987, -0.0836, -0.1164, -0.1531],
       device='cuda:0', requires_grad=True)
Param: fc.weight
	Parameter containing:
tensor([[ 0.0552,  0.0810, -0.0911,  ...,  0.0360,  0.0154, -0.0155],
        [-0.0619, -0.0507, -0.0239,  ..., -0.0706,  0.0774, -0.0214],
        [-0.0888, -0.0486,  0.0225,  ..., -0.1093,  0.1027,  0.0517],
        ...,
        [-0.0597, -0.0078,  0.0032,  ..., -0.0886, -0.0412,  0.0038],
        [-0.1055,  0.0918, -0.0016,  ..., -0.0848, -0.0498, -0.0796],
        [-0.0559, -0.0499, -0.0288,  ..., -0.0404, -0.0192,  0.0089]],
       device='cuda:0', requires_grad=True)
Param: fc.bias
	Parameter containing:
tensor([-0.0262,  0.0041,  0.0413,  0.0291,  0.0491,  0.0031,  0.0179,  0.0020,
        -0.0056,  0.0375], device='cuda:0', requires_grad=True)







==================== End of the experiment ====================


